17/03/15 09:59:30 WARN SparkContext: Support for Java 7 is deprecated as of Spark 2.0.0
17/03/15 09:59:31 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
17/03/15 09:59:31 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
17/03/15 09:59:31 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[GetGroups], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
17/03/15 09:59:31 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
17/03/15 09:59:31 DEBUG Shell: setsid exited with exit code 0
17/03/15 09:59:31 DEBUG Groups:  Creating new Groups object
17/03/15 09:59:31 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
17/03/15 09:59:31 DEBUG NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
17/03/15 09:59:31 DEBUG NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
17/03/15 09:59:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/15 09:59:31 DEBUG PerformanceAdvisory: Falling back to shell based
17/03/15 09:59:31 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
17/03/15 09:59:31 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17/03/15 09:59:31 DEBUG UserGroupInformation: hadoop login
17/03/15 09:59:31 DEBUG UserGroupInformation: hadoop login commit
17/03/15 09:59:31 DEBUG UserGroupInformation: using local user:UnixPrincipal: hadoop
17/03/15 09:59:31 DEBUG UserGroupInformation: Using user: "UnixPrincipal: hadoop" with name hadoop
17/03/15 09:59:31 DEBUG UserGroupInformation: User entry: "hadoop"
17/03/15 09:59:31 DEBUG UserGroupInformation: UGI loginUser:hadoop (auth:SIMPLE)
17/03/15 09:59:31 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
17/03/15 09:59:31 WARN SparkConf: 
SPARK_CLASSPATH was detected (set to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
17/03/15 09:59:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:' as a work-around.
17/03/15 09:59:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:' as a work-around.
17/03/15 09:59:31 DEBUG InternalLoggerFactory: Using SLF4J as the default logging framework
17/03/15 09:59:31 DEBUG PlatformDependent0: java.nio.Buffer.address: available
17/03/15 09:59:31 DEBUG PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
17/03/15 09:59:31 DEBUG PlatformDependent0: sun.misc.Unsafe.copyMemory: available
17/03/15 09:59:31 DEBUG PlatformDependent0: direct buffer constructor: available
17/03/15 09:59:31 DEBUG PlatformDependent0: java.nio.Bits.unaligned: available, true
17/03/15 09:59:31 DEBUG PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
17/03/15 09:59:31 DEBUG Cleaner0: java.nio.ByteBuffer.cleaner(): available
17/03/15 09:59:31 DEBUG PlatformDependent: Java version: 7
17/03/15 09:59:31 DEBUG PlatformDependent: -Dio.netty.noUnsafe: false
17/03/15 09:59:31 DEBUG PlatformDependent: sun.misc.Unsafe: available
17/03/15 09:59:31 DEBUG PlatformDependent: -Dio.netty.noJavassist: false
17/03/15 09:59:31 DEBUG PlatformDependent: Javassist: available
17/03/15 09:59:31 DEBUG PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
17/03/15 09:59:31 DEBUG PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
17/03/15 09:59:31 DEBUG PlatformDependent: -Dio.netty.noPreferDirect: false
17/03/15 09:59:31 DEBUG PlatformDependent: io.netty.maxDirectMemory: 954728448 bytes
17/03/15 09:59:31 DEBUG JavassistTypeParameterMatcherGenerator: Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
17/03/15 09:59:31 DEBUG JavassistTypeParameterMatcherGenerator: Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
17/03/15 09:59:31 DEBUG MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 8
17/03/15 09:59:31 DEBUG NioEventLoop: -Dio.netty.noKeySetOptimization: false
17/03/15 09:59:31 DEBUG NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
17/03/15 09:59:31 DEBUG PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 8
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 8
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
17/03/15 09:59:31 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
17/03/15 09:59:31 DEBUG ThreadLocalRandom: -Dio.netty.initialSeedUniquifier: 0x3afe47e9460bbd01 (took 0 ms)
17/03/15 09:59:31 DEBUG ByteBufUtil: -Dio.netty.allocator.type: unpooled
17/03/15 09:59:31 DEBUG ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
17/03/15 09:59:31 DEBUG ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
17/03/15 09:59:31 DEBUG NetUtil: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%1)
17/03/15 09:59:31 DEBUG NetUtil: /proc/sys/net/core/somaxconn: 128
17/03/15 09:59:31 DEBUG AbstractByteBuf: -Dio.netty.buffer.bytebuf.checkAccessible: true
17/03/15 09:59:31 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
17/03/15 09:59:31 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.maxRecords: 4
17/03/15 09:59:31 DEBUG ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@22ba4310
17/03/15 09:59:31 DEBUG Recycler: -Dio.netty.recycler.maxCapacity.default: 32768
17/03/15 09:59:31 DEBUG Recycler: -Dio.netty.recycler.maxSharedCapacityFactor: 2
17/03/15 09:59:31 DEBUG Recycler: -Dio.netty.recycler.linkCapacity: 16
17/03/15 09:59:31 DEBUG Recycler: -Dio.netty.recycler.ratio: 8
17/03/15 09:59:32 DEBUG BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false
17/03/15 09:59:32 DEBUG BlockReaderLocal: dfs.client.read.shortcircuit = false
17/03/15 09:59:32 DEBUG BlockReaderLocal: dfs.client.domain.socket.data.traffic = false
17/03/15 09:59:32 DEBUG BlockReaderLocal: dfs.domain.socket.path = 
17/03/15 09:59:32 DEBUG RetryUtils: multipleLinearRandomRetry = null
17/03/15 09:59:32 DEBUG Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6e6fa41c
17/03/15 09:59:32 DEBUG Client: getting client out of cache: org.apache.hadoop.ipc.Client@1077b5d0
17/03/15 09:59:32 DEBUG PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
17/03/15 09:59:32 DEBUG DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
17/03/15 09:59:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 09:59:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #0
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #0
17/03/15 09:59:32 DEBUG ProtobufRpcEngine: Call: getFileInfo took 25ms
17/03/15 09:59:32 DEBUG DFSClient: /eventLogs/app-20170315095931-0046.lz4.inprogress: masked=rw-r--r--
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #1
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #1
17/03/15 09:59:32 DEBUG ProtobufRpcEngine: Call: create took 10ms
17/03/15 09:59:32 DEBUG DFSClient: computePacketChunkSize: src=/eventLogs/app-20170315095931-0046.lz4.inprogress, chunkSize=516, chunksPerPacket=126, packetSize=65016
17/03/15 09:59:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 started
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #2
17/03/15 09:59:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #2
17/03/15 09:59:32 DEBUG ProtobufRpcEngine: Call: setPermission took 5ms
17/03/15 09:59:32 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/03/15 09:59:32 DEBUG DFSClient: Waiting for ack for: -1
17/03/15 09:59:32 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/03/15 09:59:32 DEBUG DFSClient: Waiting for ack for: -1
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #3
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #3
17/03/15 09:59:33 DEBUG ProtobufRpcEngine: Call: getFileInfo took 0ms
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #4
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #4
17/03/15 09:59:33 DEBUG ProtobufRpcEngine: Call: getListing took 1ms
17/03/15 09:59:33 DEBUG FileInputFormat: Time taken to get FileStatuses: 15
17/03/15 09:59:33 INFO FileInputFormat: Total input paths to process : 10
17/03/15 09:59:33 DEBUG FileInputFormat: Total # of splits generated by getSplits: 15, TimeTaken: 19
17/03/15 09:59:33 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/03/15 09:59:33 DEBUG DFSClient: Waiting for ack for: -1
17/03/15 09:59:33 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=0, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/15 09:59:33 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6303 lastFlushOffset=0 createNewBlock=false
17/03/15 09:59:33 DEBUG DFSClient: Queued packet 0
17/03/15 09:59:33 DEBUG DFSClient: Waiting for ack for: 0
17/03/15 09:59:33 DEBUG DFSClient: Allocating new block
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #5
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #5
17/03/15 09:59:33 DEBUG ProtobufRpcEngine: Call: addBlock took 10ms
17/03/15 09:59:33 DEBUG DFSClient: pipeline = DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]
17/03/15 09:59:33 DEBUG DFSClient: Connecting to datanode 172.21.15.173:50010
17/03/15 09:59:33 DEBUG DFSClient: Send buf size 124928
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #6
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #6
17/03/15 09:59:33 DEBUG ProtobufRpcEngine: Call: getServerDefaults took 1ms
17/03/15 09:59:33 DEBUG SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /172.21.15.173, datanodeId = DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]
17/03/15 09:59:33 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6303
17/03/15 09:59:33 DEBUG DFSClient: DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #7
17/03/15 09:59:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #7
17/03/15 09:59:33 DEBUG ProtobufRpcEngine: Call: fsync took 55ms
17/03/15 09:59:33 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=1, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/03/15 09:59:33 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6303 lastFlushOffset=6303 createNewBlock=false
17/03/15 09:59:33 DEBUG DFSClient: Waiting for ack for: 0
[Stage 0:>                                                         (0 + 4) / 10][Stage 0:>                                                         (0 + 5) / 10][Stage 0:=====>                                                    (1 + 4) / 10][Stage 0:===========>                                              (2 + 4) / 10][Stage 0:=================>                                        (3 + 4) / 10][Stage 0:=======================>                                  (4 + 4) / 10]17/03/15 09:59:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 09:59:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 0:=============================>                            (5 + 4) / 10][Stage 0:========================================>                 (7 + 3) / 10][Stage 0:==============================================>           (8 + 2) / 10][Stage 0:====================================================>     (9 + 1) / 10]                                                                                17/03/15 09:59:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=2, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/03/15 09:59:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=10524 lastFlushOffset=6303 createNewBlock=false
17/03/15 09:59:45 DEBUG DFSClient: Queued packet 2
17/03/15 09:59:45 DEBUG DFSClient: Waiting for ack for: 2
17/03/15 09:59:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 2 offsetInBlock: 6144 lastPacketInBlock: false lastByteOffsetInBlock: 10524
17/03/15 09:59:45 DEBUG DFSClient: DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 09:59:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=3, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10240
17/03/15 09:59:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=10524 lastFlushOffset=10524 createNewBlock=false
17/03/15 09:59:45 DEBUG DFSClient: Waiting for ack for: 2
17/03/15 09:59:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=4, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10240
17/03/15 09:59:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=10524 lastFlushOffset=10524 createNewBlock=false
17/03/15 09:59:45 DEBUG DFSClient: Waiting for ack for: 2
[Stage 1:>                                                         (0 + 4) / 10][Stage 1:=====>                                                    (1 + 4) / 10][Stage 1:===========>                                              (2 + 4) / 10][Stage 1:=================>                                        (3 + 4) / 10][Stage 1:=======================>                                  (4 + 4) / 10][Stage 1:========================================>                 (7 + 3) / 10][Stage 1:==============================================>           (8 + 2) / 10][Stage 1:====================================================>     (9 + 1) / 10]17/03/15 09:59:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=5, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10240
17/03/15 09:59:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=14934 lastFlushOffset=10524 createNewBlock=false
17/03/15 09:59:48 DEBUG DFSClient: Queued packet 5
17/03/15 09:59:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 5 offsetInBlock: 10240 lastPacketInBlock: false lastByteOffsetInBlock: 14934
17/03/15 09:59:48 DEBUG DFSClient: Waiting for ack for: 5
17/03/15 09:59:48 DEBUG DFSClient: DFSClient seqno: 5 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 2:>                                                         (0 + 4) / 10][Stage 2:=======================>                                  (4 + 4) / 10][Stage 2:==================================>                       (6 + 4) / 10][Stage 2:==============================================>           (8 + 2) / 10]                                                                                17/03/15 09:59:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=6, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14848
17/03/15 09:59:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=28183 lastFlushOffset=14934 createNewBlock=false
17/03/15 09:59:57 DEBUG DFSClient: Queued packet 6
17/03/15 09:59:57 DEBUG DFSClient: Waiting for ack for: 6
17/03/15 09:59:57 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 6 offsetInBlock: 14848 lastPacketInBlock: false lastByteOffsetInBlock: 28183
17/03/15 09:59:57 DEBUG DFSClient: DFSClient seqno: 6 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 09:59:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=7, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28160
17/03/15 09:59:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=28183 lastFlushOffset=28183 createNewBlock=false
17/03/15 09:59:57 DEBUG DFSClient: Waiting for ack for: 6
17/03/15 09:59:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=8, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28160
17/03/15 09:59:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=28183 lastFlushOffset=28183 createNewBlock=false
17/03/15 09:59:57 DEBUG DFSClient: Waiting for ack for: 6
[Stage 4:>                                                         (0 + 4) / 10]17/03/15 10:00:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:00:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:00:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:00:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #8
17/03/15 10:00:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #8
17/03/15 10:00:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:00:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:00:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 4:=======================>                                  (4 + 4) / 10]17/03/15 10:00:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:00:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 4:==============================================>           (8 + 2) / 10][Stage 4:====================================================>     (9 + 1) / 10]17/03/15 10:00:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=9, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28160
17/03/15 10:00:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=40992 lastFlushOffset=28183 createNewBlock=false
17/03/15 10:00:15 DEBUG DFSClient: Queued packet 9
17/03/15 10:00:15 DEBUG DFSClient: Waiting for ack for: 9
17/03/15 10:00:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 9 offsetInBlock: 28160 lastPacketInBlock: false lastByteOffsetInBlock: 40992
17/03/15 10:00:15 DEBUG DFSClient: DFSClient seqno: 9 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
                                                                                17/03/15 10:00:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=10, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=40960
17/03/15 10:00:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=45320 lastFlushOffset=40992 createNewBlock=false
17/03/15 10:00:16 DEBUG DFSClient: Queued packet 10
17/03/15 10:00:16 DEBUG DFSClient: Waiting for ack for: 10
17/03/15 10:00:16 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 10 offsetInBlock: 40960 lastPacketInBlock: false lastByteOffsetInBlock: 45320
17/03/15 10:00:16 DEBUG DFSClient: DFSClient seqno: 10 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=11, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=45056
17/03/15 10:00:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=45320 lastFlushOffset=45320 createNewBlock=false
17/03/15 10:00:16 DEBUG DFSClient: Waiting for ack for: 10
17/03/15 10:00:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=12, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=45056
17/03/15 10:00:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=45320 lastFlushOffset=45320 createNewBlock=false
17/03/15 10:00:16 DEBUG DFSClient: Waiting for ack for: 10
[Stage 7:====================================================>     (9 + 1) / 10]                                                                                17/03/15 10:00:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=13, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=45056
17/03/15 10:00:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=53984 lastFlushOffset=45320 createNewBlock=false
17/03/15 10:00:17 DEBUG DFSClient: Queued packet 13
17/03/15 10:00:17 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 13 offsetInBlock: 45056 lastPacketInBlock: false lastByteOffsetInBlock: 53984
17/03/15 10:00:17 DEBUG DFSClient: Waiting for ack for: 13
17/03/15 10:00:17 DEBUG DFSClient: DFSClient seqno: 13 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=14, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=53760
17/03/15 10:00:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=53984 lastFlushOffset=53984 createNewBlock=false
17/03/15 10:00:17 DEBUG DFSClient: Waiting for ack for: 13
17/03/15 10:00:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=15, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=53760
17/03/15 10:00:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=53984 lastFlushOffset=53984 createNewBlock=false
17/03/15 10:00:17 DEBUG DFSClient: Waiting for ack for: 13
17/03/15 10:00:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=16, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=53760
17/03/15 10:00:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=53984 lastFlushOffset=53984 createNewBlock=false
17/03/15 10:00:17 DEBUG DFSClient: Waiting for ack for: 13
17/03/15 10:00:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=17, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=53760
17/03/15 10:00:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=58667 lastFlushOffset=53984 createNewBlock=false
17/03/15 10:00:17 DEBUG DFSClient: Queued packet 17
17/03/15 10:00:17 DEBUG DFSClient: Waiting for ack for: 17
17/03/15 10:00:17 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 17 offsetInBlock: 53760 lastPacketInBlock: false lastByteOffsetInBlock: 58667
17/03/15 10:00:17 DEBUG DFSClient: DFSClient seqno: 17 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 11:>                                                        (0 + 4) / 10][Stage 11:======================>                                  (4 + 4) / 10][Stage 11:=============================================>           (8 + 2) / 10]17/03/15 10:00:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=18, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=58368
17/03/15 10:00:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=68968 lastFlushOffset=58667 createNewBlock=false
17/03/15 10:00:19 DEBUG DFSClient: Queued packet 18
17/03/15 10:00:19 DEBUG DFSClient: Waiting for ack for: 18
17/03/15 10:00:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 18 offsetInBlock: 58368 lastPacketInBlock: false lastByteOffsetInBlock: 68968
17/03/15 10:00:19 DEBUG DFSClient: DFSClient seqno: 18 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
                                                                                17/03/15 10:00:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=19, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=68608
17/03/15 10:00:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=73617 lastFlushOffset=68968 createNewBlock=false
17/03/15 10:00:19 DEBUG DFSClient: Queued packet 19
17/03/15 10:00:19 DEBUG DFSClient: Waiting for ack for: 19
17/03/15 10:00:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 19 offsetInBlock: 68608 lastPacketInBlock: false lastByteOffsetInBlock: 73617
17/03/15 10:00:19 DEBUG DFSClient: DFSClient seqno: 19 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=20, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=73216
17/03/15 10:00:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=73617 lastFlushOffset=73617 createNewBlock=false
17/03/15 10:00:19 DEBUG DFSClient: Waiting for ack for: 19
17/03/15 10:00:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=21, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=73216
17/03/15 10:00:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=78164 lastFlushOffset=73617 createNewBlock=false
17/03/15 10:00:19 DEBUG DFSClient: Queued packet 21
17/03/15 10:00:19 DEBUG DFSClient: Waiting for ack for: 21
17/03/15 10:00:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 21 offsetInBlock: 73216 lastPacketInBlock: false lastByteOffsetInBlock: 78164
17/03/15 10:00:19 DEBUG DFSClient: DFSClient seqno: 21 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=22, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=77824
17/03/15 10:00:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=82692 lastFlushOffset=78164 createNewBlock=false
17/03/15 10:00:20 DEBUG DFSClient: Queued packet 22
17/03/15 10:00:20 DEBUG DFSClient: Waiting for ack for: 22
17/03/15 10:00:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 22 offsetInBlock: 77824 lastPacketInBlock: false lastByteOffsetInBlock: 82692
17/03/15 10:00:20 DEBUG DFSClient: DFSClient seqno: 22 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=23, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=82432
17/03/15 10:00:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=92057 lastFlushOffset=82692 createNewBlock=false
17/03/15 10:00:20 DEBUG DFSClient: Queued packet 23
17/03/15 10:00:20 DEBUG DFSClient: Waiting for ack for: 23
17/03/15 10:00:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 23 offsetInBlock: 82432 lastPacketInBlock: false lastByteOffsetInBlock: 92057
17/03/15 10:00:20 DEBUG DFSClient: DFSClient seqno: 23 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=24, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=91648
17/03/15 10:00:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=92057 lastFlushOffset=92057 createNewBlock=false
17/03/15 10:00:20 DEBUG DFSClient: Waiting for ack for: 23
17/03/15 10:00:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=25, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=91648
17/03/15 10:00:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=92057 lastFlushOffset=92057 createNewBlock=false
17/03/15 10:00:20 DEBUG DFSClient: Waiting for ack for: 23
17/03/15 10:00:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=26, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=91648
17/03/15 10:00:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=92057 lastFlushOffset=92057 createNewBlock=false
17/03/15 10:00:20 DEBUG DFSClient: Waiting for ack for: 23
17/03/15 10:00:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=27, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=91648
17/03/15 10:00:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=96939 lastFlushOffset=92057 createNewBlock=false
17/03/15 10:00:20 DEBUG DFSClient: Queued packet 27
17/03/15 10:00:20 DEBUG DFSClient: Waiting for ack for: 27
17/03/15 10:00:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 27 offsetInBlock: 91648 lastPacketInBlock: false lastByteOffsetInBlock: 96939
17/03/15 10:00:20 DEBUG DFSClient: DFSClient seqno: 27 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 24:>                                                        (0 + 4) / 10][Stage 24:=====>                                                   (1 + 4) / 10][Stage 24:======================>                                  (4 + 4) / 10][Stage 24:==================================>                      (6 + 4) / 10][Stage 24:=============================================>           (8 + 2) / 10]17/03/15 10:00:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=28, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=96768
17/03/15 10:00:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=101826 lastFlushOffset=96939 createNewBlock=false
17/03/15 10:00:24 DEBUG DFSClient: Queued packet 28
17/03/15 10:00:24 DEBUG DFSClient: Waiting for ack for: 28
17/03/15 10:00:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 28 offsetInBlock: 96768 lastPacketInBlock: false lastByteOffsetInBlock: 101826
17/03/15 10:00:24 DEBUG DFSClient: DFSClient seqno: 28 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 25:=============================================>           (8 + 2) / 10]                                                                                17/03/15 10:00:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=29, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=101376
17/03/15 10:00:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=111720 lastFlushOffset=101826 createNewBlock=false
17/03/15 10:00:25 DEBUG DFSClient: Queued packet 29
17/03/15 10:00:25 DEBUG DFSClient: Waiting for ack for: 29
17/03/15 10:00:25 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 29 offsetInBlock: 101376 lastPacketInBlock: false lastByteOffsetInBlock: 111720
17/03/15 10:00:25 DEBUG DFSClient: DFSClient seqno: 29 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=30, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=111616
17/03/15 10:00:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=111720 lastFlushOffset=111720 createNewBlock=false
17/03/15 10:00:25 DEBUG DFSClient: Waiting for ack for: 29
17/03/15 10:00:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=31, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=111616
17/03/15 10:00:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=116399 lastFlushOffset=111720 createNewBlock=false
17/03/15 10:00:25 DEBUG DFSClient: Queued packet 31
17/03/15 10:00:25 DEBUG DFSClient: Waiting for ack for: 31
17/03/15 10:00:25 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 31 offsetInBlock: 111616 lastPacketInBlock: false lastByteOffsetInBlock: 116399
17/03/15 10:00:25 DEBUG DFSClient: DFSClient seqno: 31 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 32:======================>                                  (4 + 4) / 10][Stage 32:==================================>                      (6 + 4) / 10][Stage 32:=======================================>                 (7 + 3) / 10][Stage 32:=============================================>           (8 + 2) / 10][Stage 32:===================================================>     (9 + 1) / 10]17/03/15 10:00:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=32, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=116224
17/03/15 10:00:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=120736 lastFlushOffset=116399 createNewBlock=false
17/03/15 10:00:27 DEBUG DFSClient: Queued packet 32
17/03/15 10:00:27 DEBUG DFSClient: Waiting for ack for: 32
17/03/15 10:00:27 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 32 offsetInBlock: 116224 lastPacketInBlock: false lastByteOffsetInBlock: 120736
17/03/15 10:00:27 DEBUG DFSClient: DFSClient seqno: 32 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 33:>                                                        (0 + 4) / 10][Stage 33:=====>                                                   (1 + 4) / 10][Stage 33:===========>                                             (2 + 4) / 10][Stage 33:============================>                            (5 + 4) / 10][Stage 33:==================================>                      (6 + 4) / 10][Stage 33:=======================================>                 (7 + 3) / 10][Stage 33:===================================================>     (9 + 1) / 10]                                                                                17/03/15 10:00:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=33, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=120320
17/03/15 10:00:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=134865 lastFlushOffset=120736 createNewBlock=false
17/03/15 10:00:31 DEBUG DFSClient: Queued packet 33
17/03/15 10:00:31 DEBUG DFSClient: Waiting for ack for: 33
17/03/15 10:00:31 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 33 offsetInBlock: 120320 lastPacketInBlock: false lastByteOffsetInBlock: 134865
17/03/15 10:00:31 DEBUG DFSClient: DFSClient seqno: 33 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:00:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=34, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=134656
17/03/15 10:00:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=134865 lastFlushOffset=134865 createNewBlock=false
17/03/15 10:00:31 DEBUG DFSClient: Waiting for ack for: 33
17/03/15 10:00:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=35, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=134656
17/03/15 10:00:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=134865 lastFlushOffset=134865 createNewBlock=false
17/03/15 10:00:31 DEBUG DFSClient: Waiting for ack for: 33
17/03/15 10:00:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=36, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=134656
17/03/15 10:00:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=134865 lastFlushOffset=134865 createNewBlock=false
17/03/15 10:00:31 DEBUG DFSClient: Waiting for ack for: 33
17/03/15 10:00:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=37, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=134656
17/03/15 10:00:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=139162 lastFlushOffset=134865 createNewBlock=false
17/03/15 10:00:31 DEBUG DFSClient: Queued packet 37
17/03/15 10:00:31 DEBUG DFSClient: Waiting for ack for: 37
17/03/15 10:00:31 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 37 offsetInBlock: 134656 lastPacketInBlock: false lastByteOffsetInBlock: 139162
17/03/15 10:00:31 DEBUG DFSClient: DFSClient seqno: 37 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 41:>                                                        (0 + 4) / 10]17/03/15 10:00:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:00:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:00:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:00:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #9
17/03/15 10:00:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #9
17/03/15 10:00:32 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:00:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:00:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:00:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:00:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:01:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:01:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:01:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:01:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #10
17/03/15 10:01:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #10
17/03/15 10:01:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:01:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:01:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 41:=====>                                                   (1 + 4) / 10][Stage 41:=================>                                       (3 + 4) / 10]17/03/15 10:01:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:01:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:======================>                                  (4 + 4) / 10]17/03/15 10:01:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:01:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:01:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:01:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #11
17/03/15 10:01:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #11
17/03/15 10:01:32 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:01:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:01:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 41:============================>                            (5 + 4) / 10][Stage 41:==================================>                      (6 + 4) / 10][Stage 41:=======================================>                 (7 + 3) / 10][Stage 41:=============================================>           (8 + 2) / 10]17/03/15 10:01:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:01:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:===================================================>     (9 + 1) / 10]17/03/15 10:01:43 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=38, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=138752
17/03/15 10:01:43 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=148015 lastFlushOffset=139162 createNewBlock=false
17/03/15 10:01:43 DEBUG DFSClient: Queued packet 38
17/03/15 10:01:43 DEBUG DFSClient: Waiting for ack for: 38
17/03/15 10:01:43 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 38 offsetInBlock: 138752 lastPacketInBlock: false lastByteOffsetInBlock: 148015
17/03/15 10:01:43 WARN DFSClient: Slow ReadProcessor read fields took 71541ms (threshold=30000ms); ack: seqno: 38 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 42:>                                                        (0 + 4) / 10][Stage 42:=================>                                       (3 + 4) / 10][Stage 42:======================>                                  (4 + 4) / 10][Stage 42:============================>                            (5 + 4) / 10][Stage 42:==================================>                      (6 + 4) / 10][Stage 42:=======================================>                 (7 + 3) / 10][Stage 42:=============================================>           (8 + 2) / 10][Stage 42:===================================================>     (9 + 1) / 10]                                                                                17/03/15 10:01:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=39, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=147968
17/03/15 10:01:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=157149 lastFlushOffset=148015 createNewBlock=false
17/03/15 10:01:54 DEBUG DFSClient: Queued packet 39
17/03/15 10:01:54 DEBUG DFSClient: Waiting for ack for: 39
17/03/15 10:01:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 39 offsetInBlock: 147968 lastPacketInBlock: false lastByteOffsetInBlock: 157149
17/03/15 10:01:54 DEBUG DFSClient: DFSClient seqno: 39 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:01:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=40, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=156672
17/03/15 10:01:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=157149 lastFlushOffset=157149 createNewBlock=false
17/03/15 10:01:54 DEBUG DFSClient: Waiting for ack for: 39
17/03/15 10:01:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=41, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=156672
17/03/15 10:01:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=164402 lastFlushOffset=157149 createNewBlock=false
17/03/15 10:01:54 DEBUG DFSClient: Queued packet 41
17/03/15 10:01:54 DEBUG DFSClient: Waiting for ack for: 41
17/03/15 10:01:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 41 offsetInBlock: 156672 lastPacketInBlock: false lastByteOffsetInBlock: 164402
17/03/15 10:01:54 DEBUG DFSClient: DFSClient seqno: 41 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 51:>                                                        (0 + 4) / 10][Stage 51:=================>                                       (3 + 4) / 10][Stage 51:======================>                                  (4 + 4) / 10][Stage 51:==================================>                      (6 + 4) / 10]17/03/15 10:02:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:02:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:02:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:02:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #12
17/03/15 10:02:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #12
17/03/15 10:02:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:02:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:02:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 51:=======================================>                 (7 + 3) / 10]17/03/15 10:02:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=42, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=164352
17/03/15 10:02:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=169430 lastFlushOffset=164402 createNewBlock=false
17/03/15 10:02:03 DEBUG DFSClient: Queued packet 42
17/03/15 10:02:03 DEBUG DFSClient: Waiting for ack for: 42
17/03/15 10:02:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 42 offsetInBlock: 164352 lastPacketInBlock: false lastByteOffsetInBlock: 169430
17/03/15 10:02:03 DEBUG DFSClient: DFSClient seqno: 42 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 52:>                                                        (0 + 4) / 10][Stage 52:=====>                                                   (1 + 4) / 10]17/03/15 10:02:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:02:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 52:===========>                                             (2 + 4) / 10][Stage 52:=================>                                       (3 + 4) / 10][Stage 52:============================>                            (5 + 4) / 10][Stage 52:==================================>                      (6 + 4) / 10][Stage 52:=======================================>                 (7 + 3) / 10]17/03/15 10:02:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=43, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=168960
[Stage 52:=============================================>           (8 + 2) / 10][Stage 52:===================================================>     (9 + 1) / 10]                                                                                17/03/15 10:02:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=191104 lastFlushOffset=169430 createNewBlock=false
17/03/15 10:02:27 DEBUG DFSClient: Queued packet 43
17/03/15 10:02:27 DEBUG DFSClient: Waiting for ack for: 43
17/03/15 10:02:27 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 43 offsetInBlock: 168960 lastPacketInBlock: false lastByteOffsetInBlock: 191104
17/03/15 10:02:27 DEBUG DFSClient: DFSClient seqno: 43 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:02:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=44, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190976
17/03/15 10:02:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=191104 lastFlushOffset=191104 createNewBlock=false
17/03/15 10:02:27 DEBUG DFSClient: Waiting for ack for: 43
17/03/15 10:02:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=45, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190976
17/03/15 10:02:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=191104 lastFlushOffset=191104 createNewBlock=false
17/03/15 10:02:27 DEBUG DFSClient: Waiting for ack for: 43
17/03/15 10:02:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=46, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190976
17/03/15 10:02:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=191104 lastFlushOffset=191104 createNewBlock=false
17/03/15 10:02:27 DEBUG DFSClient: Waiting for ack for: 43
17/03/15 10:02:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=47, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190976
17/03/15 10:02:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=195029 lastFlushOffset=191104 createNewBlock=false
17/03/15 10:02:27 DEBUG DFSClient: Queued packet 47
17/03/15 10:02:27 DEBUG DFSClient: Waiting for ack for: 47
17/03/15 10:02:27 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 47 offsetInBlock: 190976 lastPacketInBlock: false lastByteOffsetInBlock: 195029
17/03/15 10:02:27 DEBUG DFSClient: DFSClient seqno: 47 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 62:>                                                        (0 + 4) / 10]17/03/15 10:02:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:02:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:02:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:02:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #13
17/03/15 10:02:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #13
17/03/15 10:02:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:02:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:02:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 62:=====>                                                   (1 + 4) / 10][Stage 62:===========>                                             (2 + 4) / 10][Stage 62:=================>                                       (3 + 4) / 10][Stage 62:=================>                                       (3 + 5) / 10][Stage 62:======================>                                  (4 + 4) / 10][Stage 62:============================>                            (5 + 4) / 10]17/03/15 10:02:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:02:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 62:==================================>                      (6 + 4) / 10][Stage 62:=======================================>                 (7 + 3) / 10][Stage 62:=============================================>           (8 + 2) / 10][Stage 62:===================================================>     (9 + 1) / 10]17/03/15 10:02:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=48, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=194560
17/03/15 10:02:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=203165 lastFlushOffset=195029 createNewBlock=false
17/03/15 10:02:45 DEBUG DFSClient: Queued packet 48
17/03/15 10:02:45 DEBUG DFSClient: Waiting for ack for: 48
17/03/15 10:02:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 48 offsetInBlock: 194560 lastPacketInBlock: false lastByteOffsetInBlock: 203165
17/03/15 10:02:45 DEBUG DFSClient: DFSClient seqno: 48 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 63:>                                                        (0 + 4) / 10][Stage 63:=====>                                                   (1 + 4) / 10][Stage 63:===========>                                             (2 + 4) / 10][Stage 63:=================>                                       (3 + 4) / 10][Stage 63:======================>                                  (4 + 4) / 10][Stage 63:============================>                            (5 + 4) / 10][Stage 63:==================================>                      (6 + 4) / 10][Stage 63:=======================================>                 (7 + 3) / 10][Stage 63:=============================================>           (8 + 2) / 10][Stage 63:===================================================>     (9 + 1) / 10]                                                                                17/03/15 10:02:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=49, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=202752
17/03/15 10:02:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=214832 lastFlushOffset=203165 createNewBlock=false
17/03/15 10:02:56 DEBUG DFSClient: Queued packet 49
17/03/15 10:02:56 DEBUG DFSClient: Waiting for ack for: 49
17/03/15 10:02:56 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 49 offsetInBlock: 202752 lastPacketInBlock: false lastByteOffsetInBlock: 214832
17/03/15 10:02:56 DEBUG DFSClient: DFSClient seqno: 49 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:02:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=50, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=214528
17/03/15 10:02:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=214832 lastFlushOffset=214832 createNewBlock=false
17/03/15 10:02:56 DEBUG DFSClient: Waiting for ack for: 49
17/03/15 10:02:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=51, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=214528
17/03/15 10:02:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=222439 lastFlushOffset=214832 createNewBlock=false
17/03/15 10:02:56 DEBUG DFSClient: Queued packet 51
17/03/15 10:02:56 DEBUG DFSClient: Waiting for ack for: 51
17/03/15 10:02:56 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 51 offsetInBlock: 214528 lastPacketInBlock: false lastByteOffsetInBlock: 222439
17/03/15 10:02:56 DEBUG DFSClient: DFSClient seqno: 51 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 74:>                                                        (0 + 4) / 10][Stage 74:===========>                                             (2 + 4) / 10][Stage 74:======================>                                  (4 + 4) / 10][Stage 74:=============================================>           (8 + 2) / 10]17/03/15 10:03:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:03:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:03:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:03:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #14
17/03/15 10:03:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #14
17/03/15 10:03:02 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:03:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:03:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:03:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=52, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=222208
17/03/15 10:03:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=227558 lastFlushOffset=222439 createNewBlock=false
17/03/15 10:03:02 DEBUG DFSClient: Queued packet 52
17/03/15 10:03:02 DEBUG DFSClient: Waiting for ack for: 52
17/03/15 10:03:02 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 52 offsetInBlock: 222208 lastPacketInBlock: false lastByteOffsetInBlock: 227558
17/03/15 10:03:03 DEBUG DFSClient: DFSClient seqno: 52 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 75:>                                                        (0 + 4) / 10]17/03/15 10:03:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:03:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 75:===========>                                             (2 + 4) / 10][Stage 75:=================>                                       (3 + 4) / 10][Stage 75:======================>                                  (4 + 4) / 10][Stage 75:============================>                            (5 + 4) / 10][Stage 75:==================================>                      (6 + 4) / 10]17/03/15 10:03:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:03:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:03:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:03:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #15
17/03/15 10:03:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #15
17/03/15 10:03:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:03:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:03:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 75:=======================================>                 (7 + 3) / 10]17/03/15 10:03:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=53, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=227328
[Stage 75:=============================================>           (8 + 2) / 10][Stage 75:===================================================>     (9 + 1) / 10]                                                                                17/03/15 10:03:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=248122 lastFlushOffset=227558 createNewBlock=false
17/03/15 10:03:38 DEBUG DFSClient: Queued packet 53
17/03/15 10:03:38 DEBUG DFSClient: Waiting for ack for: 53
17/03/15 10:03:38 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 53 offsetInBlock: 227328 lastPacketInBlock: false lastByteOffsetInBlock: 248122
17/03/15 10:03:38 WARN DFSClient: Slow ReadProcessor read fields took 35707ms (threshold=30000ms); ack: seqno: 53 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/03/15 10:03:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=54, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=247808
17/03/15 10:03:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=248122 lastFlushOffset=248122 createNewBlock=false
17/03/15 10:03:38 DEBUG DFSClient: Waiting for ack for: 53
17/03/15 10:03:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=55, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=247808
17/03/15 10:03:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=248122 lastFlushOffset=248122 createNewBlock=false
17/03/15 10:03:38 DEBUG DFSClient: Waiting for ack for: 53
17/03/15 10:03:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=56, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=247808
17/03/15 10:03:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=248122 lastFlushOffset=248122 createNewBlock=false
17/03/15 10:03:38 DEBUG DFSClient: Waiting for ack for: 53
17/03/15 10:03:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=57, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=247808
17/03/15 10:03:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=256197 lastFlushOffset=248122 createNewBlock=false
17/03/15 10:03:38 DEBUG DFSClient: Queued packet 57
17/03/15 10:03:38 DEBUG DFSClient: Waiting for ack for: 57
17/03/15 10:03:38 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 57 offsetInBlock: 247808 lastPacketInBlock: false lastByteOffsetInBlock: 256197
17/03/15 10:03:38 DEBUG DFSClient: DFSClient seqno: 57 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/15 10:03:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:03:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10]17/03/15 10:04:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:04:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:04:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:04:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #16
17/03/15 10:04:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #16
17/03/15 10:04:02 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:04:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:04:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 87:===========>                                             (2 + 4) / 10][Stage 87:=================>                                       (3 + 4) / 10][Stage 87:======================>                                  (4 + 4) / 10][Stage 87:============================>                            (5 + 4) / 10][Stage 87:==================================>                      (6 + 4) / 10]17/03/15 10:04:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:04:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=======================================>                 (7 + 3) / 10][Stage 87:=============================================>           (8 + 2) / 10][Stage 87:===================================================>     (9 + 1) / 10]17/03/15 10:04:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=58, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=256000
17/03/15 10:04:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=269272 lastFlushOffset=256197 createNewBlock=false
17/03/15 10:04:16 DEBUG DFSClient: Queued packet 58
17/03/15 10:04:16 DEBUG DFSClient: Waiting for ack for: 58
17/03/15 10:04:16 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 58 offsetInBlock: 256000 lastPacketInBlock: false lastByteOffsetInBlock: 269272
17/03/15 10:04:16 WARN DFSClient: Slow ReadProcessor read fields took 37344ms (threshold=30000ms); ack: seqno: 58 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 88:>                                                        (0 + 4) / 10][Stage 88:===========>                                             (2 + 4) / 10][Stage 88:=================>                                       (3 + 4) / 10][Stage 88:======================>                                  (4 + 4) / 10]17/03/15 10:04:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:04:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:04:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:04:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #17
17/03/15 10:04:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #17
17/03/15 10:04:32 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:04:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:04:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 88:============================>                            (5 + 4) / 10][Stage 88:==================================>                      (6 + 4) / 10][Stage 88:=======================================>                 (7 + 3) / 10][Stage 88:===================================================>     (9 + 1) / 10]17/03/15 10:04:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:04:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:04:43 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=59, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=268800
17/03/15 10:04:43 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=282276 lastFlushOffset=269272 createNewBlock=false
17/03/15 10:04:43 DEBUG DFSClient: Queued packet 59
17/03/15 10:04:43 DEBUG DFSClient: Waiting for ack for: 59
17/03/15 10:04:43 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 59 offsetInBlock: 268800 lastPacketInBlock: false lastByteOffsetInBlock: 282276
17/03/15 10:04:43 DEBUG DFSClient: DFSClient seqno: 59 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 89:>                                                        (0 + 4) / 10]17/03/15 10:05:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:05:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:05:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:05:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #18
17/03/15 10:05:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #18
17/03/15 10:05:02 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:05:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:05:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 89:===========>                                             (2 + 4) / 10][Stage 89:=================>                                       (3 + 4) / 10][Stage 89:======================>                                  (4 + 4) / 10]17/03/15 10:05:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:05:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:05:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:05:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:05:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:05:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #19
17/03/15 10:05:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #19
17/03/15 10:05:32 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:05:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:05:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:05:34 WARN TaskSetManager: Lost task 4.0 in stage 89.0 (TID 254, 172.21.15.173, executor 0): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

17/03/15 10:05:40 WARN TaskSetManager: Lost task 6.0 in stage 89.0 (TID 256, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 52443, None), shuffleId=11, mapId=0, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/2c/shuffle_11_0_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1159)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1159)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2056)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2056)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/2c/shuffle_11_0_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	... 6 more

)
17/03/15 10:05:40 WARN TaskSetManager: Lost task 5.0 in stage 89.0 (TID 255, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 52443, None), shuffleId=11, mapId=0, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/30/shuffle_11_0_0.data, offset=49622764, length=9924480}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1159)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1159)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2056)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2056)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/30/shuffle_11_0_0.data, offset=49622764, length=9924480}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 24 more
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/30/shuffle_11_0_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 25 more

)
17/03/15 10:05:40 WARN TaskSetManager: Lost task 7.0 in stage 89.0 (TID 257, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 52443, None), shuffleId=11, mapId=8, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/38/shuffle_11_8_0.data, offset=69468302, length=9924076}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1159)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1159)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2056)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2056)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/38/shuffle_11_8_0.data, offset=69468302, length=9924076}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 24 more
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/38/shuffle_11_8_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 25 more

)
17/03/15 10:05:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=60, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=282112
17/03/15 10:05:40 WARN TaskSetManager: Lost task 8.0 in stage 89.0 (TID 258, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 52443, None), shuffleId=2, mapId=1, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-646794c1-78d8-4c77-82a0-8408e135a0c5/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 36 more

)
17/03/15 10:05:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=295703 lastFlushOffset=282276 createNewBlock=false
17/03/15 10:05:40 DEBUG DFSClient: Queued packet 60
17/03/15 10:05:40 DEBUG DFSClient: Waiting for ack for: 60
17/03/15 10:05:40 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 60 offsetInBlock: 282112 lastPacketInBlock: false lastByteOffsetInBlock: 295703
17/03/15 10:05:40 WARN TaskSetManager: Lost task 4.1 in stage 89.0 (TID 259, 172.21.15.173, executor 0): org.apache.spark.SparkException: Block rdd_14_4 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:05:40 WARN DFSClient: Slow ReadProcessor read fields took 56297ms (threshold=30000ms); ack: seqno: 60 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/03/15 10:05:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=61, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=295424
17/03/15 10:05:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=295703 lastFlushOffset=295703 createNewBlock=false
17/03/15 10:05:40 DEBUG DFSClient: Waiting for ack for: 60
17/03/15 10:05:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=62, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=295424
17/03/15 10:05:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=299950 lastFlushOffset=295703 createNewBlock=false
17/03/15 10:05:40 DEBUG DFSClient: Queued packet 62
17/03/15 10:05:40 DEBUG DFSClient: Waiting for ack for: 62
17/03/15 10:05:40 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 62 offsetInBlock: 295424 lastPacketInBlock: false lastByteOffsetInBlock: 299950
17/03/15 10:05:40 DEBUG DFSClient: DFSClient seqno: 62 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:05:40 WARN TaskSetManager: Lost task 0.0 in stage 76.0 (TID 261, 172.21.15.173, executor 0): org.apache.spark.SparkException: Block rdd_3_0 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:05:40 WARN TaskSetManager: Lost task 9.0 in stage 76.0 (TID 263, 172.21.15.173, executor 0): org.apache.spark.SparkException: Block rdd_3_9 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:05:40 WARN TaskSetManager: Lost task 4.0 in stage 76.0 (TID 262, 172.21.15.173, executor 0): org.apache.spark.SparkException: Block rdd_3_4 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:05:40 WARN TaskSetManager: Lost task 0.1 in stage 76.0 (TID 264, 172.21.15.173, executor 0): java.io.IOException: org.apache.spark.SparkException: Block broadcast_0 was not found even though it's read-locked
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1276)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:147)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:216)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:212)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:102)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.graphx.GraphLoader$$anonfun$1.apply(GraphLoader.scala:77)
	at org.apache.spark.graphx.GraphLoader$$anonfun$1.apply(GraphLoader.scala:75)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Block broadcast_0 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1269)
	... 48 more

17/03/15 10:05:40 WARN TaskSetManager: Lost task 4.1 in stage 76.0 (TID 266, 172.21.15.173, executor 0): java.io.IOException: org.apache.spark.SparkException: Block broadcast_0_piece0 was not found even though it's read-locked
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1276)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:147)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:216)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:212)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:102)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.graphx.GraphLoader$$anonfun$1.apply(GraphLoader.scala:77)
	at org.apache.spark.graphx.GraphLoader$$anonfun$1.apply(GraphLoader.scala:75)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Block broadcast_0_piece0 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doGetLocalBytes(BlockManager.scala:535)
	at org.apache.spark.storage.BlockManager$$anonfun$getLocalBytes$2.apply(BlockManager.scala:498)
	at org.apache.spark.storage.BlockManager$$anonfun$getLocalBytes$2.apply(BlockManager.scala:498)
	at scala.Option.map(Option.scala:146)
	at org.apache.spark.storage.BlockManager.getLocalBytes(BlockManager.scala:498)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:156)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1269)
	... 48 more

[Stage 76:>                                                        (0 + 3) / 10]17/03/15 10:05:41 ERROR TaskSchedulerImpl: Lost executor 0 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:05:41 WARN TaskSetManager: Lost task 9.0 in stage 89.0 (TID 260, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:05:41 WARN TaskSetManager: Lost task 9.1 in stage 76.0 (TID 265, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:05:41 WARN TaskSetManager: Lost task 4.2 in stage 76.0 (TID 268, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:05:41 WARN TaskSetManager: Lost task 0.2 in stage 76.0 (TID 267, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:05:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=63, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=299520
17/03/15 10:05:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=308170 lastFlushOffset=299950 createNewBlock=false
17/03/15 10:05:41 DEBUG DFSClient: Queued packet 63
17/03/15 10:05:41 DEBUG DFSClient: Waiting for ack for: 63
17/03/15 10:05:41 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 63 offsetInBlock: 299520 lastPacketInBlock: false lastByteOffsetInBlock: 308170
[Stage 76:>                                                        (0 + 0) / 10]17/03/15 10:05:41 DEBUG DFSClient: DFSClient seqno: 63 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:05:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=64, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=307712
17/03/15 10:05:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=308170 lastFlushOffset=308170 createNewBlock=false
17/03/15 10:05:41 DEBUG DFSClient: Waiting for ack for: 63
17/03/15 10:05:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:05:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:05:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=65, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=307712
17/03/15 10:05:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=308170 lastFlushOffset=308170 createNewBlock=false
17/03/15 10:05:51 DEBUG DFSClient: Waiting for ack for: 63
[Stage 76:>                                                        (0 + 3) / 10]17/03/15 10:05:52 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=66, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=307712
17/03/15 10:05:52 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=308170 lastFlushOffset=308170 createNewBlock=false
17/03/15 10:05:52 DEBUG DFSClient: Waiting for ack for: 63
[Stage 76:>                                                        (0 + 4) / 10][Stage 76:===========>                                             (2 + 4) / 10][Stage 76:=================>                                       (3 + 4) / 10][Stage 76:======================>                                  (4 + 4) / 10]17/03/15 10:06:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:06:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:06:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:06:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #20
17/03/15 10:06:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #20
17/03/15 10:06:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:06:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:06:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 76:============================>                            (5 + 4) / 10][Stage 76:==================================>                      (6 + 4) / 10][Stage 76:=======================================>                 (7 + 3) / 10][Stage 76:=============================================>           (8 + 2) / 10][Stage 76:===================================================>     (9 + 1) / 10]17/03/15 10:06:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=67, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=307712
17/03/15 10:06:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=316136 lastFlushOffset=308170 createNewBlock=false
17/03/15 10:06:07 DEBUG DFSClient: Queued packet 67
17/03/15 10:06:07 DEBUG DFSClient: Waiting for ack for: 67
17/03/15 10:06:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 67 offsetInBlock: 307712 lastPacketInBlock: false lastByteOffsetInBlock: 316136
17/03/15 10:06:07 DEBUG DFSClient: DFSClient seqno: 67 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10]17/03/15 10:06:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:06:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10]17/03/15 10:06:21 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=68, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=315904
17/03/15 10:06:21 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=324886 lastFlushOffset=316136 createNewBlock=false
17/03/15 10:06:21 DEBUG DFSClient: Queued packet 68
17/03/15 10:06:21 DEBUG DFSClient: Waiting for ack for: 68
17/03/15 10:06:21 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 68 offsetInBlock: 315904 lastPacketInBlock: false lastByteOffsetInBlock: 324886
17/03/15 10:06:21 DEBUG DFSClient: DFSClient seqno: 68 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:06:21 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=69, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=324608
17/03/15 10:06:21 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=333526 lastFlushOffset=324886 createNewBlock=false
17/03/15 10:06:21 DEBUG DFSClient: Queued packet 69
17/03/15 10:06:21 DEBUG DFSClient: Waiting for ack for: 69
17/03/15 10:06:21 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 69 offsetInBlock: 324608 lastPacketInBlock: false lastByteOffsetInBlock: 333526
17/03/15 10:06:21 DEBUG DFSClient: DFSClient seqno: 69 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                        (0 + 4) / 10][Stage 79:======================>                                  (4 + 4) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/15 10:06:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=70, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=333312
17/03/15 10:06:23 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=338819 lastFlushOffset=333526 createNewBlock=false
17/03/15 10:06:23 DEBUG DFSClient: Queued packet 70
17/03/15 10:06:23 DEBUG DFSClient: Waiting for ack for: 70
17/03/15 10:06:23 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 70 offsetInBlock: 333312 lastPacketInBlock: false lastByteOffsetInBlock: 338819
17/03/15 10:06:23 DEBUG DFSClient: DFSClient seqno: 70 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:=============================================>           (8 + 2) / 10][Stage 80:===================================================>     (9 + 1) / 10]17/03/15 10:06:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=71, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=338432
17/03/15 10:06:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=349681 lastFlushOffset=338819 createNewBlock=false
17/03/15 10:06:24 DEBUG DFSClient: Queued packet 71
17/03/15 10:06:24 DEBUG DFSClient: Waiting for ack for: 71
17/03/15 10:06:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 71 offsetInBlock: 338432 lastPacketInBlock: false lastByteOffsetInBlock: 349681
17/03/15 10:06:24 DEBUG DFSClient: DFSClient seqno: 71 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/15 10:06:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=72, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=349184
17/03/15 10:06:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=355288 lastFlushOffset=349681 createNewBlock=false
17/03/15 10:06:27 DEBUG DFSClient: Queued packet 72
17/03/15 10:06:27 DEBUG DFSClient: Waiting for ack for: 72
17/03/15 10:06:27 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 72 offsetInBlock: 349184 lastPacketInBlock: false lastByteOffsetInBlock: 355288
17/03/15 10:06:27 DEBUG DFSClient: DFSClient seqno: 72 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:=============================================>           (8 + 2) / 10]17/03/15 10:06:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=73, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=354816
17/03/15 10:06:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=366883 lastFlushOffset=355288 createNewBlock=false
17/03/15 10:06:29 DEBUG DFSClient: Queued packet 73
17/03/15 10:06:29 DEBUG DFSClient: Waiting for ack for: 73
17/03/15 10:06:29 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 73 offsetInBlock: 354816 lastPacketInBlock: false lastByteOffsetInBlock: 366883
17/03/15 10:06:30 DEBUG DFSClient: DFSClient seqno: 73 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/03/15 10:06:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:06:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:06:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:06:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #21
17/03/15 10:06:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #21
17/03/15 10:06:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:06:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:06:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:06:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:06:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===========>                                             (2 + 4) / 10][Stage 83:=================>                                       (3 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10][Stage 83:============================>                            (5 + 4) / 10][Stage 83:==================================>                      (6 + 4) / 10][Stage 83:=======================================>                 (7 + 3) / 10][Stage 83:=============================================>           (8 + 2) / 10]17/03/15 10:07:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:07:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:07:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:07:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #22
17/03/15 10:07:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #22
17/03/15 10:07:02 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:07:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:07:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 83:===================================================>     (9 + 1) / 10]17/03/15 10:07:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=74, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=366592
17/03/15 10:07:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=372413 lastFlushOffset=366883 createNewBlock=false
17/03/15 10:07:06 DEBUG DFSClient: Queued packet 74
17/03/15 10:07:06 DEBUG DFSClient: Waiting for ack for: 74
17/03/15 10:07:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 74 offsetInBlock: 366592 lastPacketInBlock: false lastByteOffsetInBlock: 372413
17/03/15 10:07:06 WARN DFSClient: Slow ReadProcessor read fields took 36097ms (threshold=30000ms); ack: seqno: 74 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                        (0 + 4) / 10]17/03/15 10:07:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:07:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:===========>                                             (2 + 4) / 10][Stage 84:=================>                                       (3 + 4) / 10][Stage 84:======================>                                  (4 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10][Stage 84:===================================================>     (9 + 1) / 10]17/03/15 10:07:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=75, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=372224
17/03/15 10:07:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=383538 lastFlushOffset=372413 createNewBlock=false
17/03/15 10:07:25 DEBUG DFSClient: Queued packet 75
17/03/15 10:07:25 DEBUG DFSClient: Waiting for ack for: 75
17/03/15 10:07:25 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 75 offsetInBlock: 372224 lastPacketInBlock: false lastByteOffsetInBlock: 383538
17/03/15 10:07:25 DEBUG DFSClient: DFSClient seqno: 75 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10]17/03/15 10:07:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:07:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:07:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:07:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #23
17/03/15 10:07:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #23
17/03/15 10:07:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:07:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:07:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 85:=====>                                                   (1 + 4) / 10][Stage 85:=================>                                       (3 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10][Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10]17/03/15 10:07:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:07:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 85:===================================================>     (9 + 1) / 10]17/03/15 10:07:43 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=76, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=383488
17/03/15 10:07:43 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=389079 lastFlushOffset=383538 createNewBlock=false
17/03/15 10:07:43 DEBUG DFSClient: Queued packet 76
17/03/15 10:07:43 DEBUG DFSClient: Waiting for ack for: 76
17/03/15 10:07:43 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 76 offsetInBlock: 383488 lastPacketInBlock: false lastByteOffsetInBlock: 389079
17/03/15 10:07:43 DEBUG DFSClient: DFSClient seqno: 76 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10][Stage 86:===========>                                             (2 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10]17/03/15 10:08:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:08:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:08:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:08:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #24
17/03/15 10:08:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #24
17/03/15 10:08:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:08:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:08:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 86:============================>                            (5 + 4) / 10][Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=======================================>                 (7 + 3) / 10][Stage 86:=============================================>           (8 + 2) / 10][Stage 86:===================================================>     (9 + 1) / 10]17/03/15 10:08:11 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=77, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=388608
17/03/15 10:08:11 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=399282 lastFlushOffset=389079 createNewBlock=false
17/03/15 10:08:11 DEBUG DFSClient: Queued packet 77
17/03/15 10:08:11 DEBUG DFSClient: Waiting for ack for: 77
17/03/15 10:08:11 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 77 offsetInBlock: 388608 lastPacketInBlock: false lastByteOffsetInBlock: 399282
17/03/15 10:08:12 DEBUG DFSClient: DFSClient seqno: 77 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/15 10:08:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:08:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10][Stage 87:===========>                                             (2 + 4) / 10][Stage 87:======================>                                  (4 + 4) / 10]17/03/15 10:08:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:08:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:08:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:08:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #25
17/03/15 10:08:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #25
17/03/15 10:08:32 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:08:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:08:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 87:============================>                            (5 + 4) / 10]17/03/15 10:08:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:08:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:08:55 WARN TaskSetManager: Lost task 6.0 in stage 87.1 (TID 385, 172.21.15.173, executor 1): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

17/03/15 10:08:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=78, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=398848
17/03/15 10:08:58 WARN TaskSetManager: Lost task 5.0 in stage 87.1 (TID 384, 172.21.15.173, executor 1): java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-cae6834b-472f-406a-8f92-caf2b9bc3717/0b/temp_shuffle_d3992672-c5f1-403d-a6bb-a8591881d4a1 ()
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:229)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:08:59 ERROR TaskSchedulerImpl: Lost executor 1 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:08:59 WARN TaskSetManager: Lost task 8.1 in stage 87.1 (TID 391, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:08:59 WARN TaskSetManager: Lost task 9.0 in stage 87.1 (TID 388, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:08:59 WARN TaskSetManager: Lost task 7.1 in stage 87.1 (TID 390, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:08:59 WARN TaskSetManager: Lost task 6.1 in stage 87.1 (TID 389, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:08:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=424564 lastFlushOffset=399282 createNewBlock=false
17/03/15 10:08:59 DEBUG DFSClient: Queued packet 78
17/03/15 10:08:59 DEBUG DFSClient: Waiting for ack for: 78
17/03/15 10:08:59 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 78 offsetInBlock: 398848 lastPacketInBlock: false lastByteOffsetInBlock: 424564
[Stage 87:============================>                           (5 + -5) / 10]17/03/15 10:08:59 WARN DFSClient: Slow ReadProcessor read fields took 47570ms (threshold=30000ms); ack: seqno: 78 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/03/15 10:08:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=79, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=424448
17/03/15 10:08:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=424564 lastFlushOffset=424564 createNewBlock=false
17/03/15 10:08:59 DEBUG DFSClient: Waiting for ack for: 78
17/03/15 10:09:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:09:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:09:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:09:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #26
17/03/15 10:09:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #26
17/03/15 10:09:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:09:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:09:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:09:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=80, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=424448
17/03/15 10:09:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=424564 lastFlushOffset=424564 createNewBlock=false
17/03/15 10:09:06 DEBUG DFSClient: Waiting for ack for: 78
17/03/15 10:09:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=81, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=424448
17/03/15 10:09:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=424564 lastFlushOffset=424564 createNewBlock=false
17/03/15 10:09:06 DEBUG DFSClient: Waiting for ack for: 78
[Stage 87:============================>                           (5 + -1) / 10]17/03/15 10:09:07 WARN TaskSetManager: Lost task 8.2 in stage 87.1 (TID 395, 172.21.15.173, executor 2): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:09:07 WARN TaskSetManager: Lost task 9.1 in stage 87.1 (TID 394, 172.21.15.173, executor 2): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:09:07 WARN TaskSetManager: Lost task 6.2 in stage 87.1 (TID 392, 172.21.15.173, executor 2): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=6, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:09:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=82, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=424448
17/03/15 10:09:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=429013 lastFlushOffset=424564 createNewBlock=false
17/03/15 10:09:07 DEBUG DFSClient: Queued packet 82
17/03/15 10:09:07 DEBUG DFSClient: Waiting for ack for: 82
17/03/15 10:09:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 82 offsetInBlock: 424448 lastPacketInBlock: false lastByteOffsetInBlock: 429013
17/03/15 10:09:07 WARN TaskSetManager: Lost task 7.2 in stage 87.1 (TID 393, 172.21.15.173, executor 2): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:09:07 DEBUG DFSClient: DFSClient seqno: 82 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:09:07 WARN TaskSetManager: Lost task 1.1 in stage 87.1 (TID 396, 172.21.15.173, executor 2): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=1, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
[Stage 76:>                                                        (0 + 4) / 10]17/03/15 10:09:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:09:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 76:=====>                                                   (1 + 4) / 10][Stage 76:===========>                                             (2 + 4) / 10][Stage 76:=================>                                       (3 + 4) / 10][Stage 76:======================>                                  (4 + 4) / 10][Stage 76:============================>                            (5 + 4) / 10][Stage 76:==================================>                      (6 + 4) / 10][Stage 76:=======================================>                 (7 + 3) / 10][Stage 76:=============================================>           (8 + 2) / 10][Stage 76:===================================================>     (9 + 1) / 10]17/03/15 10:09:22 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=83, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=428544
17/03/15 10:09:22 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=441639 lastFlushOffset=429013 createNewBlock=false
17/03/15 10:09:22 DEBUG DFSClient: Queued packet 83
17/03/15 10:09:22 DEBUG DFSClient: Waiting for ack for: 83
17/03/15 10:09:22 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 83 offsetInBlock: 428544 lastPacketInBlock: false lastByteOffsetInBlock: 441639
17/03/15 10:09:22 DEBUG DFSClient: DFSClient seqno: 83 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10][Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10]17/03/15 10:09:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:09:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:09:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:09:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #27
17/03/15 10:09:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #27
17/03/15 10:09:32 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:09:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:09:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:09:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=84, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=441344
17/03/15 10:09:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=450385 lastFlushOffset=441639 createNewBlock=false
17/03/15 10:09:34 DEBUG DFSClient: Queued packet 84
17/03/15 10:09:34 DEBUG DFSClient: Waiting for ack for: 84
17/03/15 10:09:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 84 offsetInBlock: 441344 lastPacketInBlock: false lastByteOffsetInBlock: 450385
17/03/15 10:09:34 DEBUG DFSClient: DFSClient seqno: 84 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:09:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=85, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=450048
17/03/15 10:09:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=459623 lastFlushOffset=450385 createNewBlock=false
17/03/15 10:09:35 DEBUG DFSClient: Queued packet 85
17/03/15 10:09:35 DEBUG DFSClient: Waiting for ack for: 85
17/03/15 10:09:35 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 85 offsetInBlock: 450048 lastPacketInBlock: false lastByteOffsetInBlock: 459623
17/03/15 10:09:35 DEBUG DFSClient: DFSClient seqno: 85 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                        (0 + 4) / 10][Stage 79:======================>                                  (4 + 4) / 10][Stage 79:=======================================>                 (7 + 3) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/15 10:09:37 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=86, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=459264
17/03/15 10:09:37 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=465018 lastFlushOffset=459623 createNewBlock=false
17/03/15 10:09:37 DEBUG DFSClient: Queued packet 86
17/03/15 10:09:37 DEBUG DFSClient: Waiting for ack for: 86
17/03/15 10:09:37 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 86 offsetInBlock: 459264 lastPacketInBlock: false lastByteOffsetInBlock: 465018
17/03/15 10:09:37 DEBUG DFSClient: DFSClient seqno: 86 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:======================>                                  (4 + 4) / 10][Stage 80:=============================================>           (8 + 2) / 10]17/03/15 10:09:37 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=87, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=464896
17/03/15 10:09:37 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=470757 lastFlushOffset=465018 createNewBlock=false
17/03/15 10:09:37 DEBUG DFSClient: Queued packet 87
17/03/15 10:09:37 DEBUG DFSClient: Waiting for ack for: 87
17/03/15 10:09:37 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 87 offsetInBlock: 464896 lastPacketInBlock: false lastByteOffsetInBlock: 470757
17/03/15 10:09:37 DEBUG DFSClient: DFSClient seqno: 87 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/15 10:09:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=88, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=470528
17/03/15 10:09:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=481471 lastFlushOffset=470757 createNewBlock=false
17/03/15 10:09:41 DEBUG DFSClient: Queued packet 88
17/03/15 10:09:41 DEBUG DFSClient: Waiting for ack for: 88
17/03/15 10:09:41 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 88 offsetInBlock: 470528 lastPacketInBlock: false lastByteOffsetInBlock: 481471
17/03/15 10:09:41 DEBUG DFSClient: DFSClient seqno: 88 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10]17/03/15 10:09:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:09:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 82:=============================================>           (8 + 2) / 10]17/03/15 10:09:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=89, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=481280
17/03/15 10:09:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=487448 lastFlushOffset=481471 createNewBlock=false
17/03/15 10:09:44 DEBUG DFSClient: Queued packet 89
17/03/15 10:09:44 DEBUG DFSClient: Waiting for ack for: 89
17/03/15 10:09:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 89 offsetInBlock: 481280 lastPacketInBlock: false lastByteOffsetInBlock: 487448
17/03/15 10:09:44 DEBUG DFSClient: DFSClient seqno: 89 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10][Stage 83:=================>                                       (3 + 4) / 10]17/03/15 10:10:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:10:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:10:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:10:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #28
17/03/15 10:10:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #28
17/03/15 10:10:02 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:10:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:10:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 83:======================>                                  (4 + 4) / 10]17/03/15 10:10:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:10:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:============================>                            (5 + 4) / 10][Stage 83:==================================>                      (6 + 4) / 10][Stage 83:=======================================>                 (7 + 3) / 10][Stage 83:=============================================>           (8 + 2) / 10][Stage 83:===================================================>     (9 + 1) / 10]17/03/15 10:10:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=90, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=487424
17/03/15 10:10:23 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=498271 lastFlushOffset=487448 createNewBlock=false
17/03/15 10:10:23 DEBUG DFSClient: Queued packet 90
17/03/15 10:10:23 DEBUG DFSClient: Waiting for ack for: 90
17/03/15 10:10:23 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 90 offsetInBlock: 487424 lastPacketInBlock: false lastByteOffsetInBlock: 498271
17/03/15 10:10:23 WARN DFSClient: Slow ReadProcessor read fields took 39389ms (threshold=30000ms); ack: seqno: 90 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                        (0 + 4) / 10][Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:===========>                                             (2 + 4) / 10][Stage 84:======================>                                  (4 + 4) / 10]17/03/15 10:10:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:10:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:10:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:10:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #29
17/03/15 10:10:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #29
17/03/15 10:10:32 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:10:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:10:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 84:==================================>                      (6 + 4) / 10][Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10]17/03/15 10:10:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=91, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=498176
17/03/15 10:10:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=509666 lastFlushOffset=498271 createNewBlock=false
17/03/15 10:10:41 DEBUG DFSClient: Queued packet 91
17/03/15 10:10:41 DEBUG DFSClient: Waiting for ack for: 91
17/03/15 10:10:41 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 91 offsetInBlock: 498176 lastPacketInBlock: false lastByteOffsetInBlock: 509666
17/03/15 10:10:41 DEBUG DFSClient: DFSClient seqno: 91 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10]17/03/15 10:10:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:10:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 85:===========>                                             (2 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10][Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10][Stage 85:===================================================>     (9 + 1) / 10]17/03/15 10:11:01 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=92, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=509440
17/03/15 10:11:01 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=515066 lastFlushOffset=509666 createNewBlock=false
17/03/15 10:11:01 DEBUG DFSClient: Queued packet 92
17/03/15 10:11:01 DEBUG DFSClient: Waiting for ack for: 92
17/03/15 10:11:01 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 92 offsetInBlock: 509440 lastPacketInBlock: false lastByteOffsetInBlock: 515066
17/03/15 10:11:01 DEBUG DFSClient: DFSClient seqno: 92 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10]17/03/15 10:11:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:11:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:11:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:11:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #30
17/03/15 10:11:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #30
17/03/15 10:11:02 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:11:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:11:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 86:===========>                                             (2 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10]17/03/15 10:11:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:11:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=======================================>                 (7 + 3) / 10][Stage 86:=============================================>           (8 + 2) / 10][Stage 86:===================================================>     (9 + 1) / 10]17/03/15 10:11:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:11:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:11:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:11:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #31
17/03/15 10:11:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #31
17/03/15 10:11:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:11:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:11:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:11:32 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=93, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=514560
17/03/15 10:11:32 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=525085 lastFlushOffset=515066 createNewBlock=false
17/03/15 10:11:32 DEBUG DFSClient: Queued packet 93
17/03/15 10:11:32 DEBUG DFSClient: Waiting for ack for: 93
17/03/15 10:11:32 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 93 offsetInBlock: 514560 lastPacketInBlock: false lastByteOffsetInBlock: 525085
17/03/15 10:11:33 WARN DFSClient: Slow ReadProcessor read fields took 31799ms (threshold=30000ms); ack: seqno: 93 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 87:>                                                        (0 + 4) / 10]17/03/15 10:11:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:11:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10]17/03/15 10:11:59 WARN TaskSetManager: Lost task 3.0 in stage 87.2 (TID 510, 172.21.15.173, executor 2): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

17/03/15 10:12:02 ERROR TaskSchedulerImpl: Lost executor 2 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:12:02 WARN TaskSetManager: Lost task 1.0 in stage 87.2 (TID 508, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:12:02 WARN TaskSetManager: Lost task 0.0 in stage 87.2 (TID 507, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:12:02 WARN TaskSetManager: Lost task 5.0 in stage 87.2 (TID 512, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:12:02 WARN TaskSetManager: Lost task 4.0 in stage 87.2 (TID 511, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:12:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=94, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=524800
17/03/15 10:12:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529815 lastFlushOffset=525085 createNewBlock=false
17/03/15 10:12:02 DEBUG DFSClient: Queued packet 94
17/03/15 10:12:02 DEBUG DFSClient: Waiting for ack for: 94
17/03/15 10:12:02 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 94 offsetInBlock: 524800 lastPacketInBlock: false lastByteOffsetInBlock: 529815
17/03/15 10:12:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:12:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:12:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:12:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #32
17/03/15 10:12:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #32
17/03/15 10:12:02 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:12:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:12:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 87:=====>                                                  (1 + -1) / 10]17/03/15 10:12:03 DEBUG DFSClient: DFSClient seqno: 94 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:12:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=95, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/03/15 10:12:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529815 lastFlushOffset=529815 createNewBlock=false
17/03/15 10:12:03 DEBUG DFSClient: Waiting for ack for: 94
17/03/15 10:12:10 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=96, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/03/15 10:12:10 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529815 lastFlushOffset=529815 createNewBlock=false
17/03/15 10:12:10 DEBUG DFSClient: Waiting for ack for: 94
17/03/15 10:12:10 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=97, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/03/15 10:12:10 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529815 lastFlushOffset=529815 createNewBlock=false
17/03/15 10:12:10 DEBUG DFSClient: Waiting for ack for: 94
[Stage 87:=====>                                                   (1 + 3) / 10]17/03/15 10:12:12 WARN TaskSetManager: Lost task 1.1 in stage 87.2 (TID 516, 172.21.15.173, executor 3): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=1, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:12:12 WARN TaskSetManager: Lost task 4.1 in stage 87.2 (TID 513, 172.21.15.173, executor 3): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=4, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:12:12 WARN TaskSetManager: Lost task 0.1 in stage 87.2 (TID 515, 172.21.15.173, executor 3): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:12:12 WARN TaskSetManager: Lost task 5.1 in stage 87.2 (TID 514, 172.21.15.173, executor 3): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:12:12 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=98, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/03/15 10:12:12 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=535749 lastFlushOffset=529815 createNewBlock=false
17/03/15 10:12:12 DEBUG DFSClient: Queued packet 98
17/03/15 10:12:12 DEBUG DFSClient: Waiting for ack for: 98
17/03/15 10:12:12 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 98 offsetInBlock: 529408 lastPacketInBlock: false lastByteOffsetInBlock: 535749
17/03/15 10:12:12 DEBUG DFSClient: DFSClient seqno: 98 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:12:12 WARN TaskSetManager: Lost task 2.1 in stage 87.2 (TID 517, 172.21.15.173, executor 3): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=2, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
[Stage 76:>                                                        (0 + 0) / 10]17/03/15 10:12:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:12:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 76:>                                                        (0 + 4) / 10][Stage 76:===========>                                             (2 + 4) / 10][Stage 76:=================>                                       (3 + 4) / 10][Stage 76:======================>                                  (4 + 4) / 10][Stage 76:============================>                            (5 + 4) / 10][Stage 76:=======================================>                 (7 + 3) / 10][Stage 76:=============================================>           (8 + 2) / 10][Stage 76:===================================================>     (9 + 1) / 10]17/03/15 10:12:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=99, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=535552
17/03/15 10:12:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=548714 lastFlushOffset=535749 createNewBlock=false
17/03/15 10:12:29 DEBUG DFSClient: Queued packet 99
17/03/15 10:12:29 DEBUG DFSClient: Waiting for ack for: 99
17/03/15 10:12:29 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 99 offsetInBlock: 535552 lastPacketInBlock: false lastByteOffsetInBlock: 548714
17/03/15 10:12:29 DEBUG DFSClient: DFSClient seqno: 99 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10]17/03/15 10:12:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:12:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:12:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:12:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #33
17/03/15 10:12:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #33
17/03/15 10:12:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:12:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:12:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10]17/03/15 10:12:42 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=100, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=548352
17/03/15 10:12:42 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=557205 lastFlushOffset=548714 createNewBlock=false
17/03/15 10:12:42 DEBUG DFSClient: Queued packet 100
17/03/15 10:12:42 DEBUG DFSClient: Waiting for ack for: 100
17/03/15 10:12:42 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 100 offsetInBlock: 548352 lastPacketInBlock: false lastByteOffsetInBlock: 557205
17/03/15 10:12:42 DEBUG DFSClient: DFSClient seqno: 100 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:12:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:12:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:12:43 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=101, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=557056
17/03/15 10:12:43 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=562303 lastFlushOffset=557205 createNewBlock=false
17/03/15 10:12:43 DEBUG DFSClient: Queued packet 101
17/03/15 10:12:43 DEBUG DFSClient: Waiting for ack for: 101
17/03/15 10:12:43 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 101 offsetInBlock: 557056 lastPacketInBlock: false lastByteOffsetInBlock: 562303
17/03/15 10:12:43 DEBUG DFSClient: DFSClient seqno: 101 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:=================>                                       (3 + 4) / 10][Stage 79:======================>                                  (4 + 4) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/15 10:12:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=102, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=562176
17/03/15 10:12:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=572214 lastFlushOffset=562303 createNewBlock=false
17/03/15 10:12:44 DEBUG DFSClient: Queued packet 102
17/03/15 10:12:44 DEBUG DFSClient: Waiting for ack for: 102
17/03/15 10:12:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 102 offsetInBlock: 562176 lastPacketInBlock: false lastByteOffsetInBlock: 572214
17/03/15 10:12:44 DEBUG DFSClient: DFSClient seqno: 102 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:======================>                                  (4 + 4) / 10][Stage 80:=============================================>           (8 + 2) / 10]17/03/15 10:12:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=103, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=571904
17/03/15 10:12:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=577585 lastFlushOffset=572214 createNewBlock=false
17/03/15 10:12:45 DEBUG DFSClient: Queued packet 103
17/03/15 10:12:45 DEBUG DFSClient: Waiting for ack for: 103
17/03/15 10:12:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 103 offsetInBlock: 571904 lastPacketInBlock: false lastByteOffsetInBlock: 577585
17/03/15 10:12:45 DEBUG DFSClient: DFSClient seqno: 103 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/15 10:12:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=104, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=577536
17/03/15 10:12:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=588639 lastFlushOffset=577585 createNewBlock=false
17/03/15 10:12:48 DEBUG DFSClient: Queued packet 104
17/03/15 10:12:48 DEBUG DFSClient: Waiting for ack for: 104
17/03/15 10:12:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 104 offsetInBlock: 577536 lastPacketInBlock: false lastByteOffsetInBlock: 588639
17/03/15 10:12:48 DEBUG DFSClient: DFSClient seqno: 104 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:=================>                                       (3 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:=============================================>           (8 + 2) / 10]17/03/15 10:12:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=105, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=588288
17/03/15 10:12:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=594166 lastFlushOffset=588639 createNewBlock=false
17/03/15 10:12:51 DEBUG DFSClient: Queued packet 105
17/03/15 10:12:51 DEBUG DFSClient: Waiting for ack for: 105
17/03/15 10:12:51 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 105 offsetInBlock: 588288 lastPacketInBlock: false lastByteOffsetInBlock: 594166
17/03/15 10:12:51 DEBUG DFSClient: DFSClient seqno: 105 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/03/15 10:13:02 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:13:02 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:13:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:13:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #34
17/03/15 10:13:02 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #34
17/03/15 10:13:02 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/03/15 10:13:02 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:13:02 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 83:===========>                                             (2 + 4) / 10][Stage 83:=================>                                       (3 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/03/15 10:13:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:13:12 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:============================>                            (5 + 4) / 10][Stage 83:==================================>                      (6 + 4) / 10][Stage 83:=======================================>                 (7 + 3) / 10][Stage 83:=============================================>           (8 + 2) / 10][Stage 83:===================================================>     (9 + 1) / 10]17/03/15 10:13:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=106, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=593920
17/03/15 10:13:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=605651 lastFlushOffset=594166 createNewBlock=false
17/03/15 10:13:24 DEBUG DFSClient: Queued packet 106
17/03/15 10:13:24 DEBUG DFSClient: Waiting for ack for: 106
17/03/15 10:13:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 106 offsetInBlock: 593920 lastPacketInBlock: false lastByteOffsetInBlock: 605651
17/03/15 10:13:24 WARN DFSClient: Slow ReadProcessor read fields took 33224ms (threshold=30000ms); ack: seqno: 106 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                        (0 + 4) / 10][Stage 84:=====>                                                   (1 + 4) / 10]17/03/15 10:13:32 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:13:32 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:13:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:13:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #35
17/03/15 10:13:32 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #35
17/03/15 10:13:32 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:13:32 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:13:32 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 84:=================>                                       (3 + 4) / 10][Stage 84:======================>                                  (4 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10]17/03/15 10:13:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:13:42 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10]17/03/15 10:13:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=107, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=605184
17/03/15 10:13:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=611240 lastFlushOffset=605651 createNewBlock=false
17/03/15 10:13:48 DEBUG DFSClient: Queued packet 107
17/03/15 10:13:48 DEBUG DFSClient: Waiting for ack for: 107
17/03/15 10:13:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 107 offsetInBlock: 605184 lastPacketInBlock: false lastByteOffsetInBlock: 611240
17/03/15 10:13:48 DEBUG DFSClient: DFSClient seqno: 107 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10]17/03/15 10:14:03 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:14:03 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:14:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:14:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #36
17/03/15 10:14:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #36
17/03/15 10:14:03 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:14:03 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:14:03 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10][Stage 85:===================================================>     (9 + 1) / 10]17/03/15 10:14:08 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=108, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=610816
17/03/15 10:14:08 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=622016 lastFlushOffset=611240 createNewBlock=false
17/03/15 10:14:08 DEBUG DFSClient: Queued packet 108
17/03/15 10:14:08 DEBUG DFSClient: Waiting for ack for: 108
17/03/15 10:14:08 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 108 offsetInBlock: 610816 lastPacketInBlock: false lastByteOffsetInBlock: 622016
17/03/15 10:14:08 DEBUG DFSClient: DFSClient seqno: 108 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10]17/03/15 10:14:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:14:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:=====>                                                   (1 + 4) / 10][Stage 86:===========>                                             (2 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10][Stage 86:=======================================>                 (7 + 3) / 10][Stage 86:=============================================>           (8 + 2) / 10]17/03/15 10:14:33 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:14:33 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:14:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:14:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #37
17/03/15 10:14:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #37
17/03/15 10:14:33 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:14:33 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:14:33 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 86:===================================================>     (9 + 1) / 10]17/03/15 10:14:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=109, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=621568
17/03/15 10:14:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=631726 lastFlushOffset=622016 createNewBlock=false
17/03/15 10:14:34 DEBUG DFSClient: Queued packet 109
17/03/15 10:14:34 DEBUG DFSClient: Waiting for ack for: 109
17/03/15 10:14:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 109 offsetInBlock: 621568 lastPacketInBlock: false lastByteOffsetInBlock: 631726
17/03/15 10:14:34 DEBUG DFSClient: DFSClient seqno: 109 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/15 10:14:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:14:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10][Stage 87:======================>                                  (4 + 4) / 10]17/03/15 10:15:03 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:15:03 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:15:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:15:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #38
17/03/15 10:15:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #38
17/03/15 10:15:03 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:15:03 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:15:03 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 87:============================>                            (5 + 4) / 10]17/03/15 10:15:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:15:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:15:22 WARN TaskSetManager: Lost task 5.0 in stage 87.3 (TID 633, 172.21.15.173, executor 3): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

17/03/15 10:15:22 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=110, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=631296
17/03/15 10:15:24 WARN TaskSetManager: Lost task 9.0 in stage 87.3 (TID 637, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 35088, None), shuffleId=2, mapId=1, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more

)
17/03/15 10:15:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=658212 lastFlushOffset=631726 createNewBlock=false
17/03/15 10:15:24 DEBUG DFSClient: Queued packet 110
17/03/15 10:15:24 DEBUG DFSClient: Waiting for ack for: 110
17/03/15 10:15:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 110 offsetInBlock: 631296 lastPacketInBlock: false lastByteOffsetInBlock: 658212
17/03/15 10:15:25 WARN TaskSetManager: Lost task 6.1 in stage 87.3 (TID 640, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 35088, None), shuffleId=2, mapId=1, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more

)
17/03/15 10:15:25 WARN DFSClient: Slow ReadProcessor read fields took 50538ms (threshold=30000ms); ack: seqno: 110 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/03/15 10:15:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=111, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=657920
17/03/15 10:15:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=658212 lastFlushOffset=658212 createNewBlock=false
17/03/15 10:15:25 DEBUG DFSClient: Waiting for ack for: 110
17/03/15 10:15:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=112, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=657920
17/03/15 10:15:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=658212 lastFlushOffset=658212 createNewBlock=false
17/03/15 10:15:25 DEBUG DFSClient: Waiting for ack for: 110
[Stage 76:>                                                        (0 + 1) / 10]17/03/15 10:15:26 WARN TaskSetManager: Lost task 7.1 in stage 87.3 (TID 639, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 35088, None), shuffleId=5, mapId=5, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/3e/shuffle_5_5_0.data, offset=34784696, length=4969201}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/3e/shuffle_5_5_0.data, offset=34784696, length=4969201}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 37 more
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/3e/shuffle_5_5_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 38 more

)
17/03/15 10:15:26 WARN TaskSetManager: Lost task 5.1 in stage 87.3 (TID 638, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 35088, None), shuffleId=5, mapId=4, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/1d/shuffle_5_4_0.data, offset=24877737, length=4975519}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/1d/shuffle_5_4_0.data, offset=24877737, length=4975519}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 37 more
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/1d/shuffle_5_4_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 38 more

)
17/03/15 10:15:26 WARN TaskSetManager: Lost task 8.0 in stage 87.3 (TID 636, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 35088, None), shuffleId=9, mapId=3, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/00/shuffle_9_3_0.data, offset=79392036, length=9923921}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/00/shuffle_9_3_0.data, offset=79392036, length=9923921}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-f32e5bfc-9ae3-4777-8dbf-f564311e90bd/00/shuffle_9_3_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/15 10:15:26 WARN TaskSetManager: Lost task 1.0 in stage 76.3 (TID 642, 172.21.15.173, executor 3): org.apache.spark.SparkException: Block rdd_3_1 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:15:26 WARN TaskSetManager: Lost task 2.0 in stage 76.3 (TID 643, 172.21.15.173, executor 3): org.apache.spark.SparkException: Block rdd_3_2 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:15:26 WARN TaskSetManager: Lost task 3.0 in stage 76.3 (TID 644, 172.21.15.173, executor 3): org.apache.spark.SparkException: Block rdd_3_3 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:15:26 WARN TaskSetManager: Lost task 4.0 in stage 76.3 (TID 645, 172.21.15.173, executor 3): org.apache.spark.SparkException: Block rdd_3_4 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

[Stage 76:>                                                        (0 + 4) / 10]17/03/15 10:15:26 ERROR TaskSchedulerImpl: Lost executor 3 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:15:26 WARN TaskSetManager: Lost task 3.1 in stage 76.3 (TID 648, 172.21.15.173, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:15:26 WARN TaskSetManager: Lost task 0.0 in stage 76.3 (TID 641, 172.21.15.173, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:15:26 WARN TaskSetManager: Lost task 2.1 in stage 76.3 (TID 647, 172.21.15.173, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:15:26 WARN TaskSetManager: Lost task 1.1 in stage 76.3 (TID 646, 172.21.15.173, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:15:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=113, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=657920
17/03/15 10:15:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=663014 lastFlushOffset=658212 createNewBlock=false
17/03/15 10:15:26 DEBUG DFSClient: Queued packet 113
17/03/15 10:15:26 DEBUG DFSClient: Waiting for ack for: 113
17/03/15 10:15:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 113 offsetInBlock: 657920 lastPacketInBlock: false lastByteOffsetInBlock: 663014
17/03/15 10:15:26 DEBUG DFSClient: DFSClient seqno: 113 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:15:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=114, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=662528
17/03/15 10:15:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=663014 lastFlushOffset=663014 createNewBlock=false
17/03/15 10:15:26 DEBUG DFSClient: Waiting for ack for: 113
[Stage 76:>                                                        (0 + 0) / 10]17/03/15 10:15:33 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:15:33 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:15:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:15:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #39
17/03/15 10:15:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #39
17/03/15 10:15:33 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/15 10:15:33 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:15:33 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:15:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=115, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=662528
17/03/15 10:15:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=663014 lastFlushOffset=663014 createNewBlock=false
17/03/15 10:15:35 DEBUG DFSClient: Waiting for ack for: 113
[Stage 76:>                                                        (0 + 4) / 10]17/03/15 10:15:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=116, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=662528
17/03/15 10:15:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=663014 lastFlushOffset=663014 createNewBlock=false
17/03/15 10:15:35 DEBUG DFSClient: Waiting for ack for: 113
17/03/15 10:15:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:15:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 76:=====>                                                   (1 + 4) / 10][Stage 76:===========>                                             (2 + 4) / 10][Stage 76:=================>                                       (3 + 4) / 10][Stage 76:======================>                                  (4 + 4) / 10][Stage 76:============================>                            (5 + 4) / 10][Stage 76:==================================>                      (6 + 4) / 10][Stage 76:=======================================>                 (7 + 3) / 10][Stage 76:=============================================>           (8 + 2) / 10][Stage 76:===================================================>     (9 + 1) / 10]17/03/15 10:15:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=117, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=662528
17/03/15 10:15:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=670269 lastFlushOffset=663014 createNewBlock=false
17/03/15 10:15:50 DEBUG DFSClient: Queued packet 117
17/03/15 10:15:50 DEBUG DFSClient: Waiting for ack for: 117
17/03/15 10:15:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 117 offsetInBlock: 662528 lastPacketInBlock: false lastByteOffsetInBlock: 670269
17/03/15 10:15:50 DEBUG DFSClient: DFSClient seqno: 117 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10][Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10]17/03/15 10:16:03 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:16:03 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:16:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:16:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #40
17/03/15 10:16:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #40
17/03/15 10:16:03 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:16:03 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:16:03 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:16:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=118, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=670208
17/03/15 10:16:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=683134 lastFlushOffset=670269 createNewBlock=false
17/03/15 10:16:03 DEBUG DFSClient: Queued packet 118
17/03/15 10:16:03 DEBUG DFSClient: Waiting for ack for: 118
17/03/15 10:16:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 118 offsetInBlock: 670208 lastPacketInBlock: false lastByteOffsetInBlock: 683134
17/03/15 10:16:03 DEBUG DFSClient: DFSClient seqno: 118 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:16:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=119, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=683008
17/03/15 10:16:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=688027 lastFlushOffset=683134 createNewBlock=false
17/03/15 10:16:04 DEBUG DFSClient: Queued packet 119
17/03/15 10:16:04 DEBUG DFSClient: Waiting for ack for: 119
17/03/15 10:16:04 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 119 offsetInBlock: 683008 lastPacketInBlock: false lastByteOffsetInBlock: 688027
17/03/15 10:16:04 DEBUG DFSClient: DFSClient seqno: 119 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                        (0 + 4) / 10][Stage 79:=================>                                       (3 + 4) / 10][Stage 79:======================>                                  (4 + 4) / 10][Stage 79:============================>                            (5 + 4) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/15 10:16:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=120, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=687616
17/03/15 10:16:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=693428 lastFlushOffset=688027 createNewBlock=false
17/03/15 10:16:05 DEBUG DFSClient: Queued packet 120
17/03/15 10:16:05 DEBUG DFSClient: Waiting for ack for: 120
17/03/15 10:16:05 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 120 offsetInBlock: 687616 lastPacketInBlock: false lastByteOffsetInBlock: 693428
17/03/15 10:16:05 DEBUG DFSClient: DFSClient seqno: 120 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:======================>                                  (4 + 4) / 10][Stage 80:=============================================>           (8 + 2) / 10]17/03/15 10:16:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=121, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=693248
17/03/15 10:16:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=703450 lastFlushOffset=693428 createNewBlock=false
17/03/15 10:16:06 DEBUG DFSClient: Queued packet 121
17/03/15 10:16:06 DEBUG DFSClient: Waiting for ack for: 121
17/03/15 10:16:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 121 offsetInBlock: 693248 lastPacketInBlock: false lastByteOffsetInBlock: 703450
17/03/15 10:16:06 DEBUG DFSClient: DFSClient seqno: 121 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/15 10:16:10 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=122, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=702976
17/03/15 10:16:10 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=709157 lastFlushOffset=703450 createNewBlock=false
17/03/15 10:16:10 DEBUG DFSClient: Queued packet 122
17/03/15 10:16:10 DEBUG DFSClient: Waiting for ack for: 122
17/03/15 10:16:10 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 122 offsetInBlock: 702976 lastPacketInBlock: false lastByteOffsetInBlock: 709157
17/03/15 10:16:10 DEBUG DFSClient: DFSClient seqno: 122 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:=======================================>                 (7 + 3) / 10][Stage 82:=============================================>           (8 + 2) / 10][Stage 82:===================================================>     (9 + 1) / 10]17/03/15 10:16:12 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=123, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=709120
17/03/15 10:16:12 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=719759 lastFlushOffset=709157 createNewBlock=false
17/03/15 10:16:12 DEBUG DFSClient: Queued packet 123
17/03/15 10:16:12 DEBUG DFSClient: Waiting for ack for: 123
17/03/15 10:16:12 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 123 offsetInBlock: 709120 lastPacketInBlock: false lastByteOffsetInBlock: 719759
17/03/15 10:16:12 DEBUG DFSClient: DFSClient seqno: 123 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 0) / 10]17/03/15 10:16:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:16:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:>                                                        (0 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/03/15 10:16:33 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:16:33 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:16:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:16:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #41
17/03/15 10:16:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #41
17/03/15 10:16:33 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:16:33 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:16:33 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:16:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:16:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:============================>                            (5 + 4) / 10][Stage 83:==================================>                      (6 + 4) / 10][Stage 83:=======================================>                 (7 + 3) / 10][Stage 83:=============================================>           (8 + 2) / 10][Stage 83:===================================================>     (9 + 1) / 10]17/03/15 10:16:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=124, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=719360
17/03/15 10:16:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=725660 lastFlushOffset=719759 createNewBlock=false
17/03/15 10:16:49 DEBUG DFSClient: Queued packet 124
17/03/15 10:16:50 DEBUG DFSClient: Waiting for ack for: 124
17/03/15 10:16:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 124 offsetInBlock: 719360 lastPacketInBlock: false lastByteOffsetInBlock: 725660
17/03/15 10:16:50 WARN DFSClient: Slow ReadProcessor read fields took 37109ms (threshold=30000ms); ack: seqno: 124 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                        (0 + 4) / 10][Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:===========>                                             (2 + 4) / 10][Stage 84:=================>                                       (3 + 4) / 10]17/03/15 10:17:03 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:17:03 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:17:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:17:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #42
17/03/15 10:17:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #42
17/03/15 10:17:03 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:17:03 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:17:03 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 84:======================>                                  (4 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10][Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10]17/03/15 10:17:12 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=125, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=725504
17/03/15 10:17:12 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=736609 lastFlushOffset=725660 createNewBlock=false
17/03/15 10:17:12 DEBUG DFSClient: Queued packet 125
17/03/15 10:17:12 DEBUG DFSClient: Waiting for ack for: 125
17/03/15 10:17:12 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 125 offsetInBlock: 725504 lastPacketInBlock: false lastByteOffsetInBlock: 736609
17/03/15 10:17:13 DEBUG DFSClient: DFSClient seqno: 125 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:17:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:17:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 85:>                                                        (0 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10][Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10]17/03/15 10:17:33 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:17:33 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:17:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:17:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #43
17/03/15 10:17:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #43
17/03/15 10:17:33 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:17:33 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:17:33 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10][Stage 85:===================================================>     (9 + 1) / 10]17/03/15 10:17:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=126, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=736256
17/03/15 10:17:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=742279 lastFlushOffset=736609 createNewBlock=false
17/03/15 10:17:35 DEBUG DFSClient: Queued packet 126
17/03/15 10:17:35 DEBUG DFSClient: Waiting for ack for: 126
17/03/15 10:17:35 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 126 offsetInBlock: 736256 lastPacketInBlock: false lastByteOffsetInBlock: 742279
17/03/15 10:17:35 DEBUG DFSClient: DFSClient seqno: 126 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10][Stage 86:=====>                                                   (1 + 4) / 10][Stage 86:===========>                                             (2 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10]17/03/15 10:17:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:17:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:============================>                            (5 + 4) / 10][Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=======================================>                 (7 + 3) / 10][Stage 86:=============================================>           (8 + 2) / 10]17/03/15 10:18:03 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:18:03 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:18:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:18:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #44
17/03/15 10:18:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #44
17/03/15 10:18:03 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:18:03 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:18:03 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 86:===================================================>     (9 + 1) / 10]17/03/15 10:18:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=127, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=741888
17/03/15 10:18:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=757850 lastFlushOffset=742279 createNewBlock=false
17/03/15 10:18:07 DEBUG DFSClient: Queued packet 127
17/03/15 10:18:07 DEBUG DFSClient: Waiting for ack for: 127
17/03/15 10:18:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 127 offsetInBlock: 741888 lastPacketInBlock: false lastByteOffsetInBlock: 757850
17/03/15 10:18:07 WARN DFSClient: Slow ReadProcessor read fields took 31968ms (threshold=30000ms); ack: seqno: 127 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 87:>                                                        (0 + 4) / 10]17/03/15 10:18:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:18:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10][Stage 87:===========>                                             (2 + 4) / 10][Stage 87:=================>                                       (3 + 4) / 10][Stage 87:======================>                                  (4 + 4) / 10]17/03/15 10:18:33 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:18:33 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:18:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:18:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #45
17/03/15 10:18:33 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #45
17/03/15 10:18:33 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/15 10:18:33 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:18:33 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
[Stage 87:============================>                            (5 + 4) / 10]17/03/15 10:18:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:18:43 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:==================================>                      (6 + 4) / 10]17/03/15 10:19:03 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:19:03 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:19:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:19:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #46
17/03/15 10:19:03 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #46
17/03/15 10:19:03 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/15 10:19:03 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-1454523498_1
17/03/15 10:19:03 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1454523498_1] with renew id 1 executed
17/03/15 10:19:09 WARN TaskSetManager: Lost task 8.0 in stage 87.4 (TID 767, 172.21.15.173, executor 4): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at com.esotericsoftware.kryo.io.Input.readDoubles(Input.java:885)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:222)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:205)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:69)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)

17/03/15 10:19:09 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=128, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=757760
[Stage 87:=======================================>                 (7 + 3) / 10]17/03/15 10:19:11 WARN TaskSetManager: Lost task 7.0 in stage 87.4 (TID 766, 172.21.15.173, executor 4): java.io.FileNotFoundException: /tmp/spark-cb707a28-258f-4fad-baf7-bd570338a5e9/executor-7893f17b-79fb-413a-9325-b6045216e032/blockmgr-4aaddd54-aaf3-48f2-b9b6-4d8703d6f98b/27/temp_shuffle_260c4ead-a7d6-46b2-b775-ff79a2a2d2a5 ()
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:229)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/15 10:19:11 ERROR TaskSchedulerImpl: Lost executor 4 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:19:11 WARN TaskSetManager: Lost task 9.0 in stage 87.4 (TID 768, 172.21.15.173, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:19:11 WARN TaskSetManager: Lost task 7.1 in stage 87.4 (TID 770, 172.21.15.173, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:19:11 WARN TaskSetManager: Lost task 8.1 in stage 87.4 (TID 769, 172.21.15.173, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/15 10:19:11 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=780392 lastFlushOffset=757850 createNewBlock=false
17/03/15 10:19:11 DEBUG DFSClient: Queued packet 128
17/03/15 10:19:11 DEBUG DFSClient: Waiting for ack for: 128
17/03/15 10:19:11 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 128 offsetInBlock: 757760 lastPacketInBlock: false lastByteOffsetInBlock: 780392
[Stage 87:=======================================>                (7 + -7) / 10]17/03/15 10:19:11 WARN DFSClient: Slow ReadProcessor read fields took 64063ms (threshold=30000ms); ack: seqno: 128 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/03/15 10:19:11 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=129, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=780288
17/03/15 10:19:11 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=783663 lastFlushOffset=780392 createNewBlock=false
17/03/15 10:19:11 DEBUG DFSClient: Queued packet 129
17/03/15 10:19:11 DEBUG DFSClient: Waiting for ack for: 129
17/03/15 10:19:11 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 129 offsetInBlock: 780288 lastPacketInBlock: false lastByteOffsetInBlock: 783663
17/03/15 10:19:11 DEBUG DFSClient: DFSClient seqno: 129 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:19:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:19:13 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/15 10:19:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=130, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=783360
17/03/15 10:19:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=783663 lastFlushOffset=783663 createNewBlock=false
17/03/15 10:19:19 DEBUG DFSClient: Waiting for ack for: 129
[Stage 87:=======================================>                (7 + -3) / 10]17/03/15 10:19:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=131, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=783360
17/03/15 10:19:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=783663 lastFlushOffset=783663 createNewBlock=false
17/03/15 10:19:19 DEBUG DFSClient: Waiting for ack for: 129
17/03/15 10:19:20 WARN TaskSetManager: Lost task 7.2 in stage 87.4 (TID 772, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:19:20 WARN TaskSetManager: Lost task 8.2 in stage 87.4 (TID 771, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:19:20 WARN TaskSetManager: Lost task 9.1 in stage 87.4 (TID 773, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:19:20 WARN TaskSetManager: Lost task 4.1 in stage 87.4 (TID 774, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=4, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:19:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=132, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=783360
17/03/15 10:19:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=788470 lastFlushOffset=783663 createNewBlock=false
17/03/15 10:19:20 DEBUG DFSClient: Queued packet 132
17/03/15 10:19:20 DEBUG DFSClient: Waiting for ack for: 132
17/03/15 10:19:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 132 offsetInBlock: 783360 lastPacketInBlock: false lastByteOffsetInBlock: 788470
17/03/15 10:19:20 DEBUG DFSClient: DFSClient seqno: 132 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 87 (mapPartitions at VertexRDD.scala:356) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697) 	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693) 	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285) 	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285) 	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54) 	at org.apache.spark.scheduler.Task.run(Task.scala:114) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1456)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1443)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1443)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1273)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1626)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1615)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2016)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2037)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2056)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1159)
	at src.main.scala.SVDPlusPlusApp$.main(SVDPlusPlusApp.scala:105)
	at src.main.scala.SVDPlusPlusApp.main(SVDPlusPlusApp.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/03/15 10:19:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=133, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=787968
17/03/15 10:19:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=788470 lastFlushOffset=788470 createNewBlock=false
17/03/15 10:19:20 DEBUG DFSClient: Waiting for ack for: 132
17/03/15 10:19:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=134, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=787968
17/03/15 10:19:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=792218 lastFlushOffset=788470 createNewBlock=false
17/03/15 10:19:20 DEBUG DFSClient: Queued packet 134
17/03/15 10:19:20 DEBUG DFSClient: Waiting for ack for: 134
17/03/15 10:19:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 134 offsetInBlock: 787968 lastPacketInBlock: false lastByteOffsetInBlock: 792218
17/03/15 10:19:20 DEBUG DFSClient: DFSClient seqno: 134 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:19:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=135, src=/eventLogs/app-20170315095931-0046.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=792064
17/03/15 10:19:20 DEBUG DFSClient: Queued packet 135
17/03/15 10:19:20 DEBUG DFSClient: Queued packet 136
17/03/15 10:19:20 DEBUG DFSClient: Waiting for ack for: 136
17/03/15 10:19:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 135 offsetInBlock: 792064 lastPacketInBlock: false lastByteOffsetInBlock: 792774
17/03/15 10:19:20 DEBUG DFSClient: DFSClient seqno: 135 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:19:20 WARN TaskSetManager: Lost task 1.1 in stage 87.4 (TID 775, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=1, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/03/15 10:19:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117 sending packet packet seqno: 136 offsetInBlock: 792774 lastPacketInBlock: true lastByteOffsetInBlock: 792774
17/03/15 10:19:20 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerTaskEnd(87,4,ShuffleMapTask,FetchFailed(null,0,-1,1,org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
),org.apache.spark.scheduler.TaskInfo@3158c419,null)
17/03/15 10:19:21 DEBUG DFSClient: DFSClient seqno: 136 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/15 10:19:21 DEBUG DFSClient: Closing old block BP-519507147-172.21.15.90-1479901973323:blk_1073808940_68117
17/03/15 10:19:21 DEBUG Client: The ping interval is 60000 ms.
17/03/15 10:19:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/15 10:19:21 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/15 10:19:21 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #47
17/03/15 10:19:21 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #47
17/03/15 10:19:21 DEBUG ProtobufRpcEngine: Call: complete took 3ms
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #48
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #48
17/03/15 10:19:22 DEBUG ProtobufRpcEngine: Call: complete took 7ms
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #49
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #49
17/03/15 10:19:22 DEBUG ProtobufRpcEngine: Call: getFileInfo took 2ms
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #50
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #50
17/03/15 10:19:22 DEBUG ProtobufRpcEngine: Call: rename took 9ms
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop sending #51
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop got value #51
17/03/15 10:19:22 DEBUG ProtobufRpcEngine: Call: setTimes took 8ms
17/03/15 10:19:22 DEBUG PoolThreadCache: Freed 16 thread-local buffer(s) from thread: shuffle-server-6-4
17/03/15 10:19:22 DEBUG PoolThreadCache: Freed 34 thread-local buffer(s) from thread: shuffle-server-6-2
17/03/15 10:19:22 DEBUG PoolThreadCache: Freed 29 thread-local buffer(s) from thread: rpc-server-3-4
17/03/15 10:19:22 DEBUG Client: stopping client from cache: org.apache.hadoop.ipc.Client@1077b5d0
17/03/15 10:19:22 DEBUG Client: removing client from cache: org.apache.hadoop.ipc.Client@1077b5d0
17/03/15 10:19:22 DEBUG Client: stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1077b5d0
17/03/15 10:19:22 DEBUG Client: Stopping client
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/15 10:19:22 DEBUG Client: IPC Client (953057726) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
