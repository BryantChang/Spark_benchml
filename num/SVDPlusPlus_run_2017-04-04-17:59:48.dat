17/04/04 17:59:49 WARN SparkContext: Support for Java 7 is deprecated as of Spark 2.0.0
17/04/04 17:59:49 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
17/04/04 17:59:49 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
17/04/04 17:59:49 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[GetGroups], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
17/04/04 17:59:49 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
17/04/04 17:59:49 DEBUG Shell: setsid exited with exit code 0
17/04/04 17:59:49 DEBUG Groups:  Creating new Groups object
17/04/04 17:59:49 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
17/04/04 17:59:49 DEBUG NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
17/04/04 17:59:49 DEBUG NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
17/04/04 17:59:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/04/04 17:59:49 DEBUG PerformanceAdvisory: Falling back to shell based
17/04/04 17:59:49 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
17/04/04 17:59:49 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17/04/04 17:59:49 DEBUG UserGroupInformation: hadoop login
17/04/04 17:59:49 DEBUG UserGroupInformation: hadoop login commit
17/04/04 17:59:49 DEBUG UserGroupInformation: using local user:UnixPrincipal: hadoop
17/04/04 17:59:49 DEBUG UserGroupInformation: Using user: "UnixPrincipal: hadoop" with name hadoop
17/04/04 17:59:49 DEBUG UserGroupInformation: User entry: "hadoop"
17/04/04 17:59:49 DEBUG UserGroupInformation: UGI loginUser:hadoop (auth:SIMPLE)
17/04/04 17:59:49 WARN SparkConf: Detected deprecated memory fraction settings: [spark.shuffle.memoryFraction, spark.storage.memoryFraction, spark.storage.unrollFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
17/04/04 17:59:49 WARN SparkConf: 
SPARK_CLASSPATH was detected (set to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
17/04/04 17:59:49 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:' as a work-around.
17/04/04 17:59:49 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:' as a work-around.
17/04/04 17:59:49 DEBUG InternalLoggerFactory: Using SLF4J as the default logging framework
17/04/04 17:59:49 DEBUG PlatformDependent0: java.nio.Buffer.address: available
17/04/04 17:59:49 DEBUG PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
17/04/04 17:59:49 DEBUG PlatformDependent0: sun.misc.Unsafe.copyMemory: available
17/04/04 17:59:49 DEBUG PlatformDependent0: direct buffer constructor: available
17/04/04 17:59:49 DEBUG PlatformDependent0: java.nio.Bits.unaligned: available, true
17/04/04 17:59:49 DEBUG PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
17/04/04 17:59:49 DEBUG Cleaner0: java.nio.ByteBuffer.cleaner(): available
17/04/04 17:59:49 DEBUG PlatformDependent: Java version: 7
17/04/04 17:59:49 DEBUG PlatformDependent: -Dio.netty.noUnsafe: false
17/04/04 17:59:49 DEBUG PlatformDependent: sun.misc.Unsafe: available
17/04/04 17:59:49 DEBUG PlatformDependent: -Dio.netty.noJavassist: false
17/04/04 17:59:49 DEBUG PlatformDependent: Javassist: available
17/04/04 17:59:49 DEBUG PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
17/04/04 17:59:49 DEBUG PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
17/04/04 17:59:49 DEBUG PlatformDependent: -Dio.netty.noPreferDirect: false
17/04/04 17:59:49 DEBUG PlatformDependent: io.netty.maxDirectMemory: 1342177280 bytes
17/04/04 17:59:49 DEBUG JavassistTypeParameterMatcherGenerator: Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
17/04/04 17:59:49 DEBUG JavassistTypeParameterMatcherGenerator: Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
17/04/04 17:59:49 DEBUG MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 8
17/04/04 17:59:49 DEBUG NioEventLoop: -Dio.netty.noKeySetOptimization: false
17/04/04 17:59:49 DEBUG NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
17/04/04 17:59:49 DEBUG PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 8
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 8
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
17/04/04 17:59:49 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
17/04/04 17:59:49 DEBUG ThreadLocalRandom: -Dio.netty.initialSeedUniquifier: 0xde6961a968563daf (took 0 ms)
17/04/04 17:59:49 DEBUG ByteBufUtil: -Dio.netty.allocator.type: unpooled
17/04/04 17:59:49 DEBUG ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
17/04/04 17:59:49 DEBUG ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
17/04/04 17:59:49 DEBUG NetUtil: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%1)
17/04/04 17:59:49 DEBUG NetUtil: /proc/sys/net/core/somaxconn: 128
17/04/04 17:59:50 DEBUG AbstractByteBuf: -Dio.netty.buffer.bytebuf.checkAccessible: true
17/04/04 17:59:50 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
17/04/04 17:59:50 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.maxRecords: 4
17/04/04 17:59:50 DEBUG ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@1267173d
17/04/04 17:59:50 DEBUG Recycler: -Dio.netty.recycler.maxCapacity.default: 32768
17/04/04 17:59:50 DEBUG Recycler: -Dio.netty.recycler.maxSharedCapacityFactor: 2
17/04/04 17:59:50 DEBUG Recycler: -Dio.netty.recycler.linkCapacity: 16
17/04/04 17:59:50 DEBUG Recycler: -Dio.netty.recycler.ratio: 8
17/04/04 17:59:50 DEBUG BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false
17/04/04 17:59:50 DEBUG BlockReaderLocal: dfs.client.read.shortcircuit = false
17/04/04 17:59:50 DEBUG BlockReaderLocal: dfs.client.domain.socket.data.traffic = false
17/04/04 17:59:50 DEBUG BlockReaderLocal: dfs.domain.socket.path = 
17/04/04 17:59:50 DEBUG RetryUtils: multipleLinearRandomRetry = null
17/04/04 17:59:50 DEBUG Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@531da6d3
17/04/04 17:59:50 DEBUG Client: getting client out of cache: org.apache.hadoop.ipc.Client@3cba87f2
17/04/04 17:59:50 DEBUG PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
17/04/04 17:59:50 DEBUG DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
17/04/04 17:59:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 17:59:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #0
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #0
17/04/04 17:59:50 DEBUG ProtobufRpcEngine: Call: getFileInfo took 25ms
17/04/04 17:59:50 DEBUG DFSClient: /eventLogs/app-20170404175950-0081.lz4.inprogress: masked=rw-r--r--
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #1
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #1
17/04/04 17:59:50 DEBUG ProtobufRpcEngine: Call: create took 63ms
17/04/04 17:59:50 DEBUG DFSClient: computePacketChunkSize: src=/eventLogs/app-20170404175950-0081.lz4.inprogress, chunkSize=516, chunksPerPacket=126, packetSize=65016
17/04/04 17:59:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 started
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #2
17/04/04 17:59:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #2
17/04/04 17:59:50 DEBUG ProtobufRpcEngine: Call: setPermission took 3ms
17/04/04 17:59:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/04/04 17:59:50 DEBUG DFSClient: Waiting for ack for: -1
17/04/04 17:59:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/04/04 17:59:50 DEBUG DFSClient: Waiting for ack for: -1
17/04/04 17:59:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #3
17/04/04 17:59:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #3
17/04/04 17:59:51 DEBUG ProtobufRpcEngine: Call: getFileInfo took 1ms
17/04/04 17:59:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #4
17/04/04 17:59:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #4
17/04/04 17:59:51 DEBUG ProtobufRpcEngine: Call: getListing took 1ms
17/04/04 17:59:51 DEBUG FileInputFormat: Time taken to get FileStatuses: 15
17/04/04 17:59:51 INFO FileInputFormat: Total input paths to process : 10
17/04/04 17:59:51 DEBUG FileInputFormat: Total # of splits generated by getSplits: 16, TimeTaken: 19
17/04/04 17:59:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/04/04 17:59:51 DEBUG DFSClient: Waiting for ack for: -1
[Stage 0:>                                                         (0 + 0) / 10]17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=0, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=0 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Queued packet 0
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: Allocating new block
17/04/04 17:59:59 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #5
17/04/04 17:59:59 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #5
17/04/04 17:59:59 DEBUG ProtobufRpcEngine: Call: addBlock took 21ms
17/04/04 17:59:59 DEBUG DFSClient: pipeline = DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]
17/04/04 17:59:59 DEBUG DFSClient: Connecting to datanode 172.21.15.173:50010
17/04/04 17:59:59 DEBUG DFSClient: Send buf size 124928
17/04/04 17:59:59 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #6
17/04/04 17:59:59 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #6
17/04/04 17:59:59 DEBUG ProtobufRpcEngine: Call: getServerDefaults took 1ms
17/04/04 17:59:59 DEBUG SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /172.21.15.173, datanodeId = DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]
17/04/04 17:59:59 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6331
17/04/04 17:59:59 DEBUG DFSClient: DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 17:59:59 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #7
17/04/04 17:59:59 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #7
17/04/04 17:59:59 DEBUG ProtobufRpcEngine: Call: fsync took 14ms
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=1, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=2, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=3, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=4, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=5, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=6, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
17/04/04 17:59:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=7, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 17:59:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6331 lastFlushOffset=6331 createNewBlock=false
17/04/04 17:59:59 DEBUG DFSClient: Waiting for ack for: 0
[Stage 0:>                                                         (0 + 4) / 10][Stage 0:>                                                         (0 + 5) / 10][Stage 0:=====>                                                    (1 + 4) / 10]17/04/04 18:00:09 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:00:09 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 0:===========>                                              (2 + 4) / 10][Stage 0:=================>                                        (3 + 4) / 10][Stage 0:=======================>                                  (4 + 4) / 10][Stage 0:=============================>                            (5 + 4) / 10][Stage 0:==================================>                       (6 + 4) / 10][Stage 0:========================================>                 (7 + 3) / 10][Stage 0:====================================================>     (9 + 1) / 10][Stage 0:=========================================================(10 + 0) / 10]                                                                                17/04/04 18:00:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=8, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/04/04 18:00:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=12622 lastFlushOffset=6331 createNewBlock=false
17/04/04 18:00:15 DEBUG DFSClient: Queued packet 8
17/04/04 18:00:15 DEBUG DFSClient: Waiting for ack for: 8
17/04/04 18:00:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 8 offsetInBlock: 6144 lastPacketInBlock: false lastByteOffsetInBlock: 12622
17/04/04 18:00:15 DEBUG DFSClient: DFSClient seqno: 8 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:00:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=9, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12288
17/04/04 18:00:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=12622 lastFlushOffset=12622 createNewBlock=false
17/04/04 18:00:15 DEBUG DFSClient: Waiting for ack for: 8
17/04/04 18:00:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=10, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12288
17/04/04 18:00:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=12622 lastFlushOffset=12622 createNewBlock=false
17/04/04 18:00:15 DEBUG DFSClient: Waiting for ack for: 8
[Stage 1:>                                                         (0 + 4) / 10][Stage 1:=====>                                                    (1 + 4) / 10][Stage 1:=================>                                        (3 + 4) / 10][Stage 1:=======================>                                  (4 + 4) / 10][Stage 1:=============================>                            (5 + 4) / 10][Stage 1:========================================>                 (7 + 3) / 10][Stage 1:====================================================>     (9 + 1) / 10]17/04/04 18:00:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=11, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12288
17/04/04 18:00:18 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=17104 lastFlushOffset=12622 createNewBlock=false
17/04/04 18:00:18 DEBUG DFSClient: Queued packet 11
17/04/04 18:00:18 DEBUG DFSClient: Waiting for ack for: 11
17/04/04 18:00:18 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 11 offsetInBlock: 12288 lastPacketInBlock: false lastByteOffsetInBlock: 17104
17/04/04 18:00:18 DEBUG DFSClient: DFSClient seqno: 11 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 2:>                                                         (0 + 4) / 10]17/04/04 18:00:20 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:00:20 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:00:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:00:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #8
17/04/04 18:00:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #8
17/04/04 18:00:20 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:00:20 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:00:20 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 2:===========>                                              (2 + 4) / 10][Stage 2:=======================>                                  (4 + 4) / 10][Stage 2:==================================>                       (6 + 4) / 10][Stage 2:==============================================>           (8 + 2) / 10]                                                                                17/04/04 18:00:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=12, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16896
17/04/04 18:00:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=35353 lastFlushOffset=17104 createNewBlock=false
17/04/04 18:00:26 DEBUG DFSClient: Queued packet 12
17/04/04 18:00:26 DEBUG DFSClient: Waiting for ack for: 12
17/04/04 18:00:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 12 offsetInBlock: 16896 lastPacketInBlock: false lastByteOffsetInBlock: 35353
17/04/04 18:00:26 DEBUG DFSClient: DFSClient seqno: 12 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:00:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=13, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=35328
17/04/04 18:00:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=35353 lastFlushOffset=35353 createNewBlock=false
17/04/04 18:00:26 DEBUG DFSClient: Waiting for ack for: 12
17/04/04 18:00:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=14, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=35328
17/04/04 18:00:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=35353 lastFlushOffset=35353 createNewBlock=false
17/04/04 18:00:26 DEBUG DFSClient: Waiting for ack for: 12
[Stage 4:>                                                         (0 + 4) / 10]17/04/04 18:00:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:00:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 4:===========>                                              (2 + 4) / 10][Stage 4:=======================>                                  (4 + 4) / 10][Stage 4:=============================>                            (5 + 4) / 10][Stage 4:========================================>                 (7 + 3) / 10][Stage 4:==============================================>           (8 + 2) / 10][Stage 4:====================================================>     (9 + 1) / 10]17/04/04 18:00:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=15, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=35328
17/04/04 18:00:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=50000 lastFlushOffset=35353 createNewBlock=false
17/04/04 18:00:44 DEBUG DFSClient: Queued packet 15
17/04/04 18:00:44 DEBUG DFSClient: Waiting for ack for: 15
17/04/04 18:00:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 15 offsetInBlock: 35328 lastPacketInBlock: false lastByteOffsetInBlock: 50000
17/04/04 18:00:44 DEBUG DFSClient: DFSClient seqno: 15 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
                                                                                17/04/04 18:00:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=16, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=49664
17/04/04 18:00:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=57947 lastFlushOffset=50000 createNewBlock=false
17/04/04 18:00:45 DEBUG DFSClient: Queued packet 16
17/04/04 18:00:45 DEBUG DFSClient: Waiting for ack for: 16
17/04/04 18:00:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 16 offsetInBlock: 49664 lastPacketInBlock: false lastByteOffsetInBlock: 57947
17/04/04 18:00:45 DEBUG DFSClient: DFSClient seqno: 16 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:00:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=17, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=57856
17/04/04 18:00:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=57947 lastFlushOffset=57947 createNewBlock=false
17/04/04 18:00:45 DEBUG DFSClient: Waiting for ack for: 16
17/04/04 18:00:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=18, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=57856
17/04/04 18:00:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=57947 lastFlushOffset=57947 createNewBlock=false
17/04/04 18:00:45 DEBUG DFSClient: Waiting for ack for: 16
[Stage 7:>                                                         (0 + 4) / 10]17/04/04 18:00:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:00:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:00:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:00:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #9
17/04/04 18:00:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #9
17/04/04 18:00:50 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:00:50 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:00:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 7:=====>                                                    (1 + 4) / 10][Stage 7:===========>                                              (2 + 4) / 10][Stage 7:=================>                                        (3 + 4) / 10][Stage 7:=======================>                                  (4 + 4) / 10][Stage 7:==================================>                       (6 + 4) / 10][Stage 7:========================================>                 (7 + 3) / 10][Stage 7:==============================================>           (8 + 2) / 10]17/04/04 18:01:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:01:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 7:====================================================>     (9 + 1) / 10]                                                                                17/04/04 18:01:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=19, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=57856
17/04/04 18:01:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=74752 lastFlushOffset=57947 createNewBlock=false
17/04/04 18:01:03 DEBUG DFSClient: Queued packet 19
17/04/04 18:01:03 DEBUG DFSClient: Waiting for ack for: 19
17/04/04 18:01:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 19 offsetInBlock: 57856 lastPacketInBlock: false lastByteOffsetInBlock: 74752
17/04/04 18:01:03 DEBUG DFSClient: DFSClient seqno: 19 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:01:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=74752 lastFlushOffset=74752 createNewBlock=false
17/04/04 18:01:03 DEBUG DFSClient: Waiting for ack for: 19
17/04/04 18:01:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=74752 lastFlushOffset=74752 createNewBlock=false
17/04/04 18:01:03 DEBUG DFSClient: Waiting for ack for: 19
17/04/04 18:01:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=74752 lastFlushOffset=74752 createNewBlock=false
17/04/04 18:01:03 DEBUG DFSClient: Waiting for ack for: 19
17/04/04 18:01:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=20, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=74752
17/04/04 18:01:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=83262 lastFlushOffset=74752 createNewBlock=false
17/04/04 18:01:03 DEBUG DFSClient: Queued packet 20
17/04/04 18:01:03 DEBUG DFSClient: Waiting for ack for: 20
17/04/04 18:01:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 20 offsetInBlock: 74752 lastPacketInBlock: false lastByteOffsetInBlock: 83262
17/04/04 18:01:03 DEBUG DFSClient: DFSClient seqno: 20 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 11:>                                                        (0 + 4) / 10][Stage 11:=====>                                                   (1 + 4) / 10][Stage 11:===========>                                             (2 + 4) / 10][Stage 11:======================>                                  (4 + 4) / 10][Stage 11:==================================>                      (6 + 2) / 10][Stage 11:==================================>                      (6 + 4) / 10][Stage 11:=======================================>                 (7 + 3) / 10][Stage 11:=============================================>           (8 + 2) / 10]17/04/04 18:01:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=21, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=82944
17/04/04 18:01:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=91725 lastFlushOffset=83262 createNewBlock=false
17/04/04 18:01:16 DEBUG DFSClient: Queued packet 21
17/04/04 18:01:16 DEBUG DFSClient: Waiting for ack for: 21
17/04/04 18:01:16 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 21 offsetInBlock: 82944 lastPacketInBlock: false lastByteOffsetInBlock: 91725
17/04/04 18:01:16 DEBUG DFSClient: DFSClient seqno: 21 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
                                                                                17/04/04 18:01:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=22, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=91648
17/04/04 18:01:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=104871 lastFlushOffset=91725 createNewBlock=false
17/04/04 18:01:16 DEBUG DFSClient: Queued packet 22
17/04/04 18:01:16 DEBUG DFSClient: Waiting for ack for: 22
17/04/04 18:01:16 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 22 offsetInBlock: 91648 lastPacketInBlock: false lastByteOffsetInBlock: 104871
17/04/04 18:01:16 DEBUG DFSClient: DFSClient seqno: 22 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:01:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=23, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=104448
17/04/04 18:01:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=104871 lastFlushOffset=104871 createNewBlock=false
17/04/04 18:01:16 DEBUG DFSClient: Waiting for ack for: 22
17/04/04 18:01:16 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=24, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=104448
17/04/04 18:01:16 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=104871 lastFlushOffset=104871 createNewBlock=false
17/04/04 18:01:16 DEBUG DFSClient: Waiting for ack for: 22
17/04/04 18:01:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=25, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=104448
17/04/04 18:01:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=113821 lastFlushOffset=104871 createNewBlock=false
17/04/04 18:01:17 DEBUG DFSClient: Queued packet 25
17/04/04 18:01:17 DEBUG DFSClient: Waiting for ack for: 25
17/04/04 18:01:17 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 25 offsetInBlock: 104448 lastPacketInBlock: false lastByteOffsetInBlock: 113821
17/04/04 18:01:17 DEBUG DFSClient: DFSClient seqno: 25 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 18:======================>                                  (4 + 4) / 10][Stage 18:============================>                            (5 + 4) / 10][Stage 18:==================================>                      (6 + 4) / 10]17/04/04 18:01:20 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:01:20 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:01:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:01:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #10
17/04/04 18:01:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #10
17/04/04 18:01:20 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:01:20 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:01:20 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 18:=======================================>                 (7 + 3) / 10]17/04/04 18:01:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=26, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=113664
[Stage 18:=============================================>           (8 + 2) / 10][Stage 18:===================================================>     (9 + 1) / 10]                                                                                17/04/04 18:01:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=130449 lastFlushOffset=113821 createNewBlock=false
17/04/04 18:01:24 DEBUG DFSClient: Queued packet 26
17/04/04 18:01:24 DEBUG DFSClient: Waiting for ack for: 26
17/04/04 18:01:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 26 offsetInBlock: 113664 lastPacketInBlock: false lastByteOffsetInBlock: 130449
17/04/04 18:01:24 DEBUG DFSClient: DFSClient seqno: 26 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:01:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=27, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048
17/04/04 18:01:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=130449 lastFlushOffset=130449 createNewBlock=false
17/04/04 18:01:24 DEBUG DFSClient: Waiting for ack for: 26
17/04/04 18:01:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=28, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048
17/04/04 18:01:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=130449 lastFlushOffset=130449 createNewBlock=false
17/04/04 18:01:24 DEBUG DFSClient: Waiting for ack for: 26
17/04/04 18:01:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=29, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048
17/04/04 18:01:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=130449 lastFlushOffset=130449 createNewBlock=false
17/04/04 18:01:24 DEBUG DFSClient: Waiting for ack for: 26
17/04/04 18:01:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=30, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048
17/04/04 18:01:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=134814 lastFlushOffset=130449 createNewBlock=false
17/04/04 18:01:24 DEBUG DFSClient: Queued packet 30
17/04/04 18:01:24 DEBUG DFSClient: Waiting for ack for: 30
17/04/04 18:01:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 30 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 134814
17/04/04 18:01:24 DEBUG DFSClient: DFSClient seqno: 30 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 24:>                                                        (0 + 4) / 10][Stage 24:=====>                                                   (1 + 4) / 10]17/04/04 18:01:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:01:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 24:===========>                                             (2 + 4) / 10][Stage 24:===========>                                             (2 + 5) / 10][Stage 24:=================>                                       (3 + 4) / 10][Stage 24:============================>                            (5 + 3) / 10][Stage 24:==================================>                      (6 + 3) / 10][Stage 24:=======================================>                 (7 + 2) / 10][Stage 24:=============================================>           (8 + 1) / 10][Stage 24:===================================================>     (9 + 1) / 10]17/04/04 18:01:37 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=31, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=134656
17/04/04 18:01:37 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=150918 lastFlushOffset=134814 createNewBlock=false
17/04/04 18:01:37 DEBUG DFSClient: Queued packet 31
17/04/04 18:01:37 DEBUG DFSClient: Waiting for ack for: 31
17/04/04 18:01:37 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 31 offsetInBlock: 134656 lastPacketInBlock: false lastByteOffsetInBlock: 150918
17/04/04 18:01:37 DEBUG DFSClient: DFSClient seqno: 31 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 25:>                                                        (0 + 4) / 10][Stage 25:======================>                                  (4 + 4) / 10][Stage 25:============================>                            (5 + 4) / 10][Stage 25:=============================================>           (8 + 2) / 10][Stage 25:===================================================>     (9 + 1) / 10]                                                                                17/04/04 18:01:39 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=32, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=150528
17/04/04 18:01:39 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=159202 lastFlushOffset=150918 createNewBlock=false
17/04/04 18:01:39 DEBUG DFSClient: Queued packet 32
17/04/04 18:01:39 DEBUG DFSClient: Waiting for ack for: 32
17/04/04 18:01:39 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 32 offsetInBlock: 150528 lastPacketInBlock: false lastByteOffsetInBlock: 159202
17/04/04 18:01:39 DEBUG DFSClient: DFSClient seqno: 32 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:01:39 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=33, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=158720
17/04/04 18:01:39 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=159202 lastFlushOffset=159202 createNewBlock=false
17/04/04 18:01:39 DEBUG DFSClient: Waiting for ack for: 32
17/04/04 18:01:39 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=34, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=158720
17/04/04 18:01:39 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=163541 lastFlushOffset=159202 createNewBlock=false
17/04/04 18:01:39 DEBUG DFSClient: Queued packet 34
17/04/04 18:01:39 DEBUG DFSClient: Waiting for ack for: 34
17/04/04 18:01:39 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 34 offsetInBlock: 158720 lastPacketInBlock: false lastByteOffsetInBlock: 163541
17/04/04 18:01:39 DEBUG DFSClient: DFSClient seqno: 34 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 32:======================>                                  (4 + 4) / 10][Stage 32:============================>                            (5 + 4) / 10][Stage 32:==================================>                      (6 + 4) / 10][Stage 32:=============================================>           (8 + 2) / 10][Stage 32:===================================================>     (9 + 1) / 10]17/04/04 18:01:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=35, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=163328
17/04/04 18:01:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=171740 lastFlushOffset=163541 createNewBlock=false
17/04/04 18:01:44 DEBUG DFSClient: Queued packet 35
17/04/04 18:01:44 DEBUG DFSClient: Waiting for ack for: 35
17/04/04 18:01:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 35 offsetInBlock: 163328 lastPacketInBlock: false lastByteOffsetInBlock: 171740
17/04/04 18:01:44 DEBUG DFSClient: DFSClient seqno: 35 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 33:>                                                        (0 + 4) / 10][Stage 33:===========>                                             (2 + 4) / 10]17/04/04 18:01:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:01:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:01:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:01:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #11
17/04/04 18:01:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #11
17/04/04 18:01:50 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:01:50 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:01:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 33:=================>                                       (3 + 4) / 10][Stage 33:======================>                                  (4 + 4) / 10][Stage 33:============================>                            (5 + 3) / 10][Stage 33:============================>                            (5 + 4) / 10][Stage 33:==================================>                      (6 + 4) / 10][Stage 33:=======================================>                 (7 + 3) / 10][Stage 33:=============================================>           (8 + 2) / 10]17/04/04 18:01:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=36, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=171520
[Stage 33:===================================================>     (9 + 1) / 10]                                                                                17/04/04 18:01:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=190708 lastFlushOffset=171740 createNewBlock=false
17/04/04 18:01:59 DEBUG DFSClient: Queued packet 36
17/04/04 18:01:59 DEBUG DFSClient: Waiting for ack for: 36
17/04/04 18:01:59 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 36 offsetInBlock: 171520 lastPacketInBlock: false lastByteOffsetInBlock: 190708
17/04/04 18:01:59 DEBUG DFSClient: DFSClient seqno: 36 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:01:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=37, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190464
17/04/04 18:01:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=190708 lastFlushOffset=190708 createNewBlock=false
17/04/04 18:01:59 DEBUG DFSClient: Waiting for ack for: 36
17/04/04 18:01:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=38, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190464
17/04/04 18:01:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=190708 lastFlushOffset=190708 createNewBlock=false
17/04/04 18:01:59 DEBUG DFSClient: Waiting for ack for: 36
17/04/04 18:01:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=39, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190464
17/04/04 18:01:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=190708 lastFlushOffset=190708 createNewBlock=false
17/04/04 18:01:59 DEBUG DFSClient: Waiting for ack for: 36
17/04/04 18:01:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=40, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=190464
17/04/04 18:01:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=195108 lastFlushOffset=190708 createNewBlock=false
17/04/04 18:01:59 DEBUG DFSClient: Queued packet 40
17/04/04 18:01:59 DEBUG DFSClient: Waiting for ack for: 40
17/04/04 18:01:59 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 40 offsetInBlock: 190464 lastPacketInBlock: false lastByteOffsetInBlock: 195108
17/04/04 18:01:59 DEBUG DFSClient: DFSClient seqno: 40 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 41:>                                                        (0 + 4) / 10]17/04/04 18:02:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:02:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:02:20 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:02:20 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:02:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:02:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #12
17/04/04 18:02:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #12
17/04/04 18:02:20 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:02:20 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:02:20 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:02:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:02:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:=====>                                                   (1 + 4) / 10][Stage 41:===========>                                             (2 + 4) / 10][Stage 41:=================>                                       (3 + 4) / 10][Stage 41:======================>                                  (4 + 4) / 10]17/04/04 18:02:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:02:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:02:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:02:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #13
17/04/04 18:02:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #13
17/04/04 18:02:50 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:02:50 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:02:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:03:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:03:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:============================>                            (5 + 4) / 10][Stage 41:==================================>                      (6 + 4) / 10][Stage 41:=======================================>                 (7 + 3) / 10]17/04/04 18:03:20 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:03:20 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:03:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:03:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #14
17/04/04 18:03:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #14
17/04/04 18:03:20 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:03:20 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:03:20 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:03:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:03:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:=============================================>           (8 + 2) / 10]17/04/04 18:03:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:03:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:03:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:03:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #15
17/04/04 18:03:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #15
17/04/04 18:03:50 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:03:50 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:03:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 41:===================================================>     (9 + 1) / 10]17/04/04 18:04:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:04:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:04:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=41, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=195072
17/04/04 18:04:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=203914 lastFlushOffset=195108 createNewBlock=false
17/04/04 18:04:03 DEBUG DFSClient: Queued packet 41
17/04/04 18:04:03 DEBUG DFSClient: Waiting for ack for: 41
17/04/04 18:04:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 41 offsetInBlock: 195072 lastPacketInBlock: false lastByteOffsetInBlock: 203914
17/04/04 18:04:03 WARN DFSClient: Slow ReadProcessor read fields took 124133ms (threshold=30000ms); ack: seqno: 41 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 42:>                                                        (0 + 4) / 10][Stage 42:=====>                                                   (1 + 4) / 10][Stage 42:===========>                                             (2 + 4) / 10][Stage 42:======================>                                  (4 + 4) / 10][Stage 42:============================>                            (5 + 4) / 10][Stage 42:==================================>                      (6 + 4) / 10][Stage 42:=============================================>           (8 + 2) / 10]                                                                                17/04/04 18:04:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=42, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=203776
17/04/04 18:04:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=217520 lastFlushOffset=203914 createNewBlock=false
17/04/04 18:04:15 DEBUG DFSClient: Queued packet 42
17/04/04 18:04:15 DEBUG DFSClient: Waiting for ack for: 42
17/04/04 18:04:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 42 offsetInBlock: 203776 lastPacketInBlock: false lastByteOffsetInBlock: 217520
17/04/04 18:04:15 DEBUG DFSClient: DFSClient seqno: 42 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:04:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=43, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=217088
17/04/04 18:04:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=217520 lastFlushOffset=217520 createNewBlock=false
17/04/04 18:04:15 DEBUG DFSClient: Waiting for ack for: 42
17/04/04 18:04:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=44, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=217088
17/04/04 18:04:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=224956 lastFlushOffset=217520 createNewBlock=false
17/04/04 18:04:15 DEBUG DFSClient: Queued packet 44
17/04/04 18:04:15 DEBUG DFSClient: Waiting for ack for: 44
17/04/04 18:04:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 44 offsetInBlock: 217088 lastPacketInBlock: false lastByteOffsetInBlock: 224956
17/04/04 18:04:15 DEBUG DFSClient: DFSClient seqno: 44 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 51:>                                                        (0 + 4) / 10][Stage 51:===========>                                             (2 + 4) / 10][Stage 51:=================>                                       (3 + 4) / 10][Stage 51:======================>                                  (4 + 4) / 10]17/04/04 18:04:20 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:04:20 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:04:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:04:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #16
17/04/04 18:04:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #16
17/04/04 18:04:20 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:04:20 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:04:20 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 51:============================>                            (5 + 4) / 10][Stage 51:==================================>                      (6 + 3) / 10][Stage 51:=======================================>                 (7 + 2) / 10][Stage 51:=============================================>           (8 + 2) / 10][Stage 51:===================================================>     (9 + 1) / 10]17/04/04 18:04:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=45, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=224768
17/04/04 18:04:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=229899 lastFlushOffset=224956 createNewBlock=false
17/04/04 18:04:26 DEBUG DFSClient: Queued packet 45
17/04/04 18:04:26 DEBUG DFSClient: Waiting for ack for: 45
17/04/04 18:04:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 45 offsetInBlock: 224768 lastPacketInBlock: false lastByteOffsetInBlock: 229899
17/04/04 18:04:27 DEBUG DFSClient: DFSClient seqno: 45 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 52:>                                                        (0 + 4) / 10]17/04/04 18:04:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:04:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 52:=====>                                                   (1 + 4) / 10][Stage 52:===========>                                             (2 + 4) / 10][Stage 52:=================>                                       (3 + 4) / 10][Stage 52:======================>                                  (4 + 4) / 10]17/04/04 18:04:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:04:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:04:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:04:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #17
17/04/04 18:04:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #17
17/04/04 18:04:50 DEBUG ProtobufRpcEngine: Call: renewLease took 9ms
17/04/04 18:04:50 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:04:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 52:============================>                            (5 + 4) / 10][Stage 52:==================================>                      (6 + 4) / 10][Stage 52:=======================================>                 (7 + 3) / 10]17/04/04 18:04:58 WARN TaskSetManager: Lost task 6.0 in stage 52.0 (TID 185, 172.21.15.173, executor 2): java.lang.OutOfMemoryError: GC overhead limit exceeded

17/04/04 18:04:59 ERROR TaskSchedulerImpl: Lost executor 2 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:04:59 WARN TaskSetManager: Lost task 6.1 in stage 52.0 (TID 190, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:04:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=46, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=229888
17/04/04 18:04:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=242058 lastFlushOffset=229899 createNewBlock=false
17/04/04 18:04:59 DEBUG DFSClient: Queued packet 46
17/04/04 18:04:59 DEBUG DFSClient: Waiting for ack for: 46
17/04/04 18:04:59 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 46 offsetInBlock: 229888 lastPacketInBlock: false lastByteOffsetInBlock: 242058
[Stage 52:=======================================>                 (7 + 2) / 10]17/04/04 18:04:59 WARN DFSClient: Slow ReadProcessor read fields took 32895ms (threshold=30000ms); ack: seqno: 46 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:04:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=47, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=241664
17/04/04 18:04:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=242058 lastFlushOffset=242058 createNewBlock=false
17/04/04 18:04:59 DEBUG DFSClient: Waiting for ack for: 46
[Stage 52:=======================================>                 (7 + 3) / 10]17/04/04 18:05:00 WARN TaskSetManager: Lost task 6.2 in stage 52.0 (TID 191, 172.21.15.173, executor 3): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=6, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:05:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=48, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=241664
17/04/04 18:05:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=246928 lastFlushOffset=242058 createNewBlock=false
17/04/04 18:05:00 DEBUG DFSClient: Queued packet 48
17/04/04 18:05:00 DEBUG DFSClient: Waiting for ack for: 48
17/04/04 18:05:00 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 48 offsetInBlock: 241664 lastPacketInBlock: false lastByteOffsetInBlock: 246928
17/04/04 18:05:00 DEBUG DFSClient: DFSClient seqno: 48 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:05:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:05:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 43:>                                                         (0 + 1) / 2][Stage 43:=============================>                            (1 + 1) / 2]17/04/04 18:05:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=49, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=246784
17/04/04 18:05:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=246928 lastFlushOffset=246928 createNewBlock=false
17/04/04 18:05:15 DEBUG DFSClient: Waiting for ack for: 48
[Stage 44:>                                                         (0 + 0) / 2][Stage 44:>                                                         (0 + 1) / 2]17/04/04 18:05:17 WARN TaskSetManager: Lost task 9.0 in stage 52.0 (TID 189, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(2, 172.21.15.173, 33991, None), shuffleId=2, mapId=2, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:33991
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:33991
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:33991
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
[Stage 44:>                                                         (0 + 2) / 2]17/04/04 18:05:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=50, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=246784
17/04/04 18:05:18 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=251690 lastFlushOffset=246928 createNewBlock=false
17/04/04 18:05:18 DEBUG DFSClient: Queued packet 50
17/04/04 18:05:18 DEBUG DFSClient: Waiting for ack for: 50
17/04/04 18:05:18 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 50 offsetInBlock: 246784 lastPacketInBlock: false lastByteOffsetInBlock: 251690
17/04/04 18:05:18 DEBUG DFSClient: DFSClient seqno: 50 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:05:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=51, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=251392
17/04/04 18:05:18 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=251690 lastFlushOffset=251690 createNewBlock=false
17/04/04 18:05:18 DEBUG DFSClient: Waiting for ack for: 50
17/04/04 18:05:20 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:05:20 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:05:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:05:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #18
17/04/04 18:05:20 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #18
17/04/04 18:05:20 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:05:20 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:05:20 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 44:=============================>                            (1 + 1) / 2]17/04/04 18:05:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=52, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=251392
17/04/04 18:05:23 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=251690 lastFlushOffset=251690 createNewBlock=false
17/04/04 18:05:23 DEBUG DFSClient: Waiting for ack for: 50
[Stage 45:=============================>                            (1 + 1) / 2]17/04/04 18:05:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=53, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=251392
17/04/04 18:05:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=257617 lastFlushOffset=251690 createNewBlock=false
17/04/04 18:05:24 DEBUG DFSClient: Queued packet 53
17/04/04 18:05:24 DEBUG DFSClient: Waiting for ack for: 53
17/04/04 18:05:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 53 offsetInBlock: 251392 lastPacketInBlock: false lastByteOffsetInBlock: 257617
17/04/04 18:05:24 DEBUG DFSClient: DFSClient seqno: 53 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 46:===================>                                      (1 + 2) / 3][Stage 46:======================================>                   (2 + 1) / 3]17/04/04 18:05:28 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=54, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=257536
17/04/04 18:05:28 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=262910 lastFlushOffset=257617 createNewBlock=false
17/04/04 18:05:28 DEBUG DFSClient: Queued packet 54
17/04/04 18:05:28 DEBUG DFSClient: Waiting for ack for: 54
17/04/04 18:05:28 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 54 offsetInBlock: 257536 lastPacketInBlock: false lastByteOffsetInBlock: 262910
17/04/04 18:05:28 DEBUG DFSClient: DFSClient seqno: 54 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:05:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=55, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=262656
17/04/04 18:05:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=268067 lastFlushOffset=262910 createNewBlock=false
17/04/04 18:05:29 DEBUG DFSClient: Queued packet 55
17/04/04 18:05:29 DEBUG DFSClient: Waiting for ack for: 55
17/04/04 18:05:29 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 55 offsetInBlock: 262656 lastPacketInBlock: false lastByteOffsetInBlock: 268067
17/04/04 18:05:29 DEBUG DFSClient: DFSClient seqno: 55 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 48:>                                                         (0 + 2) / 2][Stage 48:=============================>                            (1 + 1) / 2]17/04/04 18:05:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:05:30 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:05:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=56, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=267776
17/04/04 18:05:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=268067 lastFlushOffset=268067 createNewBlock=false
17/04/04 18:05:31 DEBUG DFSClient: Waiting for ack for: 55
[Stage 49:>                                                         (0 + 3) / 3][Stage 49:======================================>                   (2 + 1) / 3]17/04/04 18:05:33 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=57, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=267776
17/04/04 18:05:33 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=273116 lastFlushOffset=268067 createNewBlock=false
17/04/04 18:05:33 DEBUG DFSClient: Queued packet 57
17/04/04 18:05:33 DEBUG DFSClient: Waiting for ack for: 57
17/04/04 18:05:33 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 57 offsetInBlock: 267776 lastPacketInBlock: false lastByteOffsetInBlock: 273116
17/04/04 18:05:33 DEBUG DFSClient: DFSClient seqno: 57 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 50:>                                                         (0 + 2) / 2]17/04/04 18:05:36 WARN TaskSetManager: Lost task 8.0 in stage 52.0 (TID 188, 172.21.15.173, executor 1): FetchFailed(BlockManagerId(2, 172.21.15.173, 33991, None), shuffleId=2, mapId=2, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:33991
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:33991
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:33991
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
17/04/04 18:05:36 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=58, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=272896
17/04/04 18:05:36 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=278723 lastFlushOffset=273116 createNewBlock=false
17/04/04 18:05:36 DEBUG DFSClient: Queued packet 58
17/04/04 18:05:36 DEBUG DFSClient: Waiting for ack for: 58
17/04/04 18:05:36 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 58 offsetInBlock: 272896 lastPacketInBlock: false lastByteOffsetInBlock: 278723
17/04/04 18:05:36 DEBUG DFSClient: DFSClient seqno: 58 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 50:=============================>                            (1 + 1) / 2]17/04/04 18:05:50 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:05:50 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:05:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:05:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #19
17/04/04 18:05:50 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #19
17/04/04 18:05:50 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:05:50 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:05:50 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:05:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=59, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=278528
17/04/04 18:05:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=284315 lastFlushOffset=278723 createNewBlock=false
17/04/04 18:05:51 DEBUG DFSClient: Queued packet 59
17/04/04 18:05:51 DEBUG DFSClient: Waiting for ack for: 59
17/04/04 18:05:51 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 59 offsetInBlock: 278528 lastPacketInBlock: false lastByteOffsetInBlock: 284315
17/04/04 18:05:51 DEBUG DFSClient: DFSClient seqno: 59 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 51:>                                                         (0 + 3) / 3][Stage 51:===================>                                      (1 + 2) / 3][Stage 51:======================================>                   (2 + 1) / 3]17/04/04 18:05:58 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=60, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=284160
17/04/04 18:05:58 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=289312 lastFlushOffset=284315 createNewBlock=false
17/04/04 18:05:58 DEBUG DFSClient: Queued packet 60
17/04/04 18:05:58 DEBUG DFSClient: Waiting for ack for: 60
17/04/04 18:05:58 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 60 offsetInBlock: 284160 lastPacketInBlock: false lastByteOffsetInBlock: 289312
17/04/04 18:05:59 DEBUG DFSClient: DFSClient seqno: 60 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 52:>                                                         (0 + 3) / 3]17/04/04 18:06:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:06:00 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 52:===================>                                      (1 + 2) / 3][Stage 52:======================================>                   (2 + 1) / 3]                                                                                17/04/04 18:06:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=61, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=289280
17/04/04 18:06:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=294255 lastFlushOffset=289312 createNewBlock=false
17/04/04 18:06:07 DEBUG DFSClient: Queued packet 61
17/04/04 18:06:07 DEBUG DFSClient: Waiting for ack for: 61
17/04/04 18:06:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 61 offsetInBlock: 289280 lastPacketInBlock: false lastByteOffsetInBlock: 294255
17/04/04 18:06:07 DEBUG DFSClient: DFSClient seqno: 61 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:06:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=62, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=293888
17/04/04 18:06:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=294255 lastFlushOffset=294255 createNewBlock=false
17/04/04 18:06:07 DEBUG DFSClient: Waiting for ack for: 61
17/04/04 18:06:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=63, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=293888
17/04/04 18:06:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=294255 lastFlushOffset=294255 createNewBlock=false
17/04/04 18:06:07 DEBUG DFSClient: Waiting for ack for: 61
17/04/04 18:06:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=64, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=293888
17/04/04 18:06:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=294255 lastFlushOffset=294255 createNewBlock=false
17/04/04 18:06:07 DEBUG DFSClient: Waiting for ack for: 61
17/04/04 18:06:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=65, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=293888
17/04/04 18:06:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=301867 lastFlushOffset=294255 createNewBlock=false
17/04/04 18:06:07 DEBUG DFSClient: Queued packet 65
17/04/04 18:06:07 DEBUG DFSClient: Waiting for ack for: 65
17/04/04 18:06:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 65 offsetInBlock: 293888 lastPacketInBlock: false lastByteOffsetInBlock: 301867
17/04/04 18:06:07 DEBUG DFSClient: DFSClient seqno: 65 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 62:>                                                        (0 + 3) / 10][Stage 62:>                                                        (0 + 4) / 10][Stage 62:=====>                                                   (1 + 4) / 10][Stage 62:===========>                                             (2 + 4) / 10][Stage 62:=================>                                       (3 + 4) / 10][Stage 62:======================>                                  (4 + 3) / 10][Stage 62:============================>                            (5 + 3) / 10]17/04/04 18:06:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:06:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:06:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:06:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #20
17/04/04 18:06:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #20
17/04/04 18:06:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:06:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:06:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 62:==================================>                      (6 + 3) / 10][Stage 62:=======================================>                 (7 + 3) / 10][Stage 62:=============================================>           (8 + 2) / 10][Stage 62:===================================================>     (9 + 1) / 10]17/04/04 18:06:30 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=66, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=301568
17/04/04 18:06:30 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=312551 lastFlushOffset=301867 createNewBlock=false
17/04/04 18:06:30 DEBUG DFSClient: Queued packet 66
17/04/04 18:06:30 DEBUG DFSClient: Waiting for ack for: 66
17/04/04 18:06:30 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 66 offsetInBlock: 301568 lastPacketInBlock: false lastByteOffsetInBlock: 312551
17/04/04 18:06:30 DEBUG DFSClient: DFSClient seqno: 66 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:06:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:06:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 63:===========>                                             (2 + 4) / 10][Stage 63:=================>                                       (3 + 4) / 10][Stage 63:======================>                                  (4 + 4) / 10][Stage 63:============================>                            (5 + 4) / 10][Stage 63:==================================>                      (6 + 4) / 10][Stage 63:=======================================>                 (7 + 3) / 10][Stage 63:=============================================>           (8 + 2) / 10][Stage 63:===================================================>     (9 + 1) / 10]                                                                                17/04/04 18:06:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=67, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=312320
17/04/04 18:06:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=324031 lastFlushOffset=312551 createNewBlock=false
17/04/04 18:06:41 DEBUG DFSClient: Queued packet 67
17/04/04 18:06:41 DEBUG DFSClient: Waiting for ack for: 67
17/04/04 18:06:41 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 67 offsetInBlock: 312320 lastPacketInBlock: false lastByteOffsetInBlock: 324031
17/04/04 18:06:41 DEBUG DFSClient: DFSClient seqno: 67 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:06:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=68, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=323584
17/04/04 18:06:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=324031 lastFlushOffset=324031 createNewBlock=false
17/04/04 18:06:41 DEBUG DFSClient: Waiting for ack for: 67
17/04/04 18:06:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=69, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=323584
17/04/04 18:06:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=331832 lastFlushOffset=324031 createNewBlock=false
17/04/04 18:06:41 DEBUG DFSClient: Queued packet 69
17/04/04 18:06:41 DEBUG DFSClient: Waiting for ack for: 69
17/04/04 18:06:41 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 69 offsetInBlock: 323584 lastPacketInBlock: false lastByteOffsetInBlock: 331832
17/04/04 18:06:41 DEBUG DFSClient: DFSClient seqno: 69 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 74:=====>                                                   (1 + 4) / 10][Stage 74:===========>                                             (2 + 4) / 10][Stage 74:======================>                                  (4 + 3) / 10][Stage 74:============================>                            (5 + 3) / 10][Stage 74:==================================>                      (6 + 3) / 10]17/04/04 18:06:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:06:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:06:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:06:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #21
17/04/04 18:06:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #21
17/04/04 18:06:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:06:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:06:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 74:=======================================>                 (7 + 3) / 10][Stage 74:=============================================>           (8 + 2) / 10][Stage 74:===================================================>     (9 + 1) / 10]17/04/04 18:06:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=70, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=331776
17/04/04 18:06:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=336712 lastFlushOffset=331832 createNewBlock=false
17/04/04 18:06:53 DEBUG DFSClient: Queued packet 70
17/04/04 18:06:53 DEBUG DFSClient: Waiting for ack for: 70
17/04/04 18:06:53 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 70 offsetInBlock: 331776 lastPacketInBlock: false lastByteOffsetInBlock: 336712
17/04/04 18:06:55 DEBUG DFSClient: DFSClient seqno: 70 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 75:>                                                        (0 + 3) / 10][Stage 75:>                                                        (0 + 4) / 10]17/04/04 18:07:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:07:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 75:=====>                                                   (1 + 4) / 10][Stage 75:===========>                                             (2 + 4) / 10][Stage 75:=================>                                       (3 + 4) / 10]17/04/04 18:07:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:07:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:07:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:07:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #22
17/04/04 18:07:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #22
17/04/04 18:07:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:07:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:07:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 75:======================>                                  (4 + 3) / 10][Stage 75:======================>                                  (4 + 4) / 10]17/04/04 18:07:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:07:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 75:============================>                            (5 + 4) / 10]17/04/04 18:07:44 WARN TaskSetManager: Lost task 5.0 in stage 75.0 (TID 253, 172.21.15.173, executor 0): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at com.esotericsoftware.kryo.io.Input.readDoubles(Input.java:885)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:222)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:205)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:70)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)

17/04/04 18:07:45 ERROR TaskSchedulerImpl: Lost executor 0 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:07:45 WARN TaskSetManager: Lost task 8.0 in stage 75.0 (TID 256, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:07:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=71, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=336384
17/04/04 18:07:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=349571 lastFlushOffset=336712 createNewBlock=false
17/04/04 18:07:45 DEBUG DFSClient: Queued packet 71
17/04/04 18:07:45 DEBUG DFSClient: Waiting for ack for: 71
17/04/04 18:07:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 71 offsetInBlock: 336384 lastPacketInBlock: false lastByteOffsetInBlock: 349571
[Stage 75:============================>                            (5 + 3) / 10]17/04/04 18:07:45 WARN DFSClient: Slow ReadProcessor read fields took 50787ms (threshold=30000ms); ack: seqno: 71 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:07:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=72, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=349184
17/04/04 18:07:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=349571 lastFlushOffset=349571 createNewBlock=false
17/04/04 18:07:45 DEBUG DFSClient: Waiting for ack for: 71
[Stage 75:==================================>                      (6 + 3) / 10]17/04/04 18:07:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:07:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:07:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:07:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #23
17/04/04 18:07:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #23
17/04/04 18:07:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:07:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:07:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:07:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=73, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=349184
17/04/04 18:07:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=349571 lastFlushOffset=349571 createNewBlock=false
17/04/04 18:07:54 DEBUG DFSClient: Waiting for ack for: 71
[Stage 75:==================================>                      (6 + 4) / 10]17/04/04 18:07:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=74, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=349184
17/04/04 18:07:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=349571 lastFlushOffset=349571 createNewBlock=false
17/04/04 18:07:54 DEBUG DFSClient: Waiting for ack for: 71
17/04/04 18:07:55 WARN TaskSetManager: Lost task 5.1 in stage 75.0 (TID 258, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:07:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=75, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=349184
17/04/04 18:07:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=354476 lastFlushOffset=349571 createNewBlock=false
17/04/04 18:07:55 DEBUG DFSClient: Queued packet 75
17/04/04 18:07:55 DEBUG DFSClient: Waiting for ack for: 75
17/04/04 18:07:55 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 75 offsetInBlock: 349184 lastPacketInBlock: false lastByteOffsetInBlock: 354476
17/04/04 18:07:55 DEBUG DFSClient: DFSClient seqno: 75 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 64:>                                                         (0 + 1) / 3][Stage 64:===================>                                      (1 + 1) / 3]17/04/04 18:08:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:08:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:08:01 WARN TaskSetManager: Lost task 6.0 in stage 75.0 (TID 254, 172.21.15.173, executor 4): FetchFailed(BlockManagerId(0, 172.21.15.173, 35378, None), shuffleId=9, mapId=5, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:35378
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:35378
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:35378
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
17/04/04 18:08:01 WARN TaskSetManager: Lost task 9.0 in stage 75.0 (TID 255, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(0, 172.21.15.173, 35378, None), shuffleId=7, mapId=2, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:35378
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:35378
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:35378
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
[Stage 64:===================>                                      (1 + 2) / 3][Stage 64:======================================>                   (2 + 1) / 3]17/04/04 18:08:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=76, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=354304
17/04/04 18:08:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=364403 lastFlushOffset=354476 createNewBlock=false
17/04/04 18:08:05 DEBUG DFSClient: Queued packet 76
17/04/04 18:08:05 DEBUG DFSClient: Waiting for ack for: 76
17/04/04 18:08:05 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 76 offsetInBlock: 354304 lastPacketInBlock: false lastByteOffsetInBlock: 364403
17/04/04 18:08:05 DEBUG DFSClient: DFSClient seqno: 76 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 65:>                                                         (0 + 0) / 4]17/04/04 18:08:06 WARN TaskSetManager: Lost task 8.1 in stage 75.0 (TID 257, 172.21.15.173, executor 1): FetchFailed(BlockManagerId(0, 172.21.15.173, 35378, None), shuffleId=2, mapId=0, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:35378
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:35378
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:35378
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
[Stage 65:>                                                         (0 + 1) / 4][Stage 65:>                                                         (0 + 4) / 4][Stage 65:==============>                                           (1 + 3) / 4][Stage 65:=============================>                            (2 + 2) / 4][Stage 65:===========================================>              (3 + 1) / 4]17/04/04 18:08:14 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=77, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=364032
17/04/04 18:08:14 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=370566 lastFlushOffset=364403 createNewBlock=false
17/04/04 18:08:14 DEBUG DFSClient: Queued packet 77
17/04/04 18:08:14 DEBUG DFSClient: Waiting for ack for: 77
17/04/04 18:08:14 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 77 offsetInBlock: 364032 lastPacketInBlock: false lastByteOffsetInBlock: 370566
17/04/04 18:08:14 DEBUG DFSClient: DFSClient seqno: 77 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:08:14 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=78, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=370176
17/04/04 18:08:14 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=375462 lastFlushOffset=370566 createNewBlock=false
17/04/04 18:08:14 DEBUG DFSClient: Queued packet 78
17/04/04 18:08:14 DEBUG DFSClient: Waiting for ack for: 78
17/04/04 18:08:14 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 78 offsetInBlock: 370176 lastPacketInBlock: false lastByteOffsetInBlock: 375462
17/04/04 18:08:14 DEBUG DFSClient: DFSClient seqno: 78 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 67:>                                                         (0 + 3) / 3][Stage 67:===================>                                      (1 + 2) / 3]17/04/04 18:08:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=79, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=375296
17/04/04 18:08:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=380471 lastFlushOffset=375462 createNewBlock=false
17/04/04 18:08:15 DEBUG DFSClient: Queued packet 79
17/04/04 18:08:15 DEBUG DFSClient: Waiting for ack for: 79
17/04/04 18:08:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 79 offsetInBlock: 375296 lastPacketInBlock: false lastByteOffsetInBlock: 380471
17/04/04 18:08:15 DEBUG DFSClient: DFSClient seqno: 79 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:08:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=80, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=380416
17/04/04 18:08:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=380471 lastFlushOffset=380471 createNewBlock=false
17/04/04 18:08:15 DEBUG DFSClient: Waiting for ack for: 79
[Stage 69:>                                                         (0 + 3) / 4][Stage 69:==============>                                           (1 + 3) / 4][Stage 69:===========================================>              (3 + 1) / 4]17/04/04 18:08:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=81, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=380416
17/04/04 18:08:18 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=385381 lastFlushOffset=380471 createNewBlock=false
17/04/04 18:08:18 DEBUG DFSClient: Queued packet 81
17/04/04 18:08:18 DEBUG DFSClient: Waiting for ack for: 81
17/04/04 18:08:18 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 81 offsetInBlock: 380416 lastPacketInBlock: false lastByteOffsetInBlock: 385381
17/04/04 18:08:18 DEBUG DFSClient: DFSClient seqno: 81 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 70:>                                                         (0 + 3) / 3][Stage 70:===================>                                      (1 + 2) / 3]17/04/04 18:08:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=82, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=385024
17/04/04 18:08:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=390770 lastFlushOffset=385381 createNewBlock=false
17/04/04 18:08:19 DEBUG DFSClient: Queued packet 82
17/04/04 18:08:19 DEBUG DFSClient: Waiting for ack for: 82
17/04/04 18:08:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 82 offsetInBlock: 385024 lastPacketInBlock: false lastByteOffsetInBlock: 390770
17/04/04 18:08:19 DEBUG DFSClient: DFSClient seqno: 82 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 71:>                                                         (0 + 4) / 4]17/04/04 18:08:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:08:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:08:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:08:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #24
17/04/04 18:08:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #24
17/04/04 18:08:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:08:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:08:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:08:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:08:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:08:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:08:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:08:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:08:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #25
17/04/04 18:08:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #25
17/04/04 18:08:51 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:08:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:08:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 71:==============>                                           (1 + 3) / 4][Stage 71:=============================>                            (2 + 2) / 4][Stage 71:===========================================>              (3 + 1) / 4]17/04/04 18:08:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=83, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=390656
17/04/04 18:08:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=395891 lastFlushOffset=390770 createNewBlock=false
17/04/04 18:08:54 DEBUG DFSClient: Queued packet 83
17/04/04 18:08:54 DEBUG DFSClient: Waiting for ack for: 83
17/04/04 18:08:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 83 offsetInBlock: 390656 lastPacketInBlock: false lastByteOffsetInBlock: 395891
17/04/04 18:08:55 WARN DFSClient: Slow ReadProcessor read fields took 35843ms (threshold=30000ms); ack: seqno: 83 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 72:>                                                         (0 + 3) / 3][Stage 72:===================>                                      (1 + 2) / 3][Stage 72:======================================>                   (2 + 1) / 3]17/04/04 18:09:01 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=84, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=395776
17/04/04 18:09:01 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=401316 lastFlushOffset=395891 createNewBlock=false
17/04/04 18:09:01 DEBUG DFSClient: Queued packet 84
17/04/04 18:09:01 DEBUG DFSClient: Waiting for ack for: 84
17/04/04 18:09:01 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 84 offsetInBlock: 395776 lastPacketInBlock: false lastByteOffsetInBlock: 401316
17/04/04 18:09:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:09:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:09:01 DEBUG DFSClient: DFSClient seqno: 84 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 73:>                                                         (0 + 3) / 3][Stage 73:===================>                                      (1 + 2) / 3][Stage 73:======================================>                   (2 + 1) / 3]17/04/04 18:09:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=85, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=400896
17/04/04 18:09:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=406424 lastFlushOffset=401316 createNewBlock=false
17/04/04 18:09:06 DEBUG DFSClient: Queued packet 85
17/04/04 18:09:06 DEBUG DFSClient: Waiting for ack for: 85
17/04/04 18:09:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 85 offsetInBlock: 400896 lastPacketInBlock: false lastByteOffsetInBlock: 406424
17/04/04 18:09:06 DEBUG DFSClient: DFSClient seqno: 85 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:09:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=86, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=406016
17/04/04 18:09:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=411717 lastFlushOffset=406424 createNewBlock=false
17/04/04 18:09:07 DEBUG DFSClient: Queued packet 86
17/04/04 18:09:07 DEBUG DFSClient: Waiting for ack for: 86
17/04/04 18:09:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 86 offsetInBlock: 406016 lastPacketInBlock: false lastByteOffsetInBlock: 411717
17/04/04 18:09:07 DEBUG DFSClient: DFSClient seqno: 86 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 75:>                                                         (0 + 4) / 4][Stage 75:==============>                                           (1 + 3) / 4]17/04/04 18:09:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:09:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:09:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:09:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #26
17/04/04 18:09:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #26
17/04/04 18:09:21 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:09:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:09:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 75:=============================>                            (2 + 2) / 4]17/04/04 18:09:25 WARN TaskSetManager: Lost task 3.0 in stage 75.1 (TID 297, 172.21.15.173, executor 3): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Double.valueOf(Double.java:521)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$DoubleSerializer.read(DefaultSerializers.java:179)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$DoubleSerializer.read(DefaultSerializers.java:169)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:71)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)

17/04/04 18:09:28 WARN TaskSetManager: Lost task 2.0 in stage 75.1 (TID 294, 172.21.15.173, executor 1): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Input.readDoubles(Input.java:885)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:222)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:205)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:70)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)

17/04/04 18:09:28 ERROR TaskSchedulerImpl: Lost executor 1 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:09:28 WARN TaskSetManager: Lost task 2.1 in stage 75.1 (TID 299, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:09:28 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=87, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=411648
17/04/04 18:09:28 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=421758 lastFlushOffset=411717 createNewBlock=false
17/04/04 18:09:28 DEBUG DFSClient: Queued packet 87
17/04/04 18:09:28 DEBUG DFSClient: Waiting for ack for: 87
17/04/04 18:09:28 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 87 offsetInBlock: 411648 lastPacketInBlock: false lastByteOffsetInBlock: 421758
[Stage 75:=============================>                            (2 + 1) / 4]17/04/04 18:09:29 WARN TaskSetManager: Lost task 2.2 in stage 75.1 (TID 300, 172.21.15.173, executor 5): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:88)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:09:29 DEBUG DFSClient: DFSClient seqno: 87 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:09:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=88, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=421376
17/04/04 18:09:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=421758 lastFlushOffset=421758 createNewBlock=false
17/04/04 18:09:29 DEBUG DFSClient: Waiting for ack for: 87
17/04/04 18:09:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=89, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=421376
17/04/04 18:09:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=421758 lastFlushOffset=421758 createNewBlock=false
17/04/04 18:09:29 DEBUG DFSClient: Waiting for ack for: 87
17/04/04 18:09:29 ERROR TaskSchedulerImpl: Lost executor 3 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:09:29 WARN TaskSetManager: Lost task 3.1 in stage 75.1 (TID 298, 172.21.15.173, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:09:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=90, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=421376
17/04/04 18:09:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=421758 lastFlushOffset=421758 createNewBlock=false
17/04/04 18:09:29 DEBUG DFSClient: Waiting for ack for: 87
17/04/04 18:09:29 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=91, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=421376
17/04/04 18:09:29 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=421758 lastFlushOffset=421758 createNewBlock=false
17/04/04 18:09:29 DEBUG DFSClient: Waiting for ack for: 87
[Stage 64:>                                                         (0 + 2) / 7]17/04/04 18:09:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:09:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 64:========>                                                 (1 + 2) / 7][Stage 64:================>                                         (2 + 2) / 7]17/04/04 18:09:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=92, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=421376
17/04/04 18:09:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=426692 lastFlushOffset=421758 createNewBlock=false
17/04/04 18:09:40 DEBUG DFSClient: Queued packet 92
17/04/04 18:09:40 DEBUG DFSClient: Waiting for ack for: 92
17/04/04 18:09:40 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 92 offsetInBlock: 421376 lastPacketInBlock: false lastByteOffsetInBlock: 426692
17/04/04 18:09:40 DEBUG DFSClient: DFSClient seqno: 92 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:09:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=93, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=426496
17/04/04 18:09:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=426692 lastFlushOffset=426692 createNewBlock=false
17/04/04 18:09:40 DEBUG DFSClient: Waiting for ack for: 92
[Stage 64:========================>                                 (3 + 4) / 7]17/04/04 18:09:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=94, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=426496
17/04/04 18:09:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=426692 lastFlushOffset=426692 createNewBlock=false
17/04/04 18:09:40 DEBUG DFSClient: Waiting for ack for: 92
17/04/04 18:09:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=95, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=426496
17/04/04 18:09:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=426692 lastFlushOffset=426692 createNewBlock=false
17/04/04 18:09:40 DEBUG DFSClient: Waiting for ack for: 92
[Stage 64:=================================>                        (4 + 3) / 7][Stage 64:=========================================>                (5 + 2) / 7][Stage 64:=================================================>        (6 + 1) / 7]17/04/04 18:09:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=96, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=426496
17/04/04 18:09:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=430524 lastFlushOffset=426692 createNewBlock=false
17/04/04 18:09:45 DEBUG DFSClient: Queued packet 96
17/04/04 18:09:45 DEBUG DFSClient: Waiting for ack for: 96
17/04/04 18:09:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 96 offsetInBlock: 426496 lastPacketInBlock: false lastByteOffsetInBlock: 430524
17/04/04 18:09:45 DEBUG DFSClient: DFSClient seqno: 96 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 65:>                                                         (0 + 4) / 8]17/04/04 18:09:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:09:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:09:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:09:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #27
17/04/04 18:09:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #27
17/04/04 18:09:51 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/04/04 18:09:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:09:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 65:=======>                                                  (1 + 4) / 8][Stage 65:==============>                                           (2 + 4) / 8][Stage 65:=====================>                                    (3 + 4) / 8][Stage 65:=============================>                            (4 + 4) / 8][Stage 65:====================================>                     (5 + 3) / 8][Stage 65:===========================================>              (6 + 2) / 8][Stage 65:==================================================>       (7 + 1) / 8]17/04/04 18:10:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=97, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=430080
17/04/04 18:10:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=448219 lastFlushOffset=430524 createNewBlock=false
17/04/04 18:10:00 DEBUG DFSClient: Queued packet 97
17/04/04 18:10:00 DEBUG DFSClient: Waiting for ack for: 97
17/04/04 18:10:00 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 97 offsetInBlock: 430080 lastPacketInBlock: false lastByteOffsetInBlock: 448219
17/04/04 18:10:00 DEBUG DFSClient: DFSClient seqno: 97 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:10:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=98, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=448000
17/04/04 18:10:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=453320 lastFlushOffset=448219 createNewBlock=false
17/04/04 18:10:00 DEBUG DFSClient: Queued packet 98
17/04/04 18:10:00 DEBUG DFSClient: Waiting for ack for: 98
17/04/04 18:10:00 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 98 offsetInBlock: 448000 lastPacketInBlock: false lastByteOffsetInBlock: 453320
17/04/04 18:10:00 DEBUG DFSClient: DFSClient seqno: 98 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:10:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:10:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 67:=======>                                                  (1 + 4) / 8][Stage 67:==============>                                           (2 + 4) / 8][Stage 67:=============================>                            (4 + 4) / 8][Stage 67:===========================================>              (6 + 2) / 8][Stage 67:==================================================>       (7 + 1) / 8]17/04/04 18:10:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=99, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=453120
17/04/04 18:10:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=458674 lastFlushOffset=453320 createNewBlock=false
17/04/04 18:10:06 DEBUG DFSClient: Queued packet 99
17/04/04 18:10:06 DEBUG DFSClient: Waiting for ack for: 99
17/04/04 18:10:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 99 offsetInBlock: 453120 lastPacketInBlock: false lastByteOffsetInBlock: 458674
17/04/04 18:10:06 DEBUG DFSClient: DFSClient seqno: 99 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 68:>                                                         (0 + 0) / 7][Stage 68:================>                                         (2 + 5) / 7][Stage 68:=================================================>        (6 + 1) / 7]17/04/04 18:10:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=100, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=458240
17/04/04 18:10:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=469322 lastFlushOffset=458674 createNewBlock=false
17/04/04 18:10:06 DEBUG DFSClient: Queued packet 100
17/04/04 18:10:06 DEBUG DFSClient: Waiting for ack for: 100
17/04/04 18:10:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 100 offsetInBlock: 458240 lastPacketInBlock: false lastByteOffsetInBlock: 469322
17/04/04 18:10:06 DEBUG DFSClient: DFSClient seqno: 100 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 69:>                                                         (0 + 4) / 8][Stage 69:=====================>                                    (3 + 4) / 8][Stage 69:=============================>                            (4 + 4) / 8][Stage 69:====================================>                     (5 + 3) / 8][Stage 69:===========================================>              (6 + 2) / 8][Stage 69:==================================================>       (7 + 1) / 8]17/04/04 18:10:12 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=101, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=468992
17/04/04 18:10:12 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=474844 lastFlushOffset=469322 createNewBlock=false
17/04/04 18:10:12 DEBUG DFSClient: Queued packet 101
17/04/04 18:10:12 DEBUG DFSClient: Waiting for ack for: 101
17/04/04 18:10:12 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 101 offsetInBlock: 468992 lastPacketInBlock: false lastByteOffsetInBlock: 474844
17/04/04 18:10:12 DEBUG DFSClient: DFSClient seqno: 101 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 70:>                                                         (0 + 4) / 7][Stage 70:========>                                                 (1 + 4) / 7][Stage 70:================>                                         (2 + 4) / 7][Stage 70:========================>                                 (3 + 4) / 7][Stage 70:=================================>                        (4 + 3) / 7][Stage 70:=========================================>                (5 + 2) / 7][Stage 70:=================================================>        (6 + 1) / 7]17/04/04 18:10:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=102, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=474624
17/04/04 18:10:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=486596 lastFlushOffset=474844 createNewBlock=false
17/04/04 18:10:17 DEBUG DFSClient: Queued packet 102
17/04/04 18:10:17 DEBUG DFSClient: Waiting for ack for: 102
17/04/04 18:10:17 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 102 offsetInBlock: 474624 lastPacketInBlock: false lastByteOffsetInBlock: 486596
17/04/04 18:10:17 DEBUG DFSClient: DFSClient seqno: 102 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 71:>                                                         (0 + 4) / 8]17/04/04 18:10:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:10:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:10:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:10:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #28
17/04/04 18:10:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #28
17/04/04 18:10:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:10:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:10:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:10:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:10:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:10:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:10:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:10:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:10:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #29
17/04/04 18:10:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #29
17/04/04 18:10:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:10:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:10:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 71:=======>                                                  (1 + 4) / 8][Stage 71:==============>                                           (2 + 4) / 8][Stage 71:=====================>                                    (3 + 4) / 8][Stage 71:=============================>                            (4 + 4) / 8]17/04/04 18:11:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:11:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:11:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:11:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:11:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:11:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #30
17/04/04 18:11:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #30
17/04/04 18:11:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:11:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:11:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 71:====================================>                     (5 + 3) / 8][Stage 71:===========================================>              (6 + 2) / 8]17/04/04 18:11:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:11:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 71:==================================================>       (7 + 1) / 8]17/04/04 18:11:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:11:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:11:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:11:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #31
17/04/04 18:11:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #31
17/04/04 18:11:51 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:11:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:11:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:11:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=103, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=486400
17/04/04 18:11:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=492050 lastFlushOffset=486596 createNewBlock=false
17/04/04 18:11:57 DEBUG DFSClient: Queued packet 103
17/04/04 18:11:57 DEBUG DFSClient: Waiting for ack for: 103
17/04/04 18:11:57 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 103 offsetInBlock: 486400 lastPacketInBlock: false lastByteOffsetInBlock: 492050
17/04/04 18:11:57 WARN DFSClient: Slow ReadProcessor read fields took 100355ms (threshold=30000ms); ack: seqno: 103 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 72:>                                                         (0 + 4) / 7]17/04/04 18:12:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:12:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 72:========>                                                 (1 + 4) / 7][Stage 72:================>                                         (2 + 4) / 7][Stage 72:========================>                                 (3 + 4) / 7][Stage 72:=================================>                        (4 + 3) / 7][Stage 72:=========================================>                (5 + 2) / 7][Stage 72:=================================================>        (6 + 1) / 7]17/04/04 18:12:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=104, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=492032
17/04/04 18:12:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=502491 lastFlushOffset=492050 createNewBlock=false
17/04/04 18:12:15 DEBUG DFSClient: Queued packet 104
17/04/04 18:12:15 DEBUG DFSClient: Waiting for ack for: 104
17/04/04 18:12:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 104 offsetInBlock: 492032 lastPacketInBlock: false lastByteOffsetInBlock: 502491
17/04/04 18:12:15 DEBUG DFSClient: DFSClient seqno: 104 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 73:>                                                         (0 + 4) / 7]17/04/04 18:12:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:12:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:12:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:12:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #32
17/04/04 18:12:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #32
17/04/04 18:12:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:12:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:12:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:12:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:12:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 73:================>                                         (2 + 4) / 7][Stage 73:=================================================>        (6 + 1) / 7]17/04/04 18:12:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:12:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:12:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:12:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #33
17/04/04 18:12:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #33
17/04/04 18:12:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:12:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:12:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:12:52 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=105, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=502272
17/04/04 18:12:52 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=512378 lastFlushOffset=502491 createNewBlock=false
17/04/04 18:12:52 DEBUG DFSClient: Queued packet 105
17/04/04 18:12:52 DEBUG DFSClient: Waiting for ack for: 105
17/04/04 18:12:52 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 105 offsetInBlock: 502272 lastPacketInBlock: false lastByteOffsetInBlock: 512378
17/04/04 18:12:53 WARN DFSClient: Slow ReadProcessor read fields took 37707ms (threshold=30000ms); ack: seqno: 105 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 74:>                                                         (0 + 1) / 6][Stage 74:=========>                                                (1 + 1) / 6][Stage 74:=========>                                                (1 + 4) / 6]17/04/04 18:13:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:13:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 74:===================>                                      (2 + 4) / 6][Stage 74:=============================>                            (3 + 3) / 6]17/04/04 18:13:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:13:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:13:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:13:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #34
17/04/04 18:13:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #34
17/04/04 18:13:21 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:13:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:13:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 74:======================================>                   (4 + 2) / 6][Stage 74:================================================>         (5 + 1) / 6]17/04/04 18:13:30 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=106, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512000
17/04/04 18:13:30 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=525036 lastFlushOffset=512378 createNewBlock=false
17/04/04 18:13:30 DEBUG DFSClient: Queued packet 106
17/04/04 18:13:30 DEBUG DFSClient: Waiting for ack for: 106
17/04/04 18:13:30 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 106 offsetInBlock: 512000 lastPacketInBlock: false lastByteOffsetInBlock: 525036
17/04/04 18:13:30 WARN DFSClient: Slow ReadProcessor read fields took 37548ms (threshold=30000ms); ack: seqno: 106 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:13:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:13:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 75:>                                                         (0 + 2) / 2]17/04/04 18:13:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:13:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:13:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:13:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #35
17/04/04 18:13:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #35
17/04/04 18:13:51 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:13:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:13:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 75:=============================>                            (1 + 1) / 2]                                                                                17/04/04 18:13:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=107, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=524800
17/04/04 18:13:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529631 lastFlushOffset=525036 createNewBlock=false
17/04/04 18:13:54 DEBUG DFSClient: Queued packet 107
17/04/04 18:13:54 DEBUG DFSClient: Waiting for ack for: 107
17/04/04 18:13:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 107 offsetInBlock: 524800 lastPacketInBlock: false lastByteOffsetInBlock: 529631
17/04/04 18:13:54 DEBUG DFSClient: DFSClient seqno: 107 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:13:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=108, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/04/04 18:13:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529631 lastFlushOffset=529631 createNewBlock=false
17/04/04 18:13:54 DEBUG DFSClient: Waiting for ack for: 107
17/04/04 18:13:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=109, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/04/04 18:13:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529631 lastFlushOffset=529631 createNewBlock=false
17/04/04 18:13:54 DEBUG DFSClient: Waiting for ack for: 107
17/04/04 18:13:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=110, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/04/04 18:13:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=529631 lastFlushOffset=529631 createNewBlock=false
17/04/04 18:13:54 DEBUG DFSClient: Waiting for ack for: 107
17/04/04 18:13:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=111, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529408
17/04/04 18:13:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=536799 lastFlushOffset=529631 createNewBlock=false
17/04/04 18:13:54 DEBUG DFSClient: Queued packet 111
17/04/04 18:13:54 DEBUG DFSClient: Waiting for ack for: 111
17/04/04 18:13:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 111 offsetInBlock: 529408 lastPacketInBlock: false lastByteOffsetInBlock: 536799
17/04/04 18:13:54 DEBUG DFSClient: DFSClient seqno: 111 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/04/04 18:14:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:14:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:14:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:14:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:14:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:14:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #36
17/04/04 18:14:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #36
17/04/04 18:14:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:14:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:14:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:14:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:14:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:14:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:14:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:14:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:14:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #37
17/04/04 18:14:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #37
17/04/04 18:14:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:14:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:14:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 87:>                                                        (0 + 4) / 10]17/04/04 18:15:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:15:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:15:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:15:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:15:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:15:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #38
17/04/04 18:15:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #38
17/04/04 18:15:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:15:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:15:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:15:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:15:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:15:44 WARN TaskSetManager: Lost task 2.0 in stage 87.0 (TID 384, 172.21.15.173, executor 4): java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:125)
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:123)
	at org.apache.spark.util.collection.OpenHashSet.rehash(OpenHashSet.scala:232)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded(OpenHashSet.scala:167)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded$mcJ$sp(OpenHashSet.scala:165)
	at org.apache.spark.graphx.util.collection.GraphXPrimitiveKeyOpenHashMap$mcJI$sp.update$mcJI$sp(GraphXPrimitiveKeyOpenHashMap.scala:77)
	at org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:65)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:110)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/04 18:15:48 ERROR TaskSchedulerImpl: Lost executor 4 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:15:48 WARN TaskSetManager: Lost task 5.0 in stage 87.0 (TID 387, 172.21.15.173, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:15:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=112, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=536576
17/04/04 18:15:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=541632 lastFlushOffset=536799 createNewBlock=false
17/04/04 18:15:48 DEBUG DFSClient: Queued packet 112
17/04/04 18:15:48 DEBUG DFSClient: Waiting for ack for: 112
17/04/04 18:15:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 112 offsetInBlock: 536576 lastPacketInBlock: false lastByteOffsetInBlock: 541632
[Stage 87:>                                                        (0 + 3) / 10]17/04/04 18:15:48 WARN DFSClient: Slow ReadProcessor read fields took 113446ms (threshold=30000ms); ack: seqno: 112 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:15:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=113, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=541184
17/04/04 18:15:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=541632 lastFlushOffset=541632 createNewBlock=false
17/04/04 18:15:48 DEBUG DFSClient: Waiting for ack for: 112
17/04/04 18:15:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:15:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:15:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:15:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #39
17/04/04 18:15:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #39
17/04/04 18:15:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:15:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:15:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:15:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=114, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=541184
17/04/04 18:15:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=541632 lastFlushOffset=541632 createNewBlock=false
17/04/04 18:15:56 DEBUG DFSClient: Waiting for ack for: 112
[Stage 87:>                                                        (0 + 4) / 10]17/04/04 18:15:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=115, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=541184
17/04/04 18:15:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=541632 lastFlushOffset=541632 createNewBlock=false
17/04/04 18:15:57 DEBUG DFSClient: Waiting for ack for: 112
17/04/04 18:15:59 WARN TaskSetManager: Lost task 1.0 in stage 87.0 (TID 383, 172.21.15.173, executor 5): java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:125)
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:123)
	at org.apache.spark.util.collection.OpenHashSet.rehash(OpenHashSet.scala:232)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded(OpenHashSet.scala:167)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded$mcJ$sp(OpenHashSet.scala:165)
	at org.apache.spark.graphx.util.collection.GraphXPrimitiveKeyOpenHashMap$mcJI$sp.update$mcJI$sp(GraphXPrimitiveKeyOpenHashMap.scala:77)
	at org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:65)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:110)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/04 18:16:00 WARN TaskSetManager: Lost task 6.0 in stage 87.0 (TID 389, 172.21.15.173, executor 5): org.apache.spark.SparkException: Block rdd_14_6 was not found even though it's read-locked
	at org.apache.spark.storage.BlockManager.handleLocalReadFailure(BlockManager.scala:436)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:478)
	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:688)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/04 18:16:00 WARN TransportChannelHandler: Exception in connection from /172.21.15.173:58620
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/04/04 18:16:00 ERROR TaskSchedulerImpl: Lost executor 5 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:16:00 WARN TaskSetManager: Lost task 1.1 in stage 87.0 (TID 390, 172.21.15.173, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:16:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=116, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=541184
17/04/04 18:16:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=546446 lastFlushOffset=541632 createNewBlock=false
17/04/04 18:16:00 DEBUG DFSClient: Queued packet 116
17/04/04 18:16:00 DEBUG DFSClient: Waiting for ack for: 116
17/04/04 18:16:00 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 116 offsetInBlock: 541184 lastPacketInBlock: false lastByteOffsetInBlock: 546446
17/04/04 18:16:00 DEBUG DFSClient: DFSClient seqno: 116 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:16:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=117, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=546304
17/04/04 18:16:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=546446 lastFlushOffset=546446 createNewBlock=false
17/04/04 18:16:00 DEBUG DFSClient: Waiting for ack for: 116
[Stage 87:>                                                        (0 + 3) / 10]17/04/04 18:16:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:16:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:16:01 WARN TaskSetManager: Lost task 5.1 in stage 87.0 (TID 388, 172.21.15.173, executor 8): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:16:01 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=118, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=546304
17/04/04 18:16:01 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=546446 createNewBlock=false
17/04/04 18:16:01 DEBUG DFSClient: Queued packet 118
17/04/04 18:16:01 DEBUG DFSClient: Waiting for ack for: 118
17/04/04 18:16:01 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 118 offsetInBlock: 546304 lastPacketInBlock: false lastByteOffsetInBlock: 551074
17/04/04 18:16:01 DEBUG DFSClient: DFSClient seqno: 118 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 76:>                                                         (0 + 1) / 8]17/04/04 18:16:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=119, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:04 DEBUG DFSClient: Waiting for ack for: 118
17/04/04 18:16:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=120, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:04 DEBUG DFSClient: Waiting for ack for: 118
[Stage 76:>                                                         (0 + 2) / 8][Stage 76:>                                                         (0 + 3) / 8]17/04/04 18:16:05 ERROR TaskSchedulerImpl: Lost executor 7 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:16:05 WARN TaskSetManager: Lost task 2.0 in stage 76.0 (TID 393, 172.21.15.173, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:16:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=121, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:05 DEBUG DFSClient: Waiting for ack for: 118
17/04/04 18:16:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=122, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:05 DEBUG DFSClient: Waiting for ack for: 118
[Stage 76:>                                                         (0 + 2) / 8]17/04/04 18:16:09 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=123, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:09 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:09 DEBUG DFSClient: Waiting for ack for: 118
[Stage 76:>                                                         (0 + 3) / 8]17/04/04 18:16:09 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=124, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:09 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=551074 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:09 DEBUG DFSClient: Waiting for ack for: 118
[Stage 76:=======>                                                  (1 + 3) / 8][Stage 76:==============>                                           (2 + 3) / 8][Stage 76:=====================>                                    (3 + 3) / 8]17/04/04 18:16:20 WARN TaskSetManager: Lost task 0.0 in stage 87.0 (TID 386, 172.21.15.173, executor 6): java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:125)
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:123)
	at org.apache.spark.util.collection.OpenHashSet.rehash(OpenHashSet.scala:232)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded(OpenHashSet.scala:167)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded$mcJ$sp(OpenHashSet.scala:165)
	at org.apache.spark.graphx.util.collection.GraphXPrimitiveKeyOpenHashMap$mcJI$sp.update$mcJI$sp(GraphXPrimitiveKeyOpenHashMap.scala:77)
	at org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:65)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:110)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

[Stage 76:=====================>                                    (3 + 4) / 8]17/04/04 18:16:20 ERROR TaskSchedulerImpl: Lost executor 6 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:16:20 WARN TaskSetManager: Lost task 6.0 in stage 76.0 (TID 398, 172.21.15.173, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:16:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=125, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=550912
17/04/04 18:16:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=561765 lastFlushOffset=551074 createNewBlock=false
17/04/04 18:16:20 DEBUG DFSClient: Queued packet 125
17/04/04 18:16:20 DEBUG DFSClient: Waiting for ack for: 125
17/04/04 18:16:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 125 offsetInBlock: 550912 lastPacketInBlock: false lastByteOffsetInBlock: 561765
17/04/04 18:16:20 DEBUG DFSClient: DFSClient seqno: 125 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:16:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=126, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=561664
17/04/04 18:16:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=561765 lastFlushOffset=561765 createNewBlock=false
17/04/04 18:16:20 DEBUG DFSClient: Waiting for ack for: 125
[Stage 76:=====================>                                    (3 + 3) / 8]17/04/04 18:16:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:16:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:16:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:16:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #40
17/04/04 18:16:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #40
17/04/04 18:16:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:16:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:16:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 76:=============================>                            (4 + 3) / 8][Stage 76:====================================>                     (5 + 3) / 8][Stage 76:===========================================>              (6 + 2) / 8][Stage 76:==================================================>       (7 + 1) / 8]17/04/04 18:16:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=127, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=561664
17/04/04 18:16:23 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=561765 lastFlushOffset=561765 createNewBlock=false
17/04/04 18:16:23 DEBUG DFSClient: Waiting for ack for: 125
17/04/04 18:16:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=128, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=561664
17/04/04 18:16:23 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=561765 lastFlushOffset=561765 createNewBlock=false
17/04/04 18:16:23 DEBUG DFSClient: Waiting for ack for: 125
17/04/04 18:16:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=129, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=561664
17/04/04 18:16:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=565930 lastFlushOffset=561765 createNewBlock=false
17/04/04 18:16:24 DEBUG DFSClient: Queued packet 129
17/04/04 18:16:24 DEBUG DFSClient: Waiting for ack for: 129
17/04/04 18:16:24 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 129 offsetInBlock: 561664 lastPacketInBlock: false lastByteOffsetInBlock: 565930
17/04/04 18:16:24 DEBUG DFSClient: DFSClient seqno: 129 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 76:>                                                         (0 + 2) / 2][Stage 76:=============================>                            (1 + 1) / 2]17/04/04 18:16:28 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=130, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=565760
17/04/04 18:16:28 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=565930 lastFlushOffset=565930 createNewBlock=false
17/04/04 18:16:28 DEBUG DFSClient: Waiting for ack for: 129
[Stage 77:>                                                        (0 + 4) / 10]17/04/04 18:16:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:16:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 77:=====>                                                   (1 + 4) / 10][Stage 77:===========>                                             (2 + 4) / 10][Stage 77:======================>                                  (4 + 4) / 10][Stage 77:============================>                            (5 + 4) / 10][Stage 77:==================================>                      (6 + 4) / 10][Stage 77:=======================================>                 (7 + 3) / 10][Stage 77:=============================================>           (8 + 2) / 10][Stage 77:===================================================>     (9 + 1) / 10]17/04/04 18:16:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=131, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=565760
17/04/04 18:16:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=580487 lastFlushOffset=565930 createNewBlock=false
17/04/04 18:16:47 DEBUG DFSClient: Queued packet 131
17/04/04 18:16:47 DEBUG DFSClient: Waiting for ack for: 131
17/04/04 18:16:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 131 offsetInBlock: 565760 lastPacketInBlock: false lastByteOffsetInBlock: 580487
17/04/04 18:16:47 DEBUG DFSClient: DFSClient seqno: 131 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 78:=====>                                                   (1 + 4) / 10][Stage 78:============================>                            (5 + 4) / 10][Stage 78:===================================================>     (9 + 1) / 10]17/04/04 18:16:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=132, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=580096
17/04/04 18:16:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=589620 lastFlushOffset=580487 createNewBlock=false
17/04/04 18:16:48 DEBUG DFSClient: Queued packet 132
17/04/04 18:16:48 DEBUG DFSClient: Waiting for ack for: 132
17/04/04 18:16:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 132 offsetInBlock: 580096 lastPacketInBlock: false lastByteOffsetInBlock: 589620
17/04/04 18:16:48 DEBUG DFSClient: DFSClient seqno: 132 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                        (0 + 4) / 10][Stage 79:=====>                                                   (1 + 4) / 10][Stage 79:=================>                                       (3 + 4) / 10][Stage 79:======================>                                  (4 + 4) / 10][Stage 79:============================>                            (5 + 3) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/04/04 18:16:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:16:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:16:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:16:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #41
17/04/04 18:16:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #41
17/04/04 18:16:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:16:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:16:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:16:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=133, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=589312
17/04/04 18:16:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=600578 lastFlushOffset=589620 createNewBlock=false
17/04/04 18:16:53 DEBUG DFSClient: Queued packet 133
17/04/04 18:16:53 DEBUG DFSClient: Waiting for ack for: 133
17/04/04 18:16:53 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 133 offsetInBlock: 589312 lastPacketInBlock: false lastByteOffsetInBlock: 600578
17/04/04 18:16:53 DEBUG DFSClient: DFSClient seqno: 133 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:======================>                                  (4 + 4) / 10][Stage 80:=======================================>                 (7 + 3) / 10][Stage 80:===================================================>     (9 + 1) / 10]17/04/04 18:16:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=134, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=600576
17/04/04 18:16:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=605602 lastFlushOffset=600578 createNewBlock=false
17/04/04 18:16:54 DEBUG DFSClient: Queued packet 134
17/04/04 18:16:54 DEBUG DFSClient: Waiting for ack for: 134
17/04/04 18:16:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 134 offsetInBlock: 600576 lastPacketInBlock: false lastByteOffsetInBlock: 605602
17/04/04 18:16:54 DEBUG DFSClient: DFSClient seqno: 134 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:==================================>                      (6 + 2) / 10][Stage 81:=============================================>           (8 + 2) / 10][Stage 81:===================================================>     (9 + 1) / 10]17/04/04 18:17:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:17:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:17:01 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=135, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=605184
17/04/04 18:17:01 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=616595 lastFlushOffset=605602 createNewBlock=false
17/04/04 18:17:01 DEBUG DFSClient: Queued packet 135
17/04/04 18:17:01 DEBUG DFSClient: Waiting for ack for: 135
17/04/04 18:17:01 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 135 offsetInBlock: 605184 lastPacketInBlock: false lastByteOffsetInBlock: 616595
17/04/04 18:17:01 DEBUG DFSClient: DFSClient seqno: 135 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:=====>                                                   (1 + 4) / 10][Stage 82:===========>                                             (2 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:============================>                            (5 + 4) / 10][Stage 82:==================================>                      (6 + 4) / 10][Stage 82:=======================================>                 (7 + 3) / 10][Stage 82:=============================================>           (8 + 2) / 10][Stage 82:===================================================>     (9 + 1) / 10]17/04/04 18:17:08 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=136, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=616448
17/04/04 18:17:08 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=628086 lastFlushOffset=616595 createNewBlock=false
17/04/04 18:17:08 DEBUG DFSClient: Queued packet 136
17/04/04 18:17:08 DEBUG DFSClient: Waiting for ack for: 136
17/04/04 18:17:08 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 136 offsetInBlock: 616448 lastPacketInBlock: false lastByteOffsetInBlock: 628086
17/04/04 18:17:09 DEBUG DFSClient: DFSClient seqno: 136 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/04/04 18:17:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:17:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:17:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:17:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #42
17/04/04 18:17:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #42
17/04/04 18:17:21 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/04/04 18:17:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:17:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:17:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:17:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:=====>                                                   (1 + 4) / 10][Stage 83:===========>                                             (2 + 4) / 10]17/04/04 18:17:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:17:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:17:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:17:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #43
17/04/04 18:17:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #43
17/04/04 18:17:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:17:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:17:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 83:=================>                                       (3 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/04/04 18:18:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:18:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:============================>                            (5 + 4) / 10]17/04/04 18:18:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:18:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:18:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:18:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #44
17/04/04 18:18:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #44
17/04/04 18:18:21 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:18:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:18:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 83:==================================>                      (6 + 4) / 10][Stage 83:=======================================>                 (7 + 3) / 10][Stage 83:=============================================>           (8 + 2) / 10]17/04/04 18:18:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:18:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===================================================>     (9 + 1) / 10]17/04/04 18:18:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:18:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:18:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:18:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #45
17/04/04 18:18:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #45
17/04/04 18:18:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:18:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:18:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:19:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:19:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:19:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=137, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=627712
17/04/04 18:19:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=633492 lastFlushOffset=628086 createNewBlock=false
17/04/04 18:19:04 DEBUG DFSClient: Queued packet 137
17/04/04 18:19:04 DEBUG DFSClient: Waiting for ack for: 137
17/04/04 18:19:04 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 137 offsetInBlock: 627712 lastPacketInBlock: false lastByteOffsetInBlock: 633492
17/04/04 18:19:04 WARN DFSClient: Slow ReadProcessor read fields took 115419ms (threshold=30000ms); ack: seqno: 137 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                        (0 + 4) / 10][Stage 84:=====>                                                   (1 + 4) / 10]17/04/04 18:19:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:19:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:19:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:19:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #46
17/04/04 18:19:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #46
17/04/04 18:19:21 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:19:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:19:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 84:===========>                                             (2 + 4) / 10][Stage 84:=================>                                       (3 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10]17/04/04 18:19:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:19:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10][Stage 84:===================================================>     (9 + 1) / 10]17/04/04 18:19:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=138, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=633344
17/04/04 18:19:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=645201 lastFlushOffset=633492 createNewBlock=false
17/04/04 18:19:47 DEBUG DFSClient: Queued packet 138
17/04/04 18:19:47 DEBUG DFSClient: Waiting for ack for: 138
17/04/04 18:19:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 138 offsetInBlock: 633344 lastPacketInBlock: false lastByteOffsetInBlock: 645201
17/04/04 18:19:48 WARN DFSClient: Slow ReadProcessor read fields took 43597ms (threshold=30000ms); ack: seqno: 138 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 85:>                                                        (0 + 4) / 10]17/04/04 18:19:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:19:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:19:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:19:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #47
17/04/04 18:19:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #47
17/04/04 18:19:51 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/04/04 18:19:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:19:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 85:=====>                                                   (1 + 4) / 10]17/04/04 18:20:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:20:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 85:===========>                                             (2 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10][Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10][Stage 85:===================================================>     (9 + 1) / 10]17/04/04 18:20:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=139, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=645120
17/04/04 18:20:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=656655 lastFlushOffset=645201 createNewBlock=false
17/04/04 18:20:19 DEBUG DFSClient: Queued packet 139
17/04/04 18:20:19 DEBUG DFSClient: Waiting for ack for: 139
17/04/04 18:20:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 139 offsetInBlock: 645120 lastPacketInBlock: false lastByteOffsetInBlock: 656655
17/04/04 18:20:19 WARN DFSClient: Slow ReadProcessor read fields took 31803ms (threshold=30000ms); ack: seqno: 139 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 86:>                                                        (0 + 4) / 10]17/04/04 18:20:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:20:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:20:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:20:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #48
17/04/04 18:20:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #48
17/04/04 18:20:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:20:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:20:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:20:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:20:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:=====>                                                   (1 + 4) / 10][Stage 86:===========>                                             (2 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10][Stage 86:============================>                            (5 + 4) / 10]17/04/04 18:20:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:20:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:20:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:20:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #49
17/04/04 18:20:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #49
17/04/04 18:20:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:20:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:20:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 86:==================================>                      (6 + 4) / 10]17/04/04 18:21:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:21:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:=======================================>                 (7 + 3) / 10][Stage 86:=============================================>           (8 + 2) / 10][Stage 86:===================================================>     (9 + 1) / 10]17/04/04 18:21:11 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=140, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=656384
17/04/04 18:21:11 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=670287 lastFlushOffset=656655 createNewBlock=false
17/04/04 18:21:11 DEBUG DFSClient: Queued packet 140
17/04/04 18:21:11 DEBUG DFSClient: Waiting for ack for: 140
17/04/04 18:21:11 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 140 offsetInBlock: 656384 lastPacketInBlock: false lastByteOffsetInBlock: 670287
17/04/04 18:21:11 WARN DFSClient: Slow ReadProcessor read fields took 51955ms (threshold=30000ms); ack: seqno: 140 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 87:>                                                        (0 + 4) / 10]17/04/04 18:21:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:21:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:21:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:21:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #50
17/04/04 18:21:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #50
17/04/04 18:21:21 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:21:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:21:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:21:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:21:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:21:47 WARN TaskSetManager: Lost task 0.0 in stage 87.1 (TID 506, 172.21.15.173, executor 11): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at com.esotericsoftware.kryo.io.Input.readDoubles(Input.java:885)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:222)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:205)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:70)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)

17/04/04 18:21:47 ERROR TaskSchedulerImpl: Lost executor 11 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:21:47 WARN TaskSetManager: Lost task 7.0 in stage 87.1 (TID 507, 172.21.15.173, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:21:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=141, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=670208
17/04/04 18:21:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=674764 lastFlushOffset=670287 createNewBlock=false
17/04/04 18:21:47 DEBUG DFSClient: Queued packet 141
17/04/04 18:21:47 DEBUG DFSClient: Waiting for ack for: 141
17/04/04 18:21:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 141 offsetInBlock: 670208 lastPacketInBlock: false lastByteOffsetInBlock: 674764
[Stage 87:>                                                        (0 + 3) / 10]17/04/04 18:21:48 WARN DFSClient: Slow ReadProcessor read fields took 36409ms (threshold=30000ms); ack: seqno: 141 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:21:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=142, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=674304
17/04/04 18:21:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=674764 lastFlushOffset=674764 createNewBlock=false
17/04/04 18:21:48 DEBUG DFSClient: Waiting for ack for: 141
17/04/04 18:21:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:21:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:21:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:21:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #51
17/04/04 18:21:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #51
17/04/04 18:21:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:21:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:21:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:22:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=143, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=674304
17/04/04 18:22:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=674764 lastFlushOffset=674764 createNewBlock=false
17/04/04 18:22:00 DEBUG DFSClient: Waiting for ack for: 141
17/04/04 18:22:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=144, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=674304
17/04/04 18:22:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=674764 lastFlushOffset=674764 createNewBlock=false
17/04/04 18:22:00 DEBUG DFSClient: Waiting for ack for: 141
[Stage 87:>                                                        (0 + 4) / 10]17/04/04 18:22:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:22:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:22:08 WARN TaskSetManager: Lost task 7.1 in stage 87.1 (TID 508, 172.21.15.173, executor 12): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:22:08 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=145, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=674304
17/04/04 18:22:08 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=681002 lastFlushOffset=674764 createNewBlock=false
17/04/04 18:22:08 DEBUG DFSClient: Queued packet 145
17/04/04 18:22:08 DEBUG DFSClient: Waiting for ack for: 145
17/04/04 18:22:08 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 145 offsetInBlock: 674304 lastPacketInBlock: false lastByteOffsetInBlock: 681002
17/04/04 18:22:08 DEBUG DFSClient: DFSClient seqno: 145 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:22:09 WARN TaskSetManager: Lost task 0.1 in stage 87.1 (TID 509, 172.21.15.173, executor 12): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:22:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:22:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:22:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:22:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #52
17/04/04 18:22:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #52
17/04/04 18:22:21 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:22:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:22:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:22:22 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=146, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=680960
17/04/04 18:22:22 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=681002 lastFlushOffset=681002 createNewBlock=false
17/04/04 18:22:22 DEBUG DFSClient: Waiting for ack for: 145
[Stage 77:>                                                         (0 + 1) / 2]17/04/04 18:22:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:22:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 77:=============================>                            (1 + 1) / 2]17/04/04 18:22:46 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=147, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=680960
17/04/04 18:22:46 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=685951 lastFlushOffset=681002 createNewBlock=false
17/04/04 18:22:46 DEBUG DFSClient: Queued packet 147
17/04/04 18:22:46 DEBUG DFSClient: Waiting for ack for: 147
17/04/04 18:22:46 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 147 offsetInBlock: 680960 lastPacketInBlock: false lastByteOffsetInBlock: 685951
17/04/04 18:22:46 WARN DFSClient: Slow ReadProcessor read fields took 37119ms (threshold=30000ms); ack: seqno: 147 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 78:>                                                         (0 + 1) / 3][Stage 78:===================>                                      (1 + 1) / 3][Stage 78:======================================>                   (2 + 1) / 3]17/04/04 18:22:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:22:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:22:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:22:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #53
17/04/04 18:22:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #53
17/04/04 18:22:51 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:22:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:22:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:22:52 WARN TaskSetManager: Lost task 1.0 in stage 87.1 (TID 505, 172.21.15.173, executor 9): java.lang.OutOfMemoryError: Java heap space
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:125)
	at scala.reflect.ManifestFactory$$anon$10.newArray(Manifest.scala:123)
	at org.apache.spark.util.collection.OpenHashSet.rehash(OpenHashSet.scala:232)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded(OpenHashSet.scala:167)
	at org.apache.spark.util.collection.OpenHashSet.rehashIfNeeded$mcJ$sp(OpenHashSet.scala:165)
	at org.apache.spark.graphx.util.collection.GraphXPrimitiveKeyOpenHashMap$mcJI$sp.update$mcJI$sp(GraphXPrimitiveKeyOpenHashMap.scala:77)
	at org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:65)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:110)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/04 18:22:52 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=148, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=685568
17/04/04 18:22:52 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=691311 lastFlushOffset=685951 createNewBlock=false
17/04/04 18:22:52 DEBUG DFSClient: Queued packet 148
17/04/04 18:22:52 DEBUG DFSClient: Waiting for ack for: 148
17/04/04 18:22:52 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 148 offsetInBlock: 685568 lastPacketInBlock: false lastByteOffsetInBlock: 691311
17/04/04 18:22:52 DEBUG DFSClient: DFSClient seqno: 148 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:22:53 ERROR TaskSchedulerImpl: Lost executor 9 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:22:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=149, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=691200
17/04/04 18:22:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=691311 lastFlushOffset=691311 createNewBlock=false
17/04/04 18:22:53 DEBUG DFSClient: Waiting for ack for: 148
17/04/04 18:22:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=150, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=691200
17/04/04 18:22:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=691311 lastFlushOffset=691311 createNewBlock=false
17/04/04 18:22:53 DEBUG DFSClient: Waiting for ack for: 148
[Stage 79:>                                                         (0 + 1) / 2][Stage 79:>                                                         (0 + 2) / 2]17/04/04 18:22:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=151, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=691200
17/04/04 18:22:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=696956 lastFlushOffset=691311 createNewBlock=false
17/04/04 18:22:56 DEBUG DFSClient: Queued packet 151
17/04/04 18:22:56 DEBUG DFSClient: Waiting for ack for: 151
17/04/04 18:22:56 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 151 offsetInBlock: 691200 lastPacketInBlock: false lastByteOffsetInBlock: 696956
17/04/04 18:22:56 DEBUG DFSClient: DFSClient seqno: 151 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:22:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=152, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=696832
17/04/04 18:22:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=696956 lastFlushOffset=696956 createNewBlock=false
17/04/04 18:22:56 DEBUG DFSClient: Waiting for ack for: 151
17/04/04 18:22:56 ERROR TaskSchedulerImpl: Lost executor 8 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:22:56 WARN TaskSetManager: Lost task 1.0 in stage 79.1 (TID 517, 172.21.15.173, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:22:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=153, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=696832
17/04/04 18:22:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=696956 createNewBlock=false
17/04/04 18:22:56 DEBUG DFSClient: Queued packet 153
17/04/04 18:22:56 DEBUG DFSClient: Waiting for ack for: 153
17/04/04 18:22:56 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 153 offsetInBlock: 696832 lastPacketInBlock: false lastByteOffsetInBlock: 701035
17/04/04 18:22:56 DEBUG DFSClient: DFSClient seqno: 153 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:22:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=154, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:22:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:22:56 DEBUG DFSClient: Waiting for ack for: 153
17/04/04 18:22:57 WARN TransportChannelHandler: Exception in connection from /172.21.15.173:58709
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/04/04 18:22:57 ERROR TaskSchedulerImpl: Lost executor 10 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:22:57 WARN TaskSetManager: Lost task 1.1 in stage 79.1 (TID 518, 172.21.15.173, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:22:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=155, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:22:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:22:57 DEBUG DFSClient: Waiting for ack for: 153
17/04/04 18:22:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=156, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:22:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:22:57 DEBUG DFSClient: Waiting for ack for: 153
17/04/04 18:22:58 WARN TaskSetManager: Lost task 1.2 in stage 79.1 (TID 519, 172.21.15.173, executor 13): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:22:58 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=157, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:22:58 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:22:58 DEBUG DFSClient: Waiting for ack for: 153
17/04/04 18:22:58 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=158, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:22:58 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:22:58 DEBUG DFSClient: Waiting for ack for: 153
17/04/04 18:22:58 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=159, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:22:58 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=701035 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:22:58 DEBUG DFSClient: Waiting for ack for: 153
[Stage 76:>                                                         (0 + 2) / 9]17/04/04 18:23:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:23:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:23:08 WARN TaskSetManager: Lost task 0.0 in stage 79.1 (TID 516, 172.21.15.173, executor 12): FetchFailed(BlockManagerId(9, 172.21.15.173, 53877, None), shuffleId=2, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:53877
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:53877
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:53877
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
[Stage 76:>                                                         (0 + 3) / 9][Stage 76:======>                                                   (1 + 3) / 9][Stage 76:============>                                             (2 + 3) / 9]17/04/04 18:23:12 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=160, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=700928
17/04/04 18:23:12 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=707432 lastFlushOffset=701035 createNewBlock=false
17/04/04 18:23:12 DEBUG DFSClient: Queued packet 160
17/04/04 18:23:12 DEBUG DFSClient: Waiting for ack for: 160
17/04/04 18:23:12 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 160 offsetInBlock: 700928 lastPacketInBlock: false lastByteOffsetInBlock: 707432
17/04/04 18:23:12 DEBUG DFSClient: DFSClient seqno: 160 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:23:12 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=161, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=707072
17/04/04 18:23:12 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=707432 lastFlushOffset=707432 createNewBlock=false
17/04/04 18:23:12 DEBUG DFSClient: Waiting for ack for: 160
[Stage 76:===================>                                      (3 + 4) / 9][Stage 76:=========================>                                (4 + 4) / 9][Stage 76:================================>                         (5 + 4) / 9][Stage 76:======================================>                   (6 + 3) / 9][Stage 76:=============================================>            (7 + 2) / 9][Stage 76:===================================================>      (8 + 1) / 9]17/04/04 18:23:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=162, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=707072
17/04/04 18:23:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=711083 lastFlushOffset=707432 createNewBlock=false
17/04/04 18:23:19 DEBUG DFSClient: Queued packet 162
17/04/04 18:23:19 DEBUG DFSClient: Waiting for ack for: 162
17/04/04 18:23:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 162 offsetInBlock: 707072 lastPacketInBlock: false lastByteOffsetInBlock: 711083
17/04/04 18:23:19 DEBUG DFSClient: DFSClient seqno: 162 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                         (0 + 4) / 8]17/04/04 18:23:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:23:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:23:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:23:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #54
17/04/04 18:23:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #54
17/04/04 18:23:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:23:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:23:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 77:=======>                                                  (1 + 4) / 8][Stage 77:=====================>                                    (3 + 4) / 8][Stage 77:=============================>                            (4 + 4) / 8]17/04/04 18:23:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:23:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 77:====================================>                     (5 + 3) / 8][Stage 77:===========================================>              (6 + 2) / 8][Stage 77:==================================================>       (7 + 1) / 8]17/04/04 18:23:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=163, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=710656
17/04/04 18:23:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=726344 lastFlushOffset=711083 createNewBlock=false
17/04/04 18:23:34 DEBUG DFSClient: Queued packet 163
17/04/04 18:23:34 DEBUG DFSClient: Waiting for ack for: 163
17/04/04 18:23:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 163 offsetInBlock: 710656 lastPacketInBlock: false lastByteOffsetInBlock: 726344
17/04/04 18:23:34 DEBUG DFSClient: DFSClient seqno: 163 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:23:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=164, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=726016
17/04/04 18:23:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=731293 lastFlushOffset=726344 createNewBlock=false
17/04/04 18:23:35 DEBUG DFSClient: Queued packet 164
17/04/04 18:23:35 DEBUG DFSClient: Waiting for ack for: 164
17/04/04 18:23:35 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 164 offsetInBlock: 726016 lastPacketInBlock: false lastByteOffsetInBlock: 731293
17/04/04 18:23:35 DEBUG DFSClient: DFSClient seqno: 164 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                        (0 + 4) / 10][Stage 79:=================>                                       (3 + 4) / 10][Stage 79:======================>                                  (4 + 3) / 10][Stage 79:============================>                            (5 + 2) / 10][Stage 79:==================================>                      (6 + 1) / 10][Stage 79:=======================================>                 (7 + 1) / 10][Stage 79:=============================================>           (8 + 1) / 10][Stage 79:===================================================>     (9 + 1) / 10]17/04/04 18:23:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=165, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=731136
17/04/04 18:23:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=741348 lastFlushOffset=731293 createNewBlock=false
17/04/04 18:23:44 DEBUG DFSClient: Queued packet 165
17/04/04 18:23:44 DEBUG DFSClient: Waiting for ack for: 165
17/04/04 18:23:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 165 offsetInBlock: 731136 lastPacketInBlock: false lastByteOffsetInBlock: 741348
17/04/04 18:23:44 DEBUG DFSClient: DFSClient seqno: 165 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:>                                                        (0 + 4) / 10][Stage 80:======================>                                  (4 + 4) / 10][Stage 80:=============================================>           (8 + 2) / 10]17/04/04 18:23:45 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=166, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=740864
17/04/04 18:23:45 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=746466 lastFlushOffset=741348 createNewBlock=false
17/04/04 18:23:45 DEBUG DFSClient: Queued packet 166
17/04/04 18:23:45 DEBUG DFSClient: Waiting for ack for: 166
17/04/04 18:23:45 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 166 offsetInBlock: 740864 lastPacketInBlock: false lastByteOffsetInBlock: 746466
17/04/04 18:23:45 DEBUG DFSClient: DFSClient seqno: 166 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 0) / 10][Stage 81:>                                                        (0 + 4) / 10][Stage 81:=====>                                                   (1 + 4) / 10][Stage 81:=================>                                       (3 + 4) / 10][Stage 81:============================>                            (5 + 2) / 10][Stage 81:==================================>                      (6 + 1) / 10][Stage 81:==================================>                      (6 + 4) / 10][Stage 81:=======================================>                 (7 + 3) / 10]17/04/04 18:23:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:23:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:23:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:23:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #55
17/04/04 18:23:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #55
17/04/04 18:23:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:23:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:23:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 81:=============================================>           (8 + 2) / 10][Stage 81:===================================================>     (9 + 1) / 10]17/04/04 18:23:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=167, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=745984
17/04/04 18:23:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=757314 lastFlushOffset=746466 createNewBlock=false
17/04/04 18:23:55 DEBUG DFSClient: Queued packet 167
17/04/04 18:23:55 DEBUG DFSClient: Waiting for ack for: 167
17/04/04 18:23:55 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 167 offsetInBlock: 745984 lastPacketInBlock: false lastByteOffsetInBlock: 757314
17/04/04 18:23:55 DEBUG DFSClient: DFSClient seqno: 167 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:===========>                                             (2 + 4) / 10][Stage 82:=================>                                       (3 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:=======================================>                 (7 + 3) / 10][Stage 82:=============================================>           (8 + 2) / 10]17/04/04 18:24:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=168, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=757248
17/04/04 18:24:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=768844 lastFlushOffset=757314 createNewBlock=false
17/04/04 18:24:00 DEBUG DFSClient: Queued packet 168
17/04/04 18:24:00 DEBUG DFSClient: Waiting for ack for: 168
17/04/04 18:24:00 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 168 offsetInBlock: 757248 lastPacketInBlock: false lastByteOffsetInBlock: 768844
17/04/04 18:24:00 DEBUG DFSClient: DFSClient seqno: 168 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/04/04 18:24:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:24:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:24:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:24:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:24:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:24:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #56
17/04/04 18:24:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #56
17/04/04 18:24:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:24:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:24:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:24:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:24:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===========>                                             (2 + 4) / 10][Stage 83:=================>                                       (3 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/04/04 18:24:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:24:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:24:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:24:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #57
17/04/04 18:24:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #57
17/04/04 18:24:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:24:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:24:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:25:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:25:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:============================>                            (5 + 4) / 10][Stage 83:==================================>                      (6 + 4) / 10][Stage 83:=======================================>                 (7 + 3) / 10]17/04/04 18:25:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:25:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:25:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:25:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #58
17/04/04 18:25:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #58
17/04/04 18:25:21 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:25:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:25:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:25:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:25:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:25:39 WARN TaskSetManager: Lost task 2.0 in stage 83.1 (TID 591, 172.21.15.173, executor 12): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.spark.graphx.lib.SVDPlusPlus$.org$apache$spark$graphx$lib$SVDPlusPlus$$sendMsgTrainF$1(SVDPlusPlus.scala:118)
	at org.apache.spark.graphx.lib.SVDPlusPlus$$anonfun$run$1$$anonfun$12.apply(SVDPlusPlus.scala:153)
	at org.apache.spark.graphx.lib.SVDPlusPlus$$anonfun$run$1$$anonfun$12.apply(SVDPlusPlus.scala:153)
	at org.apache.spark.graphx.impl.EdgePartition.aggregateMessagesEdgeScan(EdgePartition.scala:409)
	at org.apache.spark.graphx.impl.GraphImpl$$anonfun$13$$anonfun$apply$3.apply(GraphImpl.scala:237)
	at org.apache.spark.graphx.impl.GraphImpl$$anonfun$13$$anonfun$apply$3.apply(GraphImpl.scala:207)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/04 18:25:40 ERROR TaskSchedulerImpl: Lost executor 12 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:25:40 WARN TaskSetManager: Lost task 2.1 in stage 83.1 (TID 594, 172.21.15.173, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:25:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=169, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=768512
17/04/04 18:25:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=774191 lastFlushOffset=768844 createNewBlock=false
17/04/04 18:25:40 DEBUG DFSClient: Queued packet 169
17/04/04 18:25:40 DEBUG DFSClient: Waiting for ack for: 169
17/04/04 18:25:40 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 169 offsetInBlock: 768512 lastPacketInBlock: false lastByteOffsetInBlock: 774191
17/04/04 18:25:40 WARN DFSClient: Slow ReadProcessor read fields took 99886ms (threshold=30000ms); ack: seqno: 169 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:25:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=170, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=774144
17/04/04 18:25:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=779712 lastFlushOffset=774191 createNewBlock=false
17/04/04 18:25:40 DEBUG DFSClient: Queued packet 170
17/04/04 18:25:40 DEBUG DFSClient: Waiting for ack for: 170
17/04/04 18:25:40 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 170 offsetInBlock: 774144 lastPacketInBlock: false lastByteOffsetInBlock: 779712
[Stage 83:=======================================>                 (7 + 1) / 10]17/04/04 18:25:40 WARN TaskSetManager: Lost task 7.0 in stage 83.1 (TID 592, 172.21.15.173, executor 15): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:25:40 DEBUG DFSClient: DFSClient seqno: 170 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:25:40 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=171, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=779264
17/04/04 18:25:40 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=779712 lastFlushOffset=779712 createNewBlock=false
17/04/04 18:25:40 DEBUG DFSClient: Waiting for ack for: 170
17/04/04 18:25:40 WARN TaskSetManager: Lost task 0.1 in stage 83.1 (TID 596, 172.21.15.173, executor 15): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:25:40 WARN TaskSetManager: Lost task 2.2 in stage 83.1 (TID 595, 172.21.15.173, executor 14): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=2, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
[Stage 76:>                                                         (0 + 2) / 5][Stage 76:===========>                                              (1 + 2) / 5][Stage 76:==================================>                       (3 + 2) / 5][Stage 76:==============================================>           (4 + 1) / 5]17/04/04 18:25:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=172, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=779264
17/04/04 18:25:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=784174 lastFlushOffset=779712 createNewBlock=false
17/04/04 18:25:50 DEBUG DFSClient: Queued packet 172
17/04/04 18:25:50 DEBUG DFSClient: Waiting for ack for: 172
17/04/04 18:25:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 172 offsetInBlock: 779264 lastPacketInBlock: false lastByteOffsetInBlock: 784174
17/04/04 18:25:50 DEBUG DFSClient: DFSClient seqno: 172 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:25:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=173, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=783872
17/04/04 18:25:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=789385 lastFlushOffset=784174 createNewBlock=false
17/04/04 18:25:50 DEBUG DFSClient: Queued packet 173
17/04/04 18:25:50 DEBUG DFSClient: Waiting for ack for: 173
17/04/04 18:25:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 173 offsetInBlock: 783872 lastPacketInBlock: false lastByteOffsetInBlock: 789385
17/04/04 18:25:50 DEBUG DFSClient: DFSClient seqno: 173 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:25:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=174, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=788992
17/04/04 18:25:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=789385 lastFlushOffset=789385 createNewBlock=false
17/04/04 18:25:51 DEBUG DFSClient: Waiting for ack for: 173
[Stage 77:>                                                         (0 + 4) / 4]17/04/04 18:25:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:25:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:25:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:25:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #59
17/04/04 18:25:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #59
17/04/04 18:25:51 DEBUG ProtobufRpcEngine: Call: renewLease took 3ms
17/04/04 18:25:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:25:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 77:==============>                                           (1 + 3) / 4][Stage 77:=============================>                            (2 + 2) / 4][Stage 77:===========================================>              (3 + 1) / 4]17/04/04 18:26:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:26:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:26:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=175, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=788992
17/04/04 18:26:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=794326 lastFlushOffset=789385 createNewBlock=false
17/04/04 18:26:02 DEBUG DFSClient: Queued packet 175
17/04/04 18:26:02 DEBUG DFSClient: Waiting for ack for: 175
17/04/04 18:26:02 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 175 offsetInBlock: 788992 lastPacketInBlock: false lastByteOffsetInBlock: 794326
17/04/04 18:26:02 DEBUG DFSClient: DFSClient seqno: 175 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:26:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=176, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=794112
17/04/04 18:26:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=799328 lastFlushOffset=794326 createNewBlock=false
17/04/04 18:26:03 DEBUG DFSClient: Queued packet 176
17/04/04 18:26:03 DEBUG DFSClient: Waiting for ack for: 176
17/04/04 18:26:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 176 offsetInBlock: 794112 lastPacketInBlock: false lastByteOffsetInBlock: 799328
17/04/04 18:26:03 DEBUG DFSClient: DFSClient seqno: 176 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                         (0 + 4) / 4][Stage 79:===========================================>              (3 + 1) / 4]17/04/04 18:26:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=177, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=799232
17/04/04 18:26:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=804817 lastFlushOffset=799328 createNewBlock=false
17/04/04 18:26:06 DEBUG DFSClient: Queued packet 177
17/04/04 18:26:06 DEBUG DFSClient: Waiting for ack for: 177
17/04/04 18:26:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 177 offsetInBlock: 799232 lastPacketInBlock: false lastByteOffsetInBlock: 804817
17/04/04 18:26:06 DEBUG DFSClient: DFSClient seqno: 177 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:26:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=178, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=804352
17/04/04 18:26:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=810265 lastFlushOffset=804817 createNewBlock=false
17/04/04 18:26:06 DEBUG DFSClient: Queued packet 178
17/04/04 18:26:06 DEBUG DFSClient: Waiting for ack for: 178
17/04/04 18:26:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 178 offsetInBlock: 804352 lastPacketInBlock: false lastByteOffsetInBlock: 810265
17/04/04 18:26:06 DEBUG DFSClient: DFSClient seqno: 178 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:26:09 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=179, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=809984
17/04/04 18:26:09 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=815405 lastFlushOffset=810265 createNewBlock=false
17/04/04 18:26:09 DEBUG DFSClient: Queued packet 179
17/04/04 18:26:09 DEBUG DFSClient: Waiting for ack for: 179
17/04/04 18:26:09 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 179 offsetInBlock: 809984 lastPacketInBlock: false lastByteOffsetInBlock: 815405
17/04/04 18:26:09 DEBUG DFSClient: DFSClient seqno: 179 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                         (0 + 3) / 3][Stage 82:======================================>                   (2 + 1) / 3]17/04/04 18:26:10 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=180, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=815104
17/04/04 18:26:10 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=815405 lastFlushOffset=815405 createNewBlock=false
17/04/04 18:26:10 DEBUG DFSClient: Waiting for ack for: 179
[Stage 83:>                                                         (0 + 3) / 3]17/04/04 18:26:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:26:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:26:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:26:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #60
17/04/04 18:26:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #60
17/04/04 18:26:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:26:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:26:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:26:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:26:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===================>                                      (1 + 2) / 3][Stage 83:======================================>                   (2 + 1) / 3]17/04/04 18:26:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=181, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=815104
17/04/04 18:26:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=820221 lastFlushOffset=815405 createNewBlock=false
17/04/04 18:26:47 DEBUG DFSClient: Queued packet 181
17/04/04 18:26:47 DEBUG DFSClient: Waiting for ack for: 181
17/04/04 18:26:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 181 offsetInBlock: 815104 lastPacketInBlock: false lastByteOffsetInBlock: 820221
17/04/04 18:26:47 WARN DFSClient: Slow ReadProcessor read fields took 38645ms (threshold=30000ms); ack: seqno: 181 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                        (0 + 4) / 10]17/04/04 18:26:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:26:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:26:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:26:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #61
17/04/04 18:26:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #61
17/04/04 18:26:51 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:26:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:26:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:===========>                                             (2 + 4) / 10][Stage 84:=================>                                       (3 + 4) / 10][Stage 84:======================>                                  (4 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10]17/04/04 18:27:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:27:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10][Stage 84:===================================================>     (9 + 1) / 10]17/04/04 18:27:08 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=182, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=819712
17/04/04 18:27:08 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=830380 lastFlushOffset=820221 createNewBlock=false
17/04/04 18:27:08 DEBUG DFSClient: Queued packet 182
17/04/04 18:27:08 DEBUG DFSClient: Waiting for ack for: 182
17/04/04 18:27:08 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 182 offsetInBlock: 819712 lastPacketInBlock: false lastByteOffsetInBlock: 830380
17/04/04 18:27:08 DEBUG DFSClient: DFSClient seqno: 182 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10][Stage 85:=====>                                                   (1 + 4) / 10][Stage 85:===========>                                             (2 + 4) / 10][Stage 85:=================>                                       (3 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10]17/04/04 18:27:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:27:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:27:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:27:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #62
17/04/04 18:27:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #62
17/04/04 18:27:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:27:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:27:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10]17/04/04 18:27:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:27:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 85:===================================================>     (9 + 1) / 10]17/04/04 18:27:37 WARN TaskSetManager: Lost task 8.0 in stage 85.1 (TID 646, 172.21.15.173, executor 13): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Double.valueOf(Double.java:521)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$DoubleSerializer.read(DefaultSerializers.java:179)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$DoubleSerializer.read(DefaultSerializers.java:169)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:71)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)

17/04/04 18:27:38 ERROR TaskSchedulerImpl: Lost executor 13 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
[Stage 85:==================================================>     (9 + -1) / 10]17/04/04 18:27:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=183, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=829952
17/04/04 18:27:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=842211 lastFlushOffset=830380 createNewBlock=false
17/04/04 18:27:38 DEBUG DFSClient: Queued packet 183
17/04/04 18:27:38 DEBUG DFSClient: Waiting for ack for: 183
17/04/04 18:27:38 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 183 offsetInBlock: 829952 lastPacketInBlock: false lastByteOffsetInBlock: 842211
17/04/04 18:27:38 WARN TaskSetManager: Lost task 5.1 in stage 85.1 (TID 649, 172.21.15.173, executor 15): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:27:38 WARN DFSClient: Slow ReadProcessor read fields took 30044ms (threshold=30000ms); ack: seqno: 183 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:27:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=184, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=841728
17/04/04 18:27:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=842211 lastFlushOffset=842211 createNewBlock=false
17/04/04 18:27:38 DEBUG DFSClient: Waiting for ack for: 183
17/04/04 18:27:38 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=185, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=841728
17/04/04 18:27:38 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=848865 lastFlushOffset=842211 createNewBlock=false
17/04/04 18:27:38 DEBUG DFSClient: Queued packet 185
17/04/04 18:27:38 DEBUG DFSClient: Waiting for ack for: 185
17/04/04 18:27:38 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 185 offsetInBlock: 841728 lastPacketInBlock: false lastByteOffsetInBlock: 848865
17/04/04 18:27:38 DEBUG DFSClient: DFSClient seqno: 185 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:27:38 WARN TaskSetManager: Lost task 0.1 in stage 85.1 (TID 648, 172.21.15.173, executor 16): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:974)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
[Stage 76:>                                                         (0 + 2) / 2][Stage 76:=============================>                            (1 + 1) / 2]17/04/04 18:27:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:27:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:27:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:27:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #63
17/04/04 18:27:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #63
17/04/04 18:27:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:27:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:27:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:27:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=186, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=848384
17/04/04 18:27:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=854264 lastFlushOffset=848865 createNewBlock=false
17/04/04 18:27:53 DEBUG DFSClient: Queued packet 186
17/04/04 18:27:53 DEBUG DFSClient: Waiting for ack for: 186
17/04/04 18:27:53 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 186 offsetInBlock: 848384 lastPacketInBlock: false lastByteOffsetInBlock: 854264
17/04/04 18:27:53 DEBUG DFSClient: DFSClient seqno: 186 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:27:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=187, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=854016
17/04/04 18:27:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=854264 lastFlushOffset=854264 createNewBlock=false
17/04/04 18:27:54 DEBUG DFSClient: Waiting for ack for: 186
[Stage 77:>                                                         (0 + 3) / 3]17/04/04 18:27:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=188, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=854016
17/04/04 18:27:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=854264 lastFlushOffset=854264 createNewBlock=false
17/04/04 18:27:55 DEBUG DFSClient: Waiting for ack for: 186
[Stage 77:===================>                                      (1 + 2) / 3][Stage 77:======================================>                   (2 + 1) / 3]17/04/04 18:28:00 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=189, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=854016
17/04/04 18:28:00 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=861527 lastFlushOffset=854264 createNewBlock=false
17/04/04 18:28:00 DEBUG DFSClient: Queued packet 189
17/04/04 18:28:00 DEBUG DFSClient: Waiting for ack for: 189
17/04/04 18:28:00 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 189 offsetInBlock: 854016 lastPacketInBlock: false lastByteOffsetInBlock: 861527
17/04/04 18:28:00 DEBUG DFSClient: DFSClient seqno: 189 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 78:======================================>                   (2 + 1) / 3]17/04/04 18:28:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:28:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:28:01 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=190, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=861184
17/04/04 18:28:01 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=866404 lastFlushOffset=861527 createNewBlock=false
17/04/04 18:28:01 DEBUG DFSClient: Queued packet 190
17/04/04 18:28:01 DEBUG DFSClient: Waiting for ack for: 190
17/04/04 18:28:01 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 190 offsetInBlock: 861184 lastPacketInBlock: false lastByteOffsetInBlock: 866404
17/04/04 18:28:01 DEBUG DFSClient: DFSClient seqno: 190 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                         (0 + 3) / 3]17/04/04 18:28:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=191, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=866304
17/04/04 18:28:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=866404 lastFlushOffset=866404 createNewBlock=false
17/04/04 18:28:02 DEBUG DFSClient: Waiting for ack for: 190
17/04/04 18:28:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=192, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=866304
17/04/04 18:28:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=871311 lastFlushOffset=866404 createNewBlock=false
17/04/04 18:28:03 DEBUG DFSClient: Queued packet 192
17/04/04 18:28:03 DEBUG DFSClient: Waiting for ack for: 192
17/04/04 18:28:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 192 offsetInBlock: 866304 lastPacketInBlock: false lastByteOffsetInBlock: 871311
17/04/04 18:28:03 DEBUG DFSClient: DFSClient seqno: 192 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                         (0 + 3) / 4][Stage 81:===========================================>              (3 + 1) / 4]17/04/04 18:28:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=193, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=870912
17/04/04 18:28:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=875921 lastFlushOffset=871311 createNewBlock=false
17/04/04 18:28:04 DEBUG DFSClient: Queued packet 193
17/04/04 18:28:04 DEBUG DFSClient: Waiting for ack for: 193
17/04/04 18:28:04 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 193 offsetInBlock: 870912 lastPacketInBlock: false lastByteOffsetInBlock: 875921
17/04/04 18:28:04 DEBUG DFSClient: DFSClient seqno: 193 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                         (0 + 2) / 2][Stage 82:=============================>                            (1 + 1) / 2]17/04/04 18:28:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=194, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=875520
17/04/04 18:28:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=881057 lastFlushOffset=875921 createNewBlock=false
17/04/04 18:28:05 DEBUG DFSClient: Queued packet 194
17/04/04 18:28:05 DEBUG DFSClient: Waiting for ack for: 194
17/04/04 18:28:05 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 194 offsetInBlock: 875520 lastPacketInBlock: false lastByteOffsetInBlock: 881057
17/04/04 18:28:05 DEBUG DFSClient: DFSClient seqno: 194 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                         (0 + 3) / 4][Stage 83:>                                                         (0 + 4) / 4]17/04/04 18:28:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:28:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:28:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:28:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #64
17/04/04 18:28:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #64
17/04/04 18:28:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:28:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:28:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 83:==============>                                           (1 + 3) / 4]17/04/04 18:28:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:28:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:=============================>                            (2 + 2) / 4][Stage 83:===========================================>              (3 + 1) / 4]17/04/04 18:28:42 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=195, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=880640
17/04/04 18:28:42 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=886321 lastFlushOffset=881057 createNewBlock=false
17/04/04 18:28:42 DEBUG DFSClient: Queued packet 195
17/04/04 18:28:42 DEBUG DFSClient: Waiting for ack for: 195
17/04/04 18:28:42 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 195 offsetInBlock: 880640 lastPacketInBlock: false lastByteOffsetInBlock: 886321
17/04/04 18:28:42 WARN DFSClient: Slow ReadProcessor read fields took 36584ms (threshold=30000ms); ack: seqno: 195 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                         (0 + 3) / 3][Stage 84:===================>                                      (1 + 2) / 3][Stage 84:======================================>                   (2 + 1) / 3]17/04/04 18:28:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=196, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=886272
17/04/04 18:28:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=891800 lastFlushOffset=886321 createNewBlock=false
17/04/04 18:28:47 DEBUG DFSClient: Queued packet 196
17/04/04 18:28:47 DEBUG DFSClient: Waiting for ack for: 196
17/04/04 18:28:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 196 offsetInBlock: 886272 lastPacketInBlock: false lastByteOffsetInBlock: 891800
17/04/04 18:28:47 DEBUG DFSClient: DFSClient seqno: 196 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                         (0 + 2) / 2][Stage 85:=============================>                            (1 + 1) / 2]17/04/04 18:28:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:28:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:28:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:28:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #65
17/04/04 18:28:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #65
17/04/04 18:28:51 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:28:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:28:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:28:52 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=197, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=891392
17/04/04 18:28:52 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=897280 lastFlushOffset=891800 createNewBlock=false
17/04/04 18:28:52 DEBUG DFSClient: Queued packet 197
17/04/04 18:28:52 DEBUG DFSClient: Waiting for ack for: 197
17/04/04 18:28:52 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 197 offsetInBlock: 891392 lastPacketInBlock: false lastByteOffsetInBlock: 897280
17/04/04 18:28:52 DEBUG DFSClient: DFSClient seqno: 197 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10]17/04/04 18:29:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:29:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:=====>                                                   (1 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10][Stage 86:============================>                            (5 + 4) / 10]17/04/04 18:29:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:29:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:29:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:29:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #66
17/04/04 18:29:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #66
17/04/04 18:29:21 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:29:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:29:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=======================================>                 (7 + 3) / 10]17/04/04 18:29:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:29:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:=============================================>           (8 + 2) / 10][Stage 86:===================================================>     (9 + 1) / 10]17/04/04 18:29:37 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=198, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=897024
17/04/04 18:29:37 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=910526 lastFlushOffset=897280 createNewBlock=false
17/04/04 18:29:37 DEBUG DFSClient: Queued packet 198
17/04/04 18:29:37 DEBUG DFSClient: Waiting for ack for: 198
17/04/04 18:29:37 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 198 offsetInBlock: 897024 lastPacketInBlock: false lastByteOffsetInBlock: 910526
17/04/04 18:29:37 WARN DFSClient: Slow ReadProcessor read fields took 45763ms (threshold=30000ms); ack: seqno: 198 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 87:>                                                        (0 + 3) / 10][Stage 87:>                                                        (0 + 4) / 10]17/04/04 18:29:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:29:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:29:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:29:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #67
17/04/04 18:29:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #67
17/04/04 18:29:51 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/04/04 18:29:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:29:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:30:00 WARN TaskSetManager: Lost task 1.0 in stage 87.2 (TID 692, 172.21.15.173, executor 15): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Double.valueOf(Double.java:521)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$DoubleSerializer.read(DefaultSerializers.java:179)
	at com.esotericsoftware.kryo.serializers.DefaultSerializers$DoubleSerializer.read(DefaultSerializers.java:169)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:72)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)

17/04/04 18:30:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:30:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10]17/04/04 18:30:04 WARN TaskSetManager: Lost task 6.0 in stage 87.2 (TID 694, 172.21.15.173, executor 15): java.io.FileNotFoundException: /tmp/spark-dbb2962c-edc8-46a3-8dd6-28d2019c6bbc/executor-ee06a710-d6e3-4cde-b9f6-cb7e08d92802/blockmgr-f690c916-53e9-427b-8015-301fc22a08bf/3e/rdd_14_1 (没有那个文件或目录)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:171)
	at org.apache.spark.storage.DiskStore.put(DiskStore.scala:54)
	at org.apache.spark.storage.DiskStore.putBytes(DiskStore.scala:76)
	at org.apache.spark.storage.BlockManager.dropFromMemory(BlockManager.scala:1268)
	at org.apache.spark.storage.memory.MemoryStore.org$apache$spark$storage$memory$MemoryStore$$dropBlock$1(MemoryStore.scala:526)
	at org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$2.apply(MemoryStore.scala:547)
	at org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$2.apply(MemoryStore.scala:541)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.storage.memory.MemoryStore.evictBlocksToFreeSpace(MemoryStore.scala:541)
	at org.apache.spark.memory.StorageMemoryPool.acquireMemory(StorageMemoryPool.scala:92)
	at org.apache.spark.memory.StorageMemoryPool.acquireMemory(StorageMemoryPool.scala:73)
	at org.apache.spark.memory.UnifiedMemoryManager.acquireStorageMemory(UnifiedMemoryManager.scala:178)
	at org.apache.spark.memory.UnifiedMemoryManager.acquireUnrollMemory(UnifiedMemoryManager.scala:185)
	at org.apache.spark.storage.memory.MemoryStore.reserveUnrollMemoryForThisTask(MemoryStore.scala:584)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:223)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/04 18:30:04 WARN TaskSetManager: Lost task 3.0 in stage 87.2 (TID 693, 172.21.15.173, executor 17): FetchFailed(BlockManagerId(15, 172.21.15.173, 60767, None), shuffleId=9, mapId=1, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: java.io.FileNotFoundException: /tmp/spark-dbb2962c-edc8-46a3-8dd6-28d2019c6bbc/executor-ee06a710-d6e3-4cde-b9f6-cb7e08d92802/blockmgr-f690c916-53e9-427b-8015-301fc22a08bf/3a/shuffle_9_1_0.index (没有那个文件或目录)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:60)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:60)
	at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:159)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: java.io.FileNotFoundException: /tmp/spark-dbb2962c-edc8-46a3-8dd6-28d2019c6bbc/executor-ee06a710-d6e3-4cde-b9f6-cb7e08d92802/blockmgr-f690c916-53e9-427b-8015-301fc22a08bf/3a/shuffle_9_1_0.index (没有那个文件或目录)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:60)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:60)
	at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:159)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:189)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:121)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

)
17/04/04 18:30:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=199, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=910336
17/04/04 18:30:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=926217 lastFlushOffset=910526 createNewBlock=false
17/04/04 18:30:04 DEBUG DFSClient: Queued packet 199
17/04/04 18:30:04 DEBUG DFSClient: Waiting for ack for: 199
17/04/04 18:30:04 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 199 offsetInBlock: 910336 lastPacketInBlock: false lastByteOffsetInBlock: 926217
17/04/04 18:30:04 DEBUG DFSClient: DFSClient seqno: 199 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:30:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=200, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=926208
17/04/04 18:30:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=926217 lastFlushOffset=926217 createNewBlock=false
17/04/04 18:30:04 DEBUG DFSClient: Waiting for ack for: 199
17/04/04 18:30:05 ERROR TaskSchedulerImpl: Lost executor 15 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:30:05 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /172.21.15.173:58777 is closed
17/04/04 18:30:05 WARN TaskSetManager: Lost task 1.1 in stage 87.2 (TID 696, 172.21.15.173, executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:30:05 WARN BlockManagerMaster: Failed to remove broadcast 103 with removeFromMaster = true - Connection from /172.21.15.173:58777 closed
java.io.IOException: Connection from /172.21.15.173:58777 closed
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:128)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:109)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:257)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:182)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/04/04 18:30:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=201, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=926208
17/04/04 18:30:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=926217 lastFlushOffset=926217 createNewBlock=false
17/04/04 18:30:05 ERROR ContextCleaner: Error cleaning broadcast 103
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:151)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:303)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:60)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1245)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
Caused by: java.io.IOException: Connection from /172.21.15.173:58777 closed
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:128)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:109)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:257)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:182)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/04/04 18:30:05 DEBUG DFSClient: Waiting for ack for: 199
[Stage 76:>                                                         (0 + 1) / 5]17/04/04 18:30:15 WARN TaskSetManager: Lost task 2.0 in stage 87.2 (TID 691, 172.21.15.173, executor 14): FetchFailed(BlockManagerId(15, 172.21.15.173, 60767, None), shuffleId=9, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:60767
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:60767
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:60767
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
[Stage 76:>                                                         (0 + 2) / 5][Stage 76:===========>                                              (1 + 2) / 5][Stage 76:=======================>                                  (2 + 2) / 5][Stage 76:==================================>                       (3 + 2) / 5]17/04/04 18:30:20 WARN TaskSetManager: Lost task 9.0 in stage 87.2 (TID 695, 172.21.15.173, executor 16): FetchFailed(BlockManagerId(15, 172.21.15.173, 60767, None), shuffleId=2, mapId=0, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /172.21.15.173:60767
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to /172.21.15.173:60767
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:181)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.21.15.173:60767
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
[Stage 76:==============================================>           (4 + 1) / 5]17/04/04 18:30:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:30:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:30:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:30:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #68
17/04/04 18:30:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #68
17/04/04 18:30:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:30:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:30:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:30:21 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=202, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=926208
17/04/04 18:30:21 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=932676 lastFlushOffset=926217 createNewBlock=false
17/04/04 18:30:21 DEBUG DFSClient: Queued packet 202
17/04/04 18:30:21 DEBUG DFSClient: Waiting for ack for: 202
17/04/04 18:30:21 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 202 offsetInBlock: 926208 lastPacketInBlock: false lastByteOffsetInBlock: 932676
17/04/04 18:30:21 DEBUG DFSClient: DFSClient seqno: 202 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:30:21 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=203, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=932352
17/04/04 18:30:21 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=932676 lastFlushOffset=932676 createNewBlock=false
17/04/04 18:30:21 DEBUG DFSClient: Waiting for ack for: 202
17/04/04 18:30:22 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=204, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=932352
17/04/04 18:30:22 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=938745 lastFlushOffset=932676 createNewBlock=false
17/04/04 18:30:22 DEBUG DFSClient: Queued packet 204
17/04/04 18:30:22 DEBUG DFSClient: Waiting for ack for: 204
17/04/04 18:30:22 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 204 offsetInBlock: 932352 lastPacketInBlock: false lastByteOffsetInBlock: 938745
17/04/04 18:30:22 DEBUG DFSClient: DFSClient seqno: 204 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:==============>                                           (1 + 3) / 4][Stage 77:=============================>                            (2 + 2) / 4][Stage 77:===========================================>              (3 + 1) / 4]17/04/04 18:30:28 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=205, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=938496
17/04/04 18:30:28 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=943346 lastFlushOffset=938745 createNewBlock=false
17/04/04 18:30:28 DEBUG DFSClient: Queued packet 205
17/04/04 18:30:28 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 205 offsetInBlock: 938496 lastPacketInBlock: false lastByteOffsetInBlock: 943346
17/04/04 18:30:28 DEBUG DFSClient: Waiting for ack for: 205
17/04/04 18:30:28 DEBUG DFSClient: DFSClient seqno: 205 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:30:28 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=206, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=943104
17/04/04 18:30:28 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=948258 lastFlushOffset=943346 createNewBlock=false
17/04/04 18:30:28 DEBUG DFSClient: Queued packet 206
17/04/04 18:30:28 DEBUG DFSClient: Waiting for ack for: 206
17/04/04 18:30:28 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 206 offsetInBlock: 943104 lastPacketInBlock: false lastByteOffsetInBlock: 948258
17/04/04 18:30:28 DEBUG DFSClient: DFSClient seqno: 206 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                         (0 + 4) / 4][Stage 79:=============================>                            (2 + 2) / 4][Stage 79:===========================================>              (3 + 1) / 4]17/04/04 18:30:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=207, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=948224
17/04/04 18:30:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=952987 lastFlushOffset=948258 createNewBlock=false
17/04/04 18:30:31 DEBUG DFSClient: Queued packet 207
17/04/04 18:30:31 DEBUG DFSClient: Waiting for ack for: 207
17/04/04 18:30:31 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 207 offsetInBlock: 948224 lastPacketInBlock: false lastByteOffsetInBlock: 952987
17/04/04 18:30:31 DEBUG DFSClient: DFSClient seqno: 207 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:30:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:30:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 80:===========================================>              (3 + 1) / 4]17/04/04 18:30:32 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=208, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=952832
17/04/04 18:30:32 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=952987 lastFlushOffset=952987 createNewBlock=false
17/04/04 18:30:32 DEBUG DFSClient: Waiting for ack for: 207
[Stage 81:>                                                         (0 + 4) / 4][Stage 81:==============>                                           (1 + 3) / 4][Stage 81:=============================>                            (2 + 2) / 4][Stage 81:===========================================>              (3 + 1) / 4]17/04/04 18:30:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=209, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=952832
17/04/04 18:30:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=962135 lastFlushOffset=952987 createNewBlock=false
17/04/04 18:30:35 DEBUG DFSClient: Queued packet 209
17/04/04 18:30:35 DEBUG DFSClient: Waiting for ack for: 209
17/04/04 18:30:35 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 209 offsetInBlock: 952832 lastPacketInBlock: false lastByteOffsetInBlock: 962135
17/04/04 18:30:35 DEBUG DFSClient: DFSClient seqno: 209 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                         (0 + 4) / 4][Stage 82:===========================================>              (3 + 1) / 4]17/04/04 18:30:37 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=210, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=962048
17/04/04 18:30:37 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=966686 lastFlushOffset=962135 createNewBlock=false
17/04/04 18:30:37 DEBUG DFSClient: Queued packet 210
17/04/04 18:30:37 DEBUG DFSClient: Waiting for ack for: 210
17/04/04 18:30:37 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 210 offsetInBlock: 962048 lastPacketInBlock: false lastByteOffsetInBlock: 966686
17/04/04 18:30:37 DEBUG DFSClient: DFSClient seqno: 210 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                         (0 + 4) / 4]17/04/04 18:30:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:30:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:30:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:30:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #69
17/04/04 18:30:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #69
17/04/04 18:30:51 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/04/04 18:30:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:30:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 83:==============>                                           (1 + 3) / 4]17/04/04 18:31:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:31:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:=============================>                            (2 + 2) / 4][Stage 83:===========================================>              (3 + 1) / 4]17/04/04 18:31:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:31:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:31:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:31:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #70
17/04/04 18:31:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #70
17/04/04 18:31:21 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/04/04 18:31:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:31:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:31:21 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=211, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=966656
17/04/04 18:31:21 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=971865 lastFlushOffset=966686 createNewBlock=false
17/04/04 18:31:21 DEBUG DFSClient: Queued packet 211
17/04/04 18:31:21 DEBUG DFSClient: Waiting for ack for: 211
17/04/04 18:31:21 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 211 offsetInBlock: 966656 lastPacketInBlock: false lastByteOffsetInBlock: 971865
17/04/04 18:31:21 WARN DFSClient: Slow ReadProcessor read fields took 44241ms (threshold=30000ms); ack: seqno: 211 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 84:>                                                         (0 + 4) / 4]17/04/04 18:31:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:31:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:==============>                                           (1 + 3) / 4][Stage 84:=============================>                            (2 + 2) / 4][Stage 84:===========================================>              (3 + 1) / 4]17/04/04 18:31:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=212, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=971776
17/04/04 18:31:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=977268 lastFlushOffset=971865 createNewBlock=false
17/04/04 18:31:49 DEBUG DFSClient: Queued packet 212
17/04/04 18:31:49 DEBUG DFSClient: Waiting for ack for: 212
17/04/04 18:31:49 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 212 offsetInBlock: 971776 lastPacketInBlock: false lastByteOffsetInBlock: 977268
17/04/04 18:31:49 DEBUG DFSClient: DFSClient seqno: 212 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                         (0 + 3) / 3]17/04/04 18:31:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:31:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:31:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:31:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #71
17/04/04 18:31:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #71
17/04/04 18:31:51 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:31:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:31:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
[Stage 85:===================>                                      (1 + 2) / 3]17/04/04 18:32:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:32:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 85:======================================>                   (2 + 1) / 3]17/04/04 18:32:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=213, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=976896
17/04/04 18:32:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=982666 lastFlushOffset=977268 createNewBlock=false
17/04/04 18:32:04 DEBUG DFSClient: Queued packet 213
17/04/04 18:32:04 DEBUG DFSClient: Waiting for ack for: 213
17/04/04 18:32:04 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 213 offsetInBlock: 976896 lastPacketInBlock: false lastByteOffsetInBlock: 982666
17/04/04 18:32:04 DEBUG DFSClient: DFSClient seqno: 213 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                         (0 + 3) / 3][Stage 86:===================>                                      (1 + 2) / 3][Stage 86:======================================>                   (2 + 1) / 3]17/04/04 18:32:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=214, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=982528
17/04/04 18:32:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=987641 lastFlushOffset=982666 createNewBlock=false
17/04/04 18:32:19 DEBUG DFSClient: Queued packet 214
17/04/04 18:32:19 DEBUG DFSClient: Waiting for ack for: 214
17/04/04 18:32:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 214 offsetInBlock: 982528 lastPacketInBlock: false lastByteOffsetInBlock: 987641
17/04/04 18:32:19 DEBUG DFSClient: DFSClient seqno: 214 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                         (0 + 4) / 9]17/04/04 18:32:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:32:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:32:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:32:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #72
17/04/04 18:32:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #72
17/04/04 18:32:21 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/04/04 18:32:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:32:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:32:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:32:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:======>                                                   (1 + 4) / 9]17/04/04 18:32:51 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:32:51 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:32:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:32:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #73
17/04/04 18:32:51 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #73
17/04/04 18:32:51 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:32:51 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:32:51 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:32:52 WARN TaskSetManager: Lost task 2.0 in stage 87.3 (TID 740, 172.21.15.173, executor 17): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at com.esotericsoftware.kryo.io.Input.readDoubles(Input.java:885)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:222)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$DoubleArraySerializer.read(DefaultArraySerializers.java:205)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:69)
	at com.twitter.chill.Tuple4Serializer.read(TupleSerializers.scala:59)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:244)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:159)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:189)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:186)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)

17/04/04 18:32:53 ERROR TaskSchedulerImpl: Lost executor 17 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:32:53 WARN TaskSetManager: Lost task 4.0 in stage 87.3 (TID 744, 172.21.15.173, executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/04/04 18:32:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=215, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=987136
17/04/04 18:32:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=993487 lastFlushOffset=987641 createNewBlock=false
17/04/04 18:32:53 DEBUG DFSClient: Queued packet 215
17/04/04 18:32:53 DEBUG DFSClient: Waiting for ack for: 215
17/04/04 18:32:53 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 215 offsetInBlock: 987136 lastPacketInBlock: false lastByteOffsetInBlock: 993487
[Stage 87:======>                                                   (1 + 3) / 9]17/04/04 18:32:53 WARN DFSClient: Slow ReadProcessor read fields took 33995ms (threshold=30000ms); ack: seqno: 215 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/04/04 18:32:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=216, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=993280
17/04/04 18:32:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=993487 lastFlushOffset=993487 createNewBlock=false
17/04/04 18:32:53 DEBUG DFSClient: Waiting for ack for: 215
17/04/04 18:33:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:33:01 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/04/04 18:33:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=217, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=993280
17/04/04 18:33:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=993487 lastFlushOffset=993487 createNewBlock=false
17/04/04 18:33:02 DEBUG DFSClient: Waiting for ack for: 215
[Stage 87:======>                                                   (1 + 4) / 9]17/04/04 18:33:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=218, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=993280
17/04/04 18:33:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=993487 lastFlushOffset=993487 createNewBlock=false
17/04/04 18:33:02 DEBUG DFSClient: Waiting for ack for: 215
17/04/04 18:33:21 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:33:21 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:33:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:33:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #74
17/04/04 18:33:21 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #74
17/04/04 18:33:21 DEBUG ProtobufRpcEngine: Call: renewLease took 5ms
17/04/04 18:33:21 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-495888142_1
17/04/04 18:33:21 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-495888142_1] with renew id 1 executed
17/04/04 18:33:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:33:31 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:======>                                                   (1 + 5) / 9][Stage 87:============>                                             (2 + 4) / 9]17/04/04 18:33:34 WARN TaskSetManager: Lost task 4.1 in stage 87.3 (TID 745, 172.21.15.173, executor 19): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/04 18:33:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=219, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=993280
17/04/04 18:33:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=999776 lastFlushOffset=993487 createNewBlock=false
17/04/04 18:33:34 DEBUG DFSClient: Queued packet 219
17/04/04 18:33:34 DEBUG DFSClient: Waiting for ack for: 219
17/04/04 18:33:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 219 offsetInBlock: 993280 lastPacketInBlock: false lastByteOffsetInBlock: 999776
17/04/04 18:33:34 WARN DFSClient: Slow ReadProcessor read fields took 40543ms (threshold=30000ms); ack: seqno: 219 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 87 (mapPartitions at VertexRDD.scala:356) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2 	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697) 	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693) 	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338) 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285) 	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54) 	at org.apache.spark.scheduler.Task.run(Task.scala:114) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1456)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1443)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1443)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1273)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1626)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1615)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2016)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2037)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2056)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1159)
	at src.main.scala.SVDPlusPlusApp$.main(SVDPlusPlusApp.scala:105)
	at src.main.scala.SVDPlusPlusApp.main(SVDPlusPlusApp.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/04/04 18:33:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=220, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=999424
17/04/04 18:33:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=999776 lastFlushOffset=999776 createNewBlock=false
17/04/04 18:33:34 DEBUG DFSClient: Waiting for ack for: 219
17/04/04 18:33:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=221, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=999424
17/04/04 18:33:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=999776 lastFlushOffset=999776 createNewBlock=false
17/04/04 18:33:34 DEBUG DFSClient: Waiting for ack for: 219
17/04/04 18:33:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=222, src=/eventLogs/app-20170404175950-0081.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=999424
17/04/04 18:33:34 DEBUG DFSClient: Queued packet 222
17/04/04 18:33:34 DEBUG DFSClient: Queued packet 223
17/04/04 18:33:34 DEBUG DFSClient: Waiting for ack for: 223
17/04/04 18:33:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 222 offsetInBlock: 999424 lastPacketInBlock: false lastByteOffsetInBlock: 1002823
17/04/04 18:33:34 DEBUG DFSClient: DFSClient seqno: 222 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:33:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141 sending packet packet seqno: 223 offsetInBlock: 1002823 lastPacketInBlock: true lastByteOffsetInBlock: 1002823
17/04/04 18:33:34 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(14,WrappedArray((746,87,3,Vector(AccumulableInfo(20544,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(20545,Some(internal.metrics.executorDeserializeCpuTime),Some(0),None,true,true,None), AccumulableInfo(20546,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(20547,Some(internal.metrics.executorCpuTime),Some(0),None,true,true,None), AccumulableInfo(20548,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(20549,Some(internal.metrics.jvmGCTime),Some(964),None,true,true,None), AccumulableInfo(20550,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(20551,Some(internal.metrics.memoryBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(20552,Some(internal.metrics.diskBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(20553,Some(internal.metrics.peakExecutionMemory),Some(0),None,true,true,None), AccumulableInfo(20554,Some(internal.metrics.updatedBlockStatuses),Some([]),None,true,true,None), AccumulableInfo(20555,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(20556,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(20557,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(20558,Some(internal.metrics.shuffle.read.localBytesRead),Some(0),None,true,true,None), AccumulableInfo(20559,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(20560,Some(internal.metrics.shuffle.read.recordsRead),Some(0),None,true,true,None), AccumulableInfo(20561,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(20562,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(20563,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(20564,Some(internal.metrics.input.bytesRead),Some(12942947),None,true,true,None), AccumulableInfo(20565,Some(internal.metrics.input.recordsRead),Some(1),None,true,true,None), AccumulableInfo(20566,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(20567,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None)))))
17/04/04 18:33:34 DEBUG DFSClient: DFSClient seqno: 223 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/04/04 18:33:34 DEBUG DFSClient: Closing old block BP-519507147-172.21.15.90-1479901973323:blk_1073812963_72141
17/04/04 18:33:34 DEBUG Client: The ping interval is 60000 ms.
17/04/04 18:33:34 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/04/04 18:33:34 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/04/04 18:33:34 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #75
17/04/04 18:33:34 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #75
17/04/04 18:33:34 DEBUG ProtobufRpcEngine: Call: complete took 6ms
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #76
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #76
17/04/04 18:33:35 DEBUG ProtobufRpcEngine: Call: complete took 22ms
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #77
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #77
17/04/04 18:33:35 DEBUG ProtobufRpcEngine: Call: getFileInfo took 2ms
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #78
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #78
17/04/04 18:33:35 DEBUG ProtobufRpcEngine: Call: rename took 9ms
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop sending #79
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop got value #79
17/04/04 18:33:35 DEBUG ProtobufRpcEngine: Call: setTimes took 9ms
17/04/04 18:33:35 DEBUG PoolThreadCache: Freed 35 thread-local buffer(s) from thread: shuffle-server-6-3
17/04/04 18:33:35 DEBUG Client: stopping client from cache: org.apache.hadoop.ipc.Client@3cba87f2
17/04/04 18:33:35 DEBUG Client: removing client from cache: org.apache.hadoop.ipc.Client@3cba87f2
17/04/04 18:33:35 DEBUG Client: stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3cba87f2
17/04/04 18:33:35 DEBUG Client: Stopping client
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/04/04 18:33:35 DEBUG Client: IPC Client (1465572305) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
