storage level StorageLevel(disk, memory, deserialized, 1 replicas)
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/12/07 13:08:50 INFO SparkContext: Running Spark version 2.0.2
16/12/07 13:08:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/12/07 13:08:51 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/12/07 13:08:51 INFO SecurityManager: Changing view acls to: hadoop
16/12/07 13:08:51 INFO SecurityManager: Changing modify acls to: hadoop
16/12/07 13:08:51 INFO SecurityManager: Changing view acls groups to: 
16/12/07 13:08:51 INFO SecurityManager: Changing modify acls groups to: 
16/12/07 13:08:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
16/12/07 13:08:51 INFO Utils: Successfully started service 'sparkDriver' on port 50959.
16/12/07 13:08:51 INFO SparkEnv: Registering MapOutputTracker
16/12/07 13:08:51 INFO SparkEnv: Registering BlockManagerMaster
16/12/07 13:08:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-04f4f6bc-22b6-45f7-857f-b89924c422fb
16/12/07 13:08:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
16/12/07 13:08:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/12/07 13:08:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/12/07 13:08:51 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.21.15.90:4040
16/12/07 13:08:51 INFO SparkContext: Added JAR file:/home/hadoop/bryantchang/codes/SparkBench/SQL/target/SQLApp-1.0.jar at spark://172.21.15.90:50959/jars/SQLApp-1.0.jar with timestamp 1481087331819
16/12/07 13:08:51 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark1:7077...
16/12/07 13:08:51 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark1:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:88)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:96)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to spark1/172.21.15.90:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: java.net.ConnectException: 拒绝连接: spark1/172.21.15.90:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more
