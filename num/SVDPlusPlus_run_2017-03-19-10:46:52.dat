17/03/19 10:46:53 WARN SparkContext: Support for Java 7 is deprecated as of Spark 2.0.0
17/03/19 10:46:53 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
17/03/19 10:46:53 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
17/03/19 10:46:53 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
17/03/19 10:46:53 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
17/03/19 10:46:53 DEBUG Shell: setsid exited with exit code 0
17/03/19 10:46:53 DEBUG Groups:  Creating new Groups object
17/03/19 10:46:53 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
17/03/19 10:46:53 DEBUG NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
17/03/19 10:46:53 DEBUG NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
17/03/19 10:46:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/19 10:46:53 DEBUG PerformanceAdvisory: Falling back to shell based
17/03/19 10:46:53 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
17/03/19 10:46:53 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17/03/19 10:46:53 DEBUG UserGroupInformation: hadoop login
17/03/19 10:46:53 DEBUG UserGroupInformation: hadoop login commit
17/03/19 10:46:53 DEBUG UserGroupInformation: using local user:UnixPrincipal: hadoop
17/03/19 10:46:53 DEBUG UserGroupInformation: Using user: "UnixPrincipal: hadoop" with name hadoop
17/03/19 10:46:53 DEBUG UserGroupInformation: User entry: "hadoop"
17/03/19 10:46:53 DEBUG UserGroupInformation: UGI loginUser:hadoop (auth:SIMPLE)
17/03/19 10:46:53 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
17/03/19 10:46:53 WARN SparkConf: 
SPARK_CLASSPATH was detected (set to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
17/03/19 10:46:53 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:' as a work-around.
17/03/19 10:46:53 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/hadoop/bryantchang/platforms/spark2.0/lib/mysql-connector-java-5.1.40-bin.jar:' as a work-around.
17/03/19 10:46:53 DEBUG InternalLoggerFactory: Using SLF4J as the default logging framework
17/03/19 10:46:53 DEBUG PlatformDependent0: java.nio.Buffer.address: available
17/03/19 10:46:53 DEBUG PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
17/03/19 10:46:53 DEBUG PlatformDependent0: sun.misc.Unsafe.copyMemory: available
17/03/19 10:46:53 DEBUG PlatformDependent0: direct buffer constructor: available
17/03/19 10:46:53 DEBUG PlatformDependent0: java.nio.Bits.unaligned: available, true
17/03/19 10:46:53 DEBUG PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
17/03/19 10:46:53 DEBUG Cleaner0: java.nio.ByteBuffer.cleaner(): available
17/03/19 10:46:53 DEBUG PlatformDependent: Java version: 7
17/03/19 10:46:53 DEBUG PlatformDependent: -Dio.netty.noUnsafe: false
17/03/19 10:46:53 DEBUG PlatformDependent: sun.misc.Unsafe: available
17/03/19 10:46:53 DEBUG PlatformDependent: -Dio.netty.noJavassist: false
17/03/19 10:46:53 DEBUG PlatformDependent: Javassist: available
17/03/19 10:46:53 DEBUG PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
17/03/19 10:46:53 DEBUG PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
17/03/19 10:46:53 DEBUG PlatformDependent: -Dio.netty.noPreferDirect: false
17/03/19 10:46:53 DEBUG PlatformDependent: io.netty.maxDirectMemory: 1342177280 bytes
17/03/19 10:46:53 DEBUG JavassistTypeParameterMatcherGenerator: Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
17/03/19 10:46:53 DEBUG JavassistTypeParameterMatcherGenerator: Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
17/03/19 10:46:53 DEBUG MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 8
17/03/19 10:46:53 DEBUG NioEventLoop: -Dio.netty.noKeySetOptimization: false
17/03/19 10:46:53 DEBUG NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
17/03/19 10:46:53 DEBUG PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 8
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 8
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
17/03/19 10:46:54 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
17/03/19 10:46:54 DEBUG ThreadLocalRandom: -Dio.netty.initialSeedUniquifier: 0x62302cacdf99c512 (took 0 ms)
17/03/19 10:46:54 DEBUG ByteBufUtil: -Dio.netty.allocator.type: unpooled
17/03/19 10:46:54 DEBUG ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
17/03/19 10:46:54 DEBUG ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
17/03/19 10:46:54 DEBUG NetUtil: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%1)
17/03/19 10:46:54 DEBUG NetUtil: /proc/sys/net/core/somaxconn: 128
17/03/19 10:46:54 DEBUG AbstractByteBuf: -Dio.netty.buffer.bytebuf.checkAccessible: true
17/03/19 10:46:54 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
17/03/19 10:46:54 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.maxRecords: 4
17/03/19 10:46:54 DEBUG ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@189a9f42
17/03/19 10:46:54 DEBUG Recycler: -Dio.netty.recycler.maxCapacity.default: 32768
17/03/19 10:46:54 DEBUG Recycler: -Dio.netty.recycler.maxSharedCapacityFactor: 2
17/03/19 10:46:54 DEBUG Recycler: -Dio.netty.recycler.linkCapacity: 16
17/03/19 10:46:54 DEBUG Recycler: -Dio.netty.recycler.ratio: 8
17/03/19 10:46:54 DEBUG BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false
17/03/19 10:46:54 DEBUG BlockReaderLocal: dfs.client.read.shortcircuit = false
17/03/19 10:46:54 DEBUG BlockReaderLocal: dfs.client.domain.socket.data.traffic = false
17/03/19 10:46:54 DEBUG BlockReaderLocal: dfs.domain.socket.path = 
17/03/19 10:46:54 DEBUG RetryUtils: multipleLinearRandomRetry = null
17/03/19 10:46:54 DEBUG Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6c750751
17/03/19 10:46:54 DEBUG Client: getting client out of cache: org.apache.hadoop.ipc.Client@3c71d5a
17/03/19 10:46:54 DEBUG PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
17/03/19 10:46:54 DEBUG DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
17/03/19 10:46:54 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:46:54 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:46:54 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:46:54 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #0
17/03/19 10:46:54 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #0
17/03/19 10:46:54 DEBUG ProtobufRpcEngine: Call: getFileInfo took 25ms
17/03/19 10:46:54 DEBUG DFSClient: /eventLogs/app-20170319104654-0012.lz4.inprogress: masked=rw-r--r--
17/03/19 10:46:54 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #1
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #1
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: create took 11ms
17/03/19 10:46:55 DEBUG DFSClient: computePacketChunkSize: src=/eventLogs/app-20170319104654-0012.lz4.inprogress, chunkSize=516, chunksPerPacket=126, packetSize=65016
17/03/19 10:46:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 started
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #2
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #2
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: setPermission took 9ms
17/03/19 10:46:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/03/19 10:46:55 DEBUG DFSClient: Waiting for ack for: -1
17/03/19 10:46:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/03/19 10:46:55 DEBUG DFSClient: Waiting for ack for: -1
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #3
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #3
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: getFileInfo took 1ms
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #4
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #4
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: getListing took 2ms
17/03/19 10:46:55 DEBUG FileInputFormat: Time taken to get FileStatuses: 16
17/03/19 10:46:55 INFO FileInputFormat: Total input paths to process : 10
17/03/19 10:46:55 DEBUG FileInputFormat: Total # of splits generated by getSplits: 12, TimeTaken: 19
17/03/19 10:46:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=0 lastFlushOffset=0 createNewBlock=false
17/03/19 10:46:55 DEBUG DFSClient: Waiting for ack for: -1
17/03/19 10:46:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=0, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/19 10:46:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6323 lastFlushOffset=0 createNewBlock=false
17/03/19 10:46:55 DEBUG DFSClient: Queued packet 0
17/03/19 10:46:55 DEBUG DFSClient: Waiting for ack for: 0
17/03/19 10:46:55 DEBUG DFSClient: Allocating new block
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #5
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #5
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: addBlock took 7ms
17/03/19 10:46:55 DEBUG DFSClient: pipeline = DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]
17/03/19 10:46:55 DEBUG DFSClient: Connecting to datanode 172.21.15.173:50010
17/03/19 10:46:55 DEBUG DFSClient: Send buf size 124928
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #6
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #6
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: getServerDefaults took 1ms
17/03/19 10:46:55 DEBUG SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /172.21.15.173, datanodeId = DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]
17/03/19 10:46:55 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6323
17/03/19 10:46:55 DEBUG DFSClient: DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #7
17/03/19 10:46:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #7
17/03/19 10:46:55 DEBUG ProtobufRpcEngine: Call: fsync took 7ms
17/03/19 10:46:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=1, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/03/19 10:46:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=6323 lastFlushOffset=6323 createNewBlock=false
17/03/19 10:46:55 DEBUG DFSClient: Waiting for ack for: 0
[Stage 0:>                                                         (0 + 4) / 10][Stage 0:=====>                                                    (1 + 6) / 10][Stage 0:=================>                                        (3 + 4) / 10][Stage 0:=======================>                                  (4 + 4) / 10][Stage 0:=============================>                            (5 + 4) / 10][Stage 0:==================================>                       (6 + 4) / 10][Stage 0:==============================================>           (8 + 2) / 10][Stage 0:====================================================>     (9 + 1) / 10]                                                                                17/03/19 10:47:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=2, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6144
17/03/19 10:47:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=10417 lastFlushOffset=6323 createNewBlock=false
17/03/19 10:47:05 DEBUG DFSClient: Queued packet 2
17/03/19 10:47:05 DEBUG DFSClient: Waiting for ack for: 2
17/03/19 10:47:05 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 2 offsetInBlock: 6144 lastPacketInBlock: false lastByteOffsetInBlock: 10417
17/03/19 10:47:05 DEBUG DFSClient: DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=3, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10240
17/03/19 10:47:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=10417 lastFlushOffset=10417 createNewBlock=false
17/03/19 10:47:05 DEBUG DFSClient: Waiting for ack for: 2
17/03/19 10:47:05 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=4, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10240
17/03/19 10:47:05 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=10417 lastFlushOffset=10417 createNewBlock=false
17/03/19 10:47:05 DEBUG DFSClient: Waiting for ack for: 2
17/03/19 10:47:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:47:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 1:>                                                         (0 + 4) / 10][Stage 1:=================>                                        (3 + 4) / 10][Stage 1:=======================>                                  (4 + 4) / 10][Stage 1:========================================>                 (7 + 3) / 10][Stage 1:==============================================>           (8 + 2) / 10][Stage 1:====================================================>     (9 + 1) / 10]17/03/19 10:47:07 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=5, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10240
17/03/19 10:47:07 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=14717 lastFlushOffset=10417 createNewBlock=false
17/03/19 10:47:07 DEBUG DFSClient: Queued packet 5
17/03/19 10:47:07 DEBUG DFSClient: Waiting for ack for: 5
17/03/19 10:47:07 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 5 offsetInBlock: 10240 lastPacketInBlock: false lastByteOffsetInBlock: 14717
17/03/19 10:47:07 DEBUG DFSClient: DFSClient seqno: 5 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 2:>                                                         (0 + 4) / 10][Stage 2:=======================>                                  (4 + 4) / 10][Stage 2:==============================================>           (8 + 2) / 10][Stage 2:====================================================>     (9 + 1) / 10]                                                                                17/03/19 10:47:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=6, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14336
17/03/19 10:47:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=26951 lastFlushOffset=14717 createNewBlock=false
17/03/19 10:47:15 DEBUG DFSClient: Queued packet 6
17/03/19 10:47:15 DEBUG DFSClient: Waiting for ack for: 6
17/03/19 10:47:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 6 offsetInBlock: 14336 lastPacketInBlock: false lastByteOffsetInBlock: 26951
17/03/19 10:47:15 DEBUG DFSClient: DFSClient seqno: 6 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=7, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26624
17/03/19 10:47:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=26951 lastFlushOffset=26951 createNewBlock=false
17/03/19 10:47:15 DEBUG DFSClient: Waiting for ack for: 6
17/03/19 10:47:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=8, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26624
17/03/19 10:47:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=31617 lastFlushOffset=26951 createNewBlock=false
17/03/19 10:47:15 DEBUG DFSClient: Queued packet 8
17/03/19 10:47:15 DEBUG DFSClient: Waiting for ack for: 8
17/03/19 10:47:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 8 offsetInBlock: 26624 lastPacketInBlock: false lastByteOffsetInBlock: 31617
17/03/19 10:47:15 DEBUG DFSClient: DFSClient seqno: 8 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 4:>                                                         (0 + 4) / 10][Stage 4:=======================>                                  (4 + 4) / 10]17/03/19 10:47:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:47:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:47:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:47:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #8
17/03/19 10:47:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #8
17/03/19 10:47:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:47:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:47:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 4:==============================================>           (8 + 2) / 10]17/03/19 10:47:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=9, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31232
17/03/19 10:47:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=39713 lastFlushOffset=31617 createNewBlock=false
17/03/19 10:47:31 DEBUG DFSClient: Queued packet 9
17/03/19 10:47:31 DEBUG DFSClient: Waiting for ack for: 9
17/03/19 10:47:31 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 9 offsetInBlock: 31232 lastPacketInBlock: false lastByteOffsetInBlock: 39713
17/03/19 10:47:31 DEBUG DFSClient: DFSClient seqno: 9 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
                                                                                17/03/19 10:47:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=10, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=39424
17/03/19 10:47:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=44570 lastFlushOffset=39713 createNewBlock=false
17/03/19 10:47:31 DEBUG DFSClient: Queued packet 10
17/03/19 10:47:31 DEBUG DFSClient: Waiting for ack for: 10
17/03/19 10:47:31 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 10 offsetInBlock: 39424 lastPacketInBlock: false lastByteOffsetInBlock: 44570
17/03/19 10:47:31 DEBUG DFSClient: DFSClient seqno: 10 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=11, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=44544
17/03/19 10:47:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=44570 lastFlushOffset=44570 createNewBlock=false
17/03/19 10:47:31 DEBUG DFSClient: Waiting for ack for: 10
17/03/19 10:47:31 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=12, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=44544
17/03/19 10:47:31 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=48785 lastFlushOffset=44570 createNewBlock=false
17/03/19 10:47:31 DEBUG DFSClient: Queued packet 12
17/03/19 10:47:31 DEBUG DFSClient: Waiting for ack for: 12
17/03/19 10:47:31 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 12 offsetInBlock: 44544 lastPacketInBlock: false lastByteOffsetInBlock: 48785
17/03/19 10:47:31 DEBUG DFSClient: DFSClient seqno: 12 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 7:>                                                         (0 + 4) / 10]17/03/19 10:47:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:47:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 7:=====>                                                    (1 + 4) / 10][Stage 7:=================>                                        (3 + 4) / 10][Stage 7:=======================>                                  (4 + 4) / 10][Stage 7:=============================>                            (5 + 4) / 10][Stage 7:==================================>                       (6 + 4) / 10][Stage 7:==============================================>           (8 + 2) / 10][Stage 7:====================================================>     (9 + 1) / 10]                                                                                17/03/19 10:47:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=13, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=48640
17/03/19 10:47:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=55738 lastFlushOffset=48785 createNewBlock=false
17/03/19 10:47:47 DEBUG DFSClient: Queued packet 13
17/03/19 10:47:47 DEBUG DFSClient: Waiting for ack for: 13
17/03/19 10:47:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 13 offsetInBlock: 48640 lastPacketInBlock: false lastByteOffsetInBlock: 55738
17/03/19 10:47:47 DEBUG DFSClient: DFSClient seqno: 13 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=14, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=55296
17/03/19 10:47:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=55738 lastFlushOffset=55738 createNewBlock=false
17/03/19 10:47:47 DEBUG DFSClient: Waiting for ack for: 13
17/03/19 10:47:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=15, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=55296
17/03/19 10:47:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=55738 lastFlushOffset=55738 createNewBlock=false
17/03/19 10:47:47 DEBUG DFSClient: Waiting for ack for: 13
17/03/19 10:47:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=16, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=55296
17/03/19 10:47:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=59931 lastFlushOffset=55738 createNewBlock=false
17/03/19 10:47:47 DEBUG DFSClient: Queued packet 16
17/03/19 10:47:47 DEBUG DFSClient: Waiting for ack for: 16
17/03/19 10:47:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 16 offsetInBlock: 55296 lastPacketInBlock: false lastByteOffsetInBlock: 59931
17/03/19 10:47:47 DEBUG DFSClient: DFSClient seqno: 16 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:47 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=17, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=59904
17/03/19 10:47:47 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=64701 lastFlushOffset=59931 createNewBlock=false
17/03/19 10:47:47 DEBUG DFSClient: Queued packet 17
17/03/19 10:47:47 DEBUG DFSClient: Waiting for ack for: 17
17/03/19 10:47:47 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 17 offsetInBlock: 59904 lastPacketInBlock: false lastByteOffsetInBlock: 64701
17/03/19 10:47:47 DEBUG DFSClient: DFSClient seqno: 17 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 11:>                                                        (0 + 4) / 10][Stage 11:===========>                                             (2 + 4) / 10][Stage 11:=================>                                       (3 + 4) / 10][Stage 11:======================>                                  (4 + 4) / 10][Stage 11:=======================================>                 (7 + 3) / 10]17/03/19 10:47:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=18, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512
17/03/19 10:47:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=74007 lastFlushOffset=64701 createNewBlock=false
17/03/19 10:47:49 DEBUG DFSClient: Queued packet 18
17/03/19 10:47:49 DEBUG DFSClient: Waiting for ack for: 18
17/03/19 10:47:49 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 18 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 74007
17/03/19 10:47:49 DEBUG DFSClient: DFSClient seqno: 18 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
                                                                                17/03/19 10:47:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=19, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=73728
17/03/19 10:47:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=82858 lastFlushOffset=74007 createNewBlock=false
17/03/19 10:47:49 DEBUG DFSClient: Queued packet 19
17/03/19 10:47:49 DEBUG DFSClient: Waiting for ack for: 19
17/03/19 10:47:49 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 19 offsetInBlock: 73728 lastPacketInBlock: false lastByteOffsetInBlock: 82858
17/03/19 10:47:49 DEBUG DFSClient: DFSClient seqno: 19 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=20, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=82432
17/03/19 10:47:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=82858 lastFlushOffset=82858 createNewBlock=false
17/03/19 10:47:49 DEBUG DFSClient: Waiting for ack for: 19
17/03/19 10:47:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=21, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=82432
17/03/19 10:47:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=82858 lastFlushOffset=82858 createNewBlock=false
17/03/19 10:47:49 DEBUG DFSClient: Waiting for ack for: 19
17/03/19 10:47:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=22, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=82432
17/03/19 10:47:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=92766 lastFlushOffset=82858 createNewBlock=false
17/03/19 10:47:50 DEBUG DFSClient: Queued packet 22
17/03/19 10:47:50 DEBUG DFSClient: Waiting for ack for: 22
17/03/19 10:47:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 22 offsetInBlock: 82432 lastPacketInBlock: false lastByteOffsetInBlock: 92766
17/03/19 10:47:50 DEBUG DFSClient: DFSClient seqno: 22 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=23, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=92672
17/03/19 10:47:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=100734 lastFlushOffset=92766 createNewBlock=false
17/03/19 10:47:50 DEBUG DFSClient: Queued packet 23
17/03/19 10:47:50 DEBUG DFSClient: Waiting for ack for: 23
17/03/19 10:47:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 23 offsetInBlock: 92672 lastPacketInBlock: false lastByteOffsetInBlock: 100734
17/03/19 10:47:50 DEBUG DFSClient: DFSClient seqno: 23 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=24, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=100352
17/03/19 10:47:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=100734 lastFlushOffset=100734 createNewBlock=false
17/03/19 10:47:50 DEBUG DFSClient: Waiting for ack for: 23
17/03/19 10:47:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=25, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=100352
17/03/19 10:47:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=100734 lastFlushOffset=100734 createNewBlock=false
17/03/19 10:47:50 DEBUG DFSClient: Waiting for ack for: 23
17/03/19 10:47:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=26, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=100352
17/03/19 10:47:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=100734 lastFlushOffset=100734 createNewBlock=false
17/03/19 10:47:50 DEBUG DFSClient: Waiting for ack for: 23
17/03/19 10:47:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=27, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=100352
17/03/19 10:47:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=104859 lastFlushOffset=100734 createNewBlock=false
17/03/19 10:47:50 DEBUG DFSClient: Queued packet 27
17/03/19 10:47:50 DEBUG DFSClient: Waiting for ack for: 27
17/03/19 10:47:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 27 offsetInBlock: 100352 lastPacketInBlock: false lastByteOffsetInBlock: 104859
17/03/19 10:47:50 DEBUG DFSClient: DFSClient seqno: 27 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 24:>                                                        (0 + 4) / 10][Stage 24:=================>                                       (3 + 4) / 10][Stage 24:======================>                                  (4 + 4) / 10][Stage 24:==================================>                      (6 + 4) / 10][Stage 24:=============================================>           (8 + 2) / 10]17/03/19 10:47:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=28, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=104448
17/03/19 10:47:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=109138 lastFlushOffset=104859 createNewBlock=false
17/03/19 10:47:53 DEBUG DFSClient: Queued packet 28
17/03/19 10:47:53 DEBUG DFSClient: Waiting for ack for: 28
17/03/19 10:47:53 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 28 offsetInBlock: 104448 lastPacketInBlock: false lastByteOffsetInBlock: 109138
17/03/19 10:47:53 DEBUG DFSClient: DFSClient seqno: 28 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 25:======================>                                  (4 + 4) / 10][Stage 25:=============================================>           (8 + 2) / 10]                                                                                17/03/19 10:47:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=29, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=109056
17/03/19 10:47:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=122107 lastFlushOffset=109138 createNewBlock=false
17/03/19 10:47:54 DEBUG DFSClient: Queued packet 29
17/03/19 10:47:54 DEBUG DFSClient: Waiting for ack for: 29
17/03/19 10:47:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 29 offsetInBlock: 109056 lastPacketInBlock: false lastByteOffsetInBlock: 122107
17/03/19 10:47:54 DEBUG DFSClient: DFSClient seqno: 29 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:47:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=30, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=121856
17/03/19 10:47:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=122107 lastFlushOffset=122107 createNewBlock=false
17/03/19 10:47:54 DEBUG DFSClient: Waiting for ack for: 29
17/03/19 10:47:54 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=31, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=121856
17/03/19 10:47:54 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=126063 lastFlushOffset=122107 createNewBlock=false
17/03/19 10:47:54 DEBUG DFSClient: Queued packet 31
17/03/19 10:47:54 DEBUG DFSClient: Waiting for ack for: 31
17/03/19 10:47:54 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 31 offsetInBlock: 121856 lastPacketInBlock: false lastByteOffsetInBlock: 126063
17/03/19 10:47:54 DEBUG DFSClient: DFSClient seqno: 31 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 32:============================>                            (5 + 4) / 10][Stage 32:=============================================>           (8 + 2) / 10]17/03/19 10:47:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:47:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:47:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:47:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #9
17/03/19 10:47:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #9
17/03/19 10:47:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:47:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:47:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:47:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=32, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=125952
17/03/19 10:47:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=131751 lastFlushOffset=126063 createNewBlock=false
17/03/19 10:47:55 DEBUG DFSClient: Queued packet 32
17/03/19 10:47:55 DEBUG DFSClient: Waiting for ack for: 32
17/03/19 10:47:55 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 32 offsetInBlock: 125952 lastPacketInBlock: false lastByteOffsetInBlock: 131751
17/03/19 10:47:55 DEBUG DFSClient: DFSClient seqno: 32 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 33:>                                                        (0 + 4) / 10][Stage 33:======================>                                  (4 + 4) / 10][Stage 33:=============================================>           (8 + 2) / 10]17/03/19 10:48:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=33, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=131584
                                                                                17/03/19 10:48:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=149763 lastFlushOffset=131751 createNewBlock=false
17/03/19 10:48:02 DEBUG DFSClient: Queued packet 33
17/03/19 10:48:02 DEBUG DFSClient: Waiting for ack for: 33
17/03/19 10:48:02 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 33 offsetInBlock: 131584 lastPacketInBlock: false lastByteOffsetInBlock: 149763
17/03/19 10:48:02 DEBUG DFSClient: DFSClient seqno: 33 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:48:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=34, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=149504
17/03/19 10:48:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=149763 lastFlushOffset=149763 createNewBlock=false
17/03/19 10:48:02 DEBUG DFSClient: Waiting for ack for: 33
17/03/19 10:48:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=35, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=149504
17/03/19 10:48:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=149763 lastFlushOffset=149763 createNewBlock=false
17/03/19 10:48:02 DEBUG DFSClient: Waiting for ack for: 33
17/03/19 10:48:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=36, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=149504
17/03/19 10:48:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=149763 lastFlushOffset=149763 createNewBlock=false
17/03/19 10:48:02 DEBUG DFSClient: Waiting for ack for: 33
17/03/19 10:48:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=37, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=149504
17/03/19 10:48:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=153992 lastFlushOffset=149763 createNewBlock=false
17/03/19 10:48:02 DEBUG DFSClient: Queued packet 37
17/03/19 10:48:02 DEBUG DFSClient: Waiting for ack for: 37
17/03/19 10:48:02 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 37 offsetInBlock: 149504 lastPacketInBlock: false lastByteOffsetInBlock: 153992
17/03/19 10:48:02 DEBUG DFSClient: DFSClient seqno: 37 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 41:>                                                        (0 + 4) / 10]17/03/19 10:48:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:48:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:48:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:48:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:48:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:48:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #10
17/03/19 10:48:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #10
17/03/19 10:48:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:48:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:48:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:48:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:48:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:48:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:48:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:48:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:48:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #11
17/03/19 10:48:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #11
17/03/19 10:48:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:48:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:48:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 41:>                                                        (0 + 4) / 10][Stage 41:=====>                                                   (1 + 4) / 10]17/03/19 10:49:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:49:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:======================>                                  (4 + 4) / 10]17/03/19 10:49:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:49:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:49:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:49:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #12
17/03/19 10:49:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #12
17/03/19 10:49:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:49:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:49:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:49:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:49:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 41:============================>                            (5 + 4) / 10][Stage 41:==================================>                      (6 + 4) / 10][Stage 41:=======================================>                 (7 + 3) / 10][Stage 41:=============================================>           (8 + 2) / 10][Stage 41:===================================================>     (9 + 1) / 10]17/03/19 10:49:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:49:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:49:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:49:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #13
17/03/19 10:49:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #13
17/03/19 10:49:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:49:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:49:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:49:55 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=38, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=153600
17/03/19 10:49:55 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=162514 lastFlushOffset=153992 createNewBlock=false
17/03/19 10:49:55 DEBUG DFSClient: Queued packet 38
17/03/19 10:49:55 DEBUG DFSClient: Waiting for ack for: 38
17/03/19 10:49:55 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 38 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 162514
17/03/19 10:49:55 WARN DFSClient: Slow ReadProcessor read fields took 113552ms (threshold=30000ms); ack: seqno: 38 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
[Stage 42:>                                                        (0 + 4) / 10][Stage 42:=====>                                                   (1 + 4) / 10][Stage 42:===========>                                             (2 + 4) / 10][Stage 42:=================>                                       (3 + 4) / 10][Stage 42:======================>                                  (4 + 4) / 10][Stage 42:==================================>                      (6 + 4) / 10][Stage 42:=======================================>                 (7 + 3) / 10][Stage 42:=============================================>           (8 + 2) / 10][Stage 42:===================================================>     (9 + 1) / 10]                                                                                17/03/19 10:50:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=39, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=162304
17/03/19 10:50:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=175377 lastFlushOffset=162514 createNewBlock=false
17/03/19 10:50:03 DEBUG DFSClient: Queued packet 39
17/03/19 10:50:03 DEBUG DFSClient: Waiting for ack for: 39
17/03/19 10:50:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 39 offsetInBlock: 162304 lastPacketInBlock: false lastByteOffsetInBlock: 175377
17/03/19 10:50:03 DEBUG DFSClient: DFSClient seqno: 39 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:50:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=40, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=175104
17/03/19 10:50:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=175377 lastFlushOffset=175377 createNewBlock=false
17/03/19 10:50:03 DEBUG DFSClient: Waiting for ack for: 39
17/03/19 10:50:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=41, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=175104
17/03/19 10:50:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=179297 lastFlushOffset=175377 createNewBlock=false
17/03/19 10:50:03 DEBUG DFSClient: Queued packet 41
17/03/19 10:50:03 DEBUG DFSClient: Waiting for ack for: 41
17/03/19 10:50:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 41 offsetInBlock: 175104 lastPacketInBlock: false lastByteOffsetInBlock: 179297
17/03/19 10:50:03 DEBUG DFSClient: DFSClient seqno: 41 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 51:>                                                        (0 + 4) / 10][Stage 51:=================>                                       (3 + 4) / 10][Stage 51:======================>                                  (4 + 4) / 10]17/03/19 10:50:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:50:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 51:============================>                            (5 + 4) / 10][Stage 51:=======================================>                 (7 + 3) / 10][Stage 51:=============================================>           (8 + 2) / 10]17/03/19 10:50:06 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=42, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=179200
17/03/19 10:50:06 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=183765 lastFlushOffset=179297 createNewBlock=false
17/03/19 10:50:06 DEBUG DFSClient: Queued packet 42
17/03/19 10:50:06 DEBUG DFSClient: Waiting for ack for: 42
17/03/19 10:50:06 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 42 offsetInBlock: 179200 lastPacketInBlock: false lastByteOffsetInBlock: 183765
17/03/19 10:50:06 DEBUG DFSClient: DFSClient seqno: 42 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 52:>                                                        (0 + 4) / 10][Stage 52:===========>                                             (2 + 4) / 10][Stage 52:=================>                                       (3 + 4) / 10][Stage 52:======================>                                  (4 + 4) / 10][Stage 52:============================>                            (5 + 4) / 10][Stage 52:==================================>                      (6 + 4) / 10][Stage 52:=======================================>                 (7 + 3) / 10]17/03/19 10:50:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=43, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=183296
[Stage 52:=============================================>           (8 + 2) / 10]17/03/19 10:50:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:50:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:50:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:50:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #14
17/03/19 10:50:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #14
17/03/19 10:50:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:50:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:50:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 52:===================================================>     (9 + 1) / 10]                                                                                17/03/19 10:50:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=205863 lastFlushOffset=183765 createNewBlock=false
17/03/19 10:50:26 DEBUG DFSClient: Queued packet 43
17/03/19 10:50:26 DEBUG DFSClient: Waiting for ack for: 43
17/03/19 10:50:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 43 offsetInBlock: 183296 lastPacketInBlock: false lastByteOffsetInBlock: 205863
17/03/19 10:50:26 DEBUG DFSClient: DFSClient seqno: 43 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:50:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=44, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=205824
17/03/19 10:50:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=205863 lastFlushOffset=205863 createNewBlock=false
17/03/19 10:50:26 DEBUG DFSClient: Waiting for ack for: 43
17/03/19 10:50:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=45, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=205824
17/03/19 10:50:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=205863 lastFlushOffset=205863 createNewBlock=false
17/03/19 10:50:26 DEBUG DFSClient: Waiting for ack for: 43
17/03/19 10:50:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=46, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=205824
17/03/19 10:50:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=205863 lastFlushOffset=205863 createNewBlock=false
17/03/19 10:50:26 DEBUG DFSClient: Waiting for ack for: 43
17/03/19 10:50:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=47, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=205824
17/03/19 10:50:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=213637 lastFlushOffset=205863 createNewBlock=false
17/03/19 10:50:26 DEBUG DFSClient: Queued packet 47
17/03/19 10:50:26 DEBUG DFSClient: Waiting for ack for: 47
17/03/19 10:50:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 47 offsetInBlock: 205824 lastPacketInBlock: false lastByteOffsetInBlock: 213637
17/03/19 10:50:26 DEBUG DFSClient: DFSClient seqno: 47 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 62:>                                                        (0 + 4) / 10][Stage 62:=====>                                                   (1 + 4) / 10]17/03/19 10:50:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:50:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 62:======================>                                  (4 + 4) / 10][Stage 62:============================>                            (5 + 4) / 10][Stage 62:==================================>                      (6 + 4) / 10][Stage 62:=======================================>                 (7 + 3) / 10][Stage 62:=============================================>           (8 + 2) / 10][Stage 62:===================================================>     (9 + 1) / 10]17/03/19 10:50:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=48, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=213504
17/03/19 10:50:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=223028 lastFlushOffset=213637 createNewBlock=false
17/03/19 10:50:44 DEBUG DFSClient: Queued packet 48
17/03/19 10:50:44 DEBUG DFSClient: Waiting for ack for: 48
17/03/19 10:50:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 48 offsetInBlock: 213504 lastPacketInBlock: false lastByteOffsetInBlock: 223028
17/03/19 10:50:44 DEBUG DFSClient: DFSClient seqno: 48 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 63:>                                                        (0 + 4) / 10][Stage 63:=====>                                                   (1 + 4) / 10][Stage 63:===========>                                             (2 + 4) / 10][Stage 63:======================>                                  (4 + 4) / 10][Stage 63:============================>                            (5 + 4) / 10][Stage 63:==================================>                      (6 + 4) / 10][Stage 63:=======================================>                 (7 + 3) / 10][Stage 63:=============================================>           (8 + 2) / 10][Stage 63:===================================================>     (9 + 1) / 10]                                                                                17/03/19 10:50:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=49, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=222720
17/03/19 10:50:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=235211 lastFlushOffset=223028 createNewBlock=false
17/03/19 10:50:51 DEBUG DFSClient: Queued packet 49
17/03/19 10:50:51 DEBUG DFSClient: Waiting for ack for: 49
17/03/19 10:50:51 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 49 offsetInBlock: 222720 lastPacketInBlock: false lastByteOffsetInBlock: 235211
17/03/19 10:50:51 DEBUG DFSClient: DFSClient seqno: 49 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:50:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=50, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=235008
17/03/19 10:50:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=235211 lastFlushOffset=235211 createNewBlock=false
17/03/19 10:50:51 DEBUG DFSClient: Waiting for ack for: 49
17/03/19 10:50:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=51, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=235008
17/03/19 10:50:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=242359 lastFlushOffset=235211 createNewBlock=false
17/03/19 10:50:51 DEBUG DFSClient: Queued packet 51
17/03/19 10:50:51 DEBUG DFSClient: Waiting for ack for: 51
17/03/19 10:50:51 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 51 offsetInBlock: 235008 lastPacketInBlock: false lastByteOffsetInBlock: 242359
17/03/19 10:50:51 DEBUG DFSClient: DFSClient seqno: 51 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 74:======================>                                  (4 + 4) / 10][Stage 74:==================================>                      (6 + 4) / 10]17/03/19 10:50:52 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=52, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=242176
17/03/19 10:50:52 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=247650 lastFlushOffset=242359 createNewBlock=false
17/03/19 10:50:52 DEBUG DFSClient: Queued packet 52
17/03/19 10:50:52 DEBUG DFSClient: Waiting for ack for: 52
17/03/19 10:50:52 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 52 offsetInBlock: 242176 lastPacketInBlock: false lastByteOffsetInBlock: 247650
17/03/19 10:50:52 DEBUG DFSClient: DFSClient seqno: 52 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 75:>                                                        (0 + 4) / 10]17/03/19 10:50:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:50:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:50:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:50:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #15
17/03/19 10:50:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #15
17/03/19 10:50:55 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/19 10:50:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:50:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 75:=====>                                                   (1 + 4) / 10][Stage 75:===========>                                             (2 + 4) / 10]17/03/19 10:51:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:51:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 75:=================>                                       (3 + 4) / 10][Stage 75:======================>                                  (4 + 4) / 10][Stage 75:============================>                            (5 + 4) / 10][Stage 75:==================================>                      (6 + 4) / 10]17/03/19 10:51:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=53, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=247296
[Stage 75:=============================================>           (8 + 2) / 10][Stage 75:===================================================>     (9 + 1) / 10]                                                                                17/03/19 10:51:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=264477 lastFlushOffset=247650 createNewBlock=false
17/03/19 10:51:20 DEBUG DFSClient: Queued packet 53
17/03/19 10:51:20 DEBUG DFSClient: Waiting for ack for: 53
17/03/19 10:51:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 53 offsetInBlock: 247296 lastPacketInBlock: false lastByteOffsetInBlock: 264477
17/03/19 10:51:20 DEBUG DFSClient: DFSClient seqno: 53 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:51:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=54, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=264192
17/03/19 10:51:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=264477 lastFlushOffset=264477 createNewBlock=false
17/03/19 10:51:20 DEBUG DFSClient: Waiting for ack for: 53
17/03/19 10:51:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=55, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=264192
17/03/19 10:51:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=264477 lastFlushOffset=264477 createNewBlock=false
17/03/19 10:51:20 DEBUG DFSClient: Waiting for ack for: 53
17/03/19 10:51:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=56, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=264192
17/03/19 10:51:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=264477 lastFlushOffset=264477 createNewBlock=false
17/03/19 10:51:20 DEBUG DFSClient: Waiting for ack for: 53
17/03/19 10:51:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=57, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=264192
17/03/19 10:51:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=276016 lastFlushOffset=264477 createNewBlock=false
17/03/19 10:51:20 DEBUG DFSClient: Queued packet 57
17/03/19 10:51:20 DEBUG DFSClient: Waiting for ack for: 57
17/03/19 10:51:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 57 offsetInBlock: 264192 lastPacketInBlock: false lastByteOffsetInBlock: 276016
17/03/19 10:51:20 DEBUG DFSClient: DFSClient seqno: 57 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/19 10:51:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:51:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:51:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:51:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #16
17/03/19 10:51:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #16
17/03/19 10:51:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:51:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:51:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:51:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:51:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 87:=====>                                                   (1 + 4) / 10]17/03/19 10:51:41 WARN TaskSetManager: Lost task 3.0 in stage 87.0 (TID 233, 172.21.15.173, executor 0): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)

[Stage 87:===========>                                             (2 + 4) / 10]17/03/19 10:51:43 WARN TaskSetManager: Lost task 3.1 in stage 87.0 (TID 236, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 53024, None), shuffleId=3, mapId=6, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/23/shuffle_3_6_0.data, offset=241683, length=80543}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/23/shuffle_3_6_0.data, offset=241683, length=80543}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 38 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/23/shuffle_3_6_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 39 more

)
17/03/19 10:51:43 WARN TaskSetManager: Lost task 1.0 in stage 87.0 (TID 231, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 53024, None), shuffleId=9, mapId=8, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/25/shuffle_9_8_0.data, offset=7365876, length=7365917}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/25/shuffle_9_8_0.data, offset=7365876, length=7365917}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/25/shuffle_9_8_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/19 10:51:43 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=58, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=275968
17/03/19 10:51:43 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=282048 lastFlushOffset=276016 createNewBlock=false
17/03/19 10:51:43 DEBUG DFSClient: Queued packet 58
17/03/19 10:51:43 DEBUG DFSClient: Waiting for ack for: 58
17/03/19 10:51:43 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 58 offsetInBlock: 275968 lastPacketInBlock: false lastByteOffsetInBlock: 282048
17/03/19 10:51:43 DEBUG DFSClient: DFSClient seqno: 58 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:51:43 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=59, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=281600
17/03/19 10:51:43 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=282048 lastFlushOffset=282048 createNewBlock=false
17/03/19 10:51:43 DEBUG DFSClient: Waiting for ack for: 58
[Stage 76:>                                                        (0 + 0) / 10]17/03/19 10:51:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=60, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=281600
17/03/19 10:51:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=287709 lastFlushOffset=282048 createNewBlock=false
17/03/19 10:51:44 DEBUG DFSClient: Queued packet 60
17/03/19 10:51:44 DEBUG DFSClient: Waiting for ack for: 60
17/03/19 10:51:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 60 offsetInBlock: 281600 lastPacketInBlock: false lastByteOffsetInBlock: 287709
17/03/19 10:51:44 DEBUG DFSClient: DFSClient seqno: 60 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:51:44 WARN TaskSetManager: Lost task 4.0 in stage 87.0 (TID 234, 172.21.15.173, executor 0): FetchFailed(BlockManagerId(0, 172.21.15.173, 53024, None), shuffleId=2, mapId=1, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more

)
[Stage 76:>                                                        (0 + 1) / 10]17/03/19 10:51:45 WARN TaskSetManager: Lost task 0.0 in stage 76.0 (TID 239, 172.21.15.173, executor 0): java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-96ee1d8f-8564-4314-b198-2e2767dbf635/10/temp_shuffle_b5a43989-5561-45c7-80d7-2c2154544eae ()
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:229)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/19 10:51:46 WARN TransportChannelHandler: Exception in connection from /172.21.15.173:54307
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/19 10:51:46 ERROR TaskSchedulerImpl: Lost executor 0 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:51:46 WARN TaskSetManager: Lost task 5.0 in stage 87.0 (TID 235, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:51:46 WARN TaskSetManager: Lost task 7.0 in stage 87.0 (TID 238, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:51:46 WARN TaskSetManager: Lost task 6.0 in stage 87.0 (TID 237, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:51:46 WARN TaskSetManager: Lost task 1.0 in stage 76.0 (TID 240, 172.21.15.173, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:51:46 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=61, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=287232
17/03/19 10:51:46 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=287709 lastFlushOffset=287709 createNewBlock=false
17/03/19 10:51:46 DEBUG DFSClient: Waiting for ack for: 60
17/03/19 10:51:46 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=62, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=287232
17/03/19 10:51:46 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=287709 lastFlushOffset=287709 createNewBlock=false
17/03/19 10:51:46 DEBUG DFSClient: Waiting for ack for: 60
[Stage 76:>                                                        (0 + 0) / 10]17/03/19 10:51:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=63, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=287232
17/03/19 10:51:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=287709 lastFlushOffset=287709 createNewBlock=false
17/03/19 10:51:51 DEBUG DFSClient: Waiting for ack for: 60
17/03/19 10:51:51 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=64, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=287232
17/03/19 10:51:51 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=287709 lastFlushOffset=287709 createNewBlock=false
17/03/19 10:51:51 DEBUG DFSClient: Waiting for ack for: 60
[Stage 76:>                                                        (0 + 4) / 10]17/03/19 10:51:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:51:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:51:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:51:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #17
17/03/19 10:51:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #17
17/03/19 10:51:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:51:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:51:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 76:=================>                                       (3 + 4) / 10][Stage 76:============================>                            (5 + 4) / 10][Stage 76:=======================================>                 (7 + 3) / 10][Stage 76:=============================================>           (8 + 2) / 10][Stage 76:===================================================>     (9 + 1) / 10]17/03/19 10:52:03 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=65, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=287232
17/03/19 10:52:03 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=297460 lastFlushOffset=287709 createNewBlock=false
17/03/19 10:52:03 DEBUG DFSClient: Queued packet 65
17/03/19 10:52:03 DEBUG DFSClient: Waiting for ack for: 65
17/03/19 10:52:03 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 65 offsetInBlock: 287232 lastPacketInBlock: false lastByteOffsetInBlock: 297460
17/03/19 10:52:03 DEBUG DFSClient: DFSClient seqno: 65 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10]17/03/19 10:52:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:52:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10][Stage 77:===================================================>     (9 + 1) / 10]17/03/19 10:52:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=66, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=296960
17/03/19 10:52:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=306266 lastFlushOffset=297460 createNewBlock=false
17/03/19 10:52:15 DEBUG DFSClient: Queued packet 66
17/03/19 10:52:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 66 offsetInBlock: 296960 lastPacketInBlock: false lastByteOffsetInBlock: 306266
17/03/19 10:52:15 DEBUG DFSClient: Waiting for ack for: 66
17/03/19 10:52:15 DEBUG DFSClient: DFSClient seqno: 66 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:52:15 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=67, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=306176
17/03/19 10:52:15 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=315748 lastFlushOffset=306266 createNewBlock=false
17/03/19 10:52:15 DEBUG DFSClient: Queued packet 67
17/03/19 10:52:15 DEBUG DFSClient: Waiting for ack for: 67
17/03/19 10:52:15 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 67 offsetInBlock: 306176 lastPacketInBlock: false lastByteOffsetInBlock: 315748
17/03/19 10:52:15 DEBUG DFSClient: DFSClient seqno: 67 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:======================>                                  (4 + 4) / 10][Stage 79:============================>                            (5 + 4) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/19 10:52:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=68, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=315392
17/03/19 10:52:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=321195 lastFlushOffset=315748 createNewBlock=false
17/03/19 10:52:17 DEBUG DFSClient: Queued packet 68
17/03/19 10:52:17 DEBUG DFSClient: Waiting for ack for: 68
17/03/19 10:52:17 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 68 offsetInBlock: 315392 lastPacketInBlock: false lastByteOffsetInBlock: 321195
17/03/19 10:52:17 DEBUG DFSClient: DFSClient seqno: 68 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:============================>                            (5 + 4) / 10]17/03/19 10:52:17 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=69, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=321024
17/03/19 10:52:17 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=326989 lastFlushOffset=321195 createNewBlock=false
17/03/19 10:52:17 DEBUG DFSClient: Queued packet 69
17/03/19 10:52:17 DEBUG DFSClient: Waiting for ack for: 69
17/03/19 10:52:17 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 69 offsetInBlock: 321024 lastPacketInBlock: false lastByteOffsetInBlock: 326989
17/03/19 10:52:17 DEBUG DFSClient: DFSClient seqno: 69 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:=====>                                                   (1 + 5) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/19 10:52:20 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=70, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=326656
17/03/19 10:52:20 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=337684 lastFlushOffset=326989 createNewBlock=false
17/03/19 10:52:20 DEBUG DFSClient: Queued packet 70
17/03/19 10:52:20 DEBUG DFSClient: Waiting for ack for: 70
17/03/19 10:52:20 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 70 offsetInBlock: 326656 lastPacketInBlock: false lastByteOffsetInBlock: 337684
17/03/19 10:52:20 DEBUG DFSClient: DFSClient seqno: 70 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:=============================================>           (8 + 2) / 10]17/03/19 10:52:22 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=71, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=337408
17/03/19 10:52:22 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=343469 lastFlushOffset=337684 createNewBlock=false
17/03/19 10:52:22 DEBUG DFSClient: Queued packet 71
17/03/19 10:52:22 DEBUG DFSClient: Waiting for ack for: 71
17/03/19 10:52:22 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 71 offsetInBlock: 337408 lastPacketInBlock: false lastByteOffsetInBlock: 343469
17/03/19 10:52:22 DEBUG DFSClient: DFSClient seqno: 71 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/03/19 10:52:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:52:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:52:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:52:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #18
17/03/19 10:52:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #18
17/03/19 10:52:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:52:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:52:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:52:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:52:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:52:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:52:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:52:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:52:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #19
17/03/19 10:52:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #19
17/03/19 10:52:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:52:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:52:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:53:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:53:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:>                                                        (0 + 4) / 10]17/03/19 10:53:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:53:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:53:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:53:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #20
17/03/19 10:53:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #20
17/03/19 10:53:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:53:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:53:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:53:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:53:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===========>                                             (2 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/03/19 10:53:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:53:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:53:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:53:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #21
17/03/19 10:53:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #21
17/03/19 10:53:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:53:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:53:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:54:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:54:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:54:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:54:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:54:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:54:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #22
17/03/19 10:54:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #22
17/03/19 10:54:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:54:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:54:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:54:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:54:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:======================>                                  (4 + 4) / 10]17/03/19 10:54:52 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: -1 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 0
17/03/19 10:54:52 DEBUG DFSClient: DFSClient seqno: -1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:54:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:54:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:54:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:54:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #23
17/03/19 10:54:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #23
17/03/19 10:54:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:54:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:54:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 83:============================>                            (5 + 4) / 10][Stage 83:=============================================>           (8 + 2) / 10][Stage 83:===================================================>     (9 + 1) / 10]17/03/19 10:55:01 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=72, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=343040
17/03/19 10:55:01 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=354507 lastFlushOffset=343469 createNewBlock=false
17/03/19 10:55:01 DEBUG DFSClient: Queued packet 72
17/03/19 10:55:01 DEBUG DFSClient: Waiting for ack for: 72
17/03/19 10:55:01 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 72 offsetInBlock: 343040 lastPacketInBlock: false lastByteOffsetInBlock: 354507
17/03/19 10:55:01 DEBUG DFSClient: DFSClient seqno: 72 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 84:>                                                        (0 + 4) / 10][Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:===========>                                             (2 + 4) / 10]17/03/19 10:55:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:55:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:======================>                                  (4 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10][Stage 84:=============================================>           (8 + 2) / 10]17/03/19 10:55:13 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=73, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=354304
17/03/19 10:55:13 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=360319 lastFlushOffset=354507 createNewBlock=false
17/03/19 10:55:13 DEBUG DFSClient: Queued packet 73
17/03/19 10:55:13 DEBUG DFSClient: Waiting for ack for: 73
17/03/19 10:55:13 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 73 offsetInBlock: 354304 lastPacketInBlock: false lastByteOffsetInBlock: 360319
17/03/19 10:55:13 DEBUG DFSClient: DFSClient seqno: 73 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10][Stage 85:=====>                                                   (1 + 4) / 10][Stage 85:===========>                                             (2 + 4) / 10][Stage 85:=================>                                       (3 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10][Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10][Stage 85:===================================================>     (9 + 1) / 10]17/03/19 10:55:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:55:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:55:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:55:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #24
17/03/19 10:55:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #24
17/03/19 10:55:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:55:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:55:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:55:25 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=74, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=359936
17/03/19 10:55:25 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=371532 lastFlushOffset=360319 createNewBlock=false
17/03/19 10:55:25 DEBUG DFSClient: Queued packet 74
17/03/19 10:55:25 DEBUG DFSClient: Waiting for ack for: 74
17/03/19 10:55:25 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 74 offsetInBlock: 359936 lastPacketInBlock: false lastByteOffsetInBlock: 371532
17/03/19 10:55:25 DEBUG DFSClient: DFSClient seqno: 74 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10][Stage 86:=====>                                                   (1 + 4) / 10][Stage 86:===========>                                             (2 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10][Stage 86:======================>                                  (4 + 5) / 10][Stage 86:============================>                            (5 + 4) / 10]17/03/19 10:55:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:55:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=======================================>                 (7 + 3) / 10][Stage 86:=============================================>           (8 + 2) / 10][Stage 86:===================================================>     (9 + 1) / 10]17/03/19 10:55:41 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=75, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=371200
17/03/19 10:55:41 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=381772 lastFlushOffset=371532 createNewBlock=false
17/03/19 10:55:41 DEBUG DFSClient: Queued packet 75
17/03/19 10:55:41 DEBUG DFSClient: Waiting for ack for: 75
17/03/19 10:55:41 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 75 offsetInBlock: 371200 lastPacketInBlock: false lastByteOffsetInBlock: 381772
17/03/19 10:55:41 DEBUG DFSClient: DFSClient seqno: 75 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/19 10:55:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:55:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:55:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:55:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #25
17/03/19 10:55:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #25
17/03/19 10:55:55 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/19 10:55:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:55:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 87:======================>                                  (4 + 4) / 10]17/03/19 10:56:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:56:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:56:16 WARN TaskSetManager: Lost task 6.0 in stage 87.1 (TID 357, 172.21.15.173, executor 1): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

[Stage 87:============================>                            (5 + 4) / 10]17/03/19 10:56:18 WARN TaskSetManager: Lost task 5.0 in stage 87.1 (TID 356, 172.21.15.173, executor 1): FetchFailed(BlockManagerId(1, 172.21.15.173, 35693, None), shuffleId=9, mapId=6, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/1d/shuffle_9_6_0.data, offset=37209624, length=7441791}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/1d/shuffle_9_6_0.data, offset=37209624, length=7441791}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/1d/shuffle_9_6_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/19 10:56:18 WARN TaskSetManager: Lost task 4.0 in stage 87.1 (TID 355, 172.21.15.173, executor 1): FetchFailed(BlockManagerId(1, 172.21.15.173, 35693, None), shuffleId=9, mapId=6, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/1d/shuffle_9_6_0.data, offset=29767793, length=7441831}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/1d/shuffle_9_6_0.data, offset=29767793, length=7441831}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/1d/shuffle_9_6_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/19 10:56:18 WARN TaskSetManager: Lost task 6.1 in stage 87.1 (TID 360, 172.21.15.173, executor 1): FetchFailed(BlockManagerId(1, 172.21.15.173, 35693, None), shuffleId=2, mapId=2, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/38/shuffle_2_2_0.data, offset=163560, length=27260}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/38/shuffle_2_2_0.data, offset=163560, length=27260}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 39 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/38/shuffle_2_2_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 40 more

)
17/03/19 10:56:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=76, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=381440
17/03/19 10:56:18 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=398144 lastFlushOffset=381772 createNewBlock=false
17/03/19 10:56:18 DEBUG DFSClient: Queued packet 76
17/03/19 10:56:18 DEBUG DFSClient: Waiting for ack for: 76
17/03/19 10:56:18 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 76 offsetInBlock: 381440 lastPacketInBlock: false lastByteOffsetInBlock: 398144
17/03/19 10:56:18 WARN DFSClient: Slow ReadProcessor read fields took 37548ms (threshold=30000ms); ack: seqno: 76 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0, targets: [DatanodeInfoWithStorage[172.21.15.173:50010,DS-bcd3842f-7acc-473a-9a24-360950418375,DISK]]
17/03/19 10:56:18 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=77, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=397824
17/03/19 10:56:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=398144 lastFlushOffset=398144 createNewBlock=false
17/03/19 10:56:19 DEBUG DFSClient: Waiting for ack for: 76
17/03/19 10:56:19 WARN TaskSetManager: Lost task 8.0 in stage 87.1 (TID 359, 172.21.15.173, executor 1): FetchFailed(BlockManagerId(1, 172.21.15.173, 35693, None), shuffleId=2, mapId=1, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-93b57637-cc1d-4908-99cf-79d55e87f2e4/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more

)
17/03/19 10:56:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=78, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=397824
17/03/19 10:56:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=403398 lastFlushOffset=398144 createNewBlock=false
17/03/19 10:56:19 DEBUG DFSClient: Queued packet 78
17/03/19 10:56:19 DEBUG DFSClient: Waiting for ack for: 78
17/03/19 10:56:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 78 offsetInBlock: 397824 lastPacketInBlock: false lastByteOffsetInBlock: 403398
17/03/19 10:56:19 DEBUG DFSClient: DFSClient seqno: 78 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:56:19 WARN TransportChannelHandler: Exception in connection from /172.21.15.173:54323
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/19 10:56:19 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /172.21.15.173:54323 is closed
17/03/19 10:56:19 ERROR TaskSchedulerImpl: Lost executor 1 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:56:19 WARN TaskSetManager: Lost task 9.0 in stage 87.1 (TID 361, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:56:19 WARN BlockManagerMaster: Failed to remove broadcast 32 with removeFromMaster = true - Connection reset by peer
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/19 10:56:19 WARN TaskSetManager: Lost task 2.0 in stage 76.1 (TID 364, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:56:19 WARN TaskSetManager: Lost task 1.0 in stage 76.1 (TID 363, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:56:19 WARN TaskSetManager: Lost task 0.0 in stage 76.1 (TID 362, 172.21.15.173, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 10:56:19 ERROR ContextCleaner: Error cleaning broadcast 32
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:151)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:303)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:60)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1245)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/19 10:56:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=79, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=402944
17/03/19 10:56:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=411566 lastFlushOffset=403398 createNewBlock=false
17/03/19 10:56:19 DEBUG DFSClient: Queued packet 79
17/03/19 10:56:19 DEBUG DFSClient: Waiting for ack for: 79
17/03/19 10:56:19 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 79 offsetInBlock: 402944 lastPacketInBlock: false lastByteOffsetInBlock: 411566
17/03/19 10:56:19 DEBUG DFSClient: DFSClient seqno: 79 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:56:19 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=80, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=411136
17/03/19 10:56:19 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=411566 lastFlushOffset=411566 createNewBlock=false
17/03/19 10:56:19 DEBUG DFSClient: Waiting for ack for: 79
[Stage 76:>                                                        (0 + 0) / 10]17/03/19 10:56:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=81, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=411136
17/03/19 10:56:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=411566 lastFlushOffset=411566 createNewBlock=false
17/03/19 10:56:24 DEBUG DFSClient: Waiting for ack for: 79
[Stage 76:>                                                        (0 + 4) / 10]17/03/19 10:56:24 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=82, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=411136
17/03/19 10:56:24 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=411566 lastFlushOffset=411566 createNewBlock=false
17/03/19 10:56:24 DEBUG DFSClient: Waiting for ack for: 79
17/03/19 10:56:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:56:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:56:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:56:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #26
17/03/19 10:56:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #26
17/03/19 10:56:25 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/19 10:56:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:56:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 76:=================>                                       (3 + 4) / 10][Stage 76:=================>                                       (3 + 5) / 10][Stage 76:============================>                            (5 + 4) / 10][Stage 76:=======================================>                 (7 + 3) / 10][Stage 76:=============================================>           (8 + 2) / 10]17/03/19 10:56:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:56:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 76:===================================================>     (9 + 1) / 10]17/03/19 10:56:36 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=83, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=411136
17/03/19 10:56:36 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=421157 lastFlushOffset=411566 createNewBlock=false
17/03/19 10:56:36 DEBUG DFSClient: Queued packet 83
17/03/19 10:56:36 DEBUG DFSClient: Waiting for ack for: 83
17/03/19 10:56:36 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 83 offsetInBlock: 411136 lastPacketInBlock: false lastByteOffsetInBlock: 421157
17/03/19 10:56:36 DEBUG DFSClient: DFSClient seqno: 83 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10][Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10]17/03/19 10:56:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=84, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=420864
17/03/19 10:56:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=429255 lastFlushOffset=421157 createNewBlock=false
17/03/19 10:56:48 DEBUG DFSClient: Queued packet 84
17/03/19 10:56:48 DEBUG DFSClient: Waiting for ack for: 84
17/03/19 10:56:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 84 offsetInBlock: 420864 lastPacketInBlock: false lastByteOffsetInBlock: 429255
17/03/19 10:56:48 DEBUG DFSClient: DFSClient seqno: 84 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 10:56:48 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=85, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=429056
17/03/19 10:56:48 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=434615 lastFlushOffset=429255 createNewBlock=false
17/03/19 10:56:48 DEBUG DFSClient: Queued packet 85
17/03/19 10:56:48 DEBUG DFSClient: Waiting for ack for: 85
17/03/19 10:56:48 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 85 offsetInBlock: 429056 lastPacketInBlock: false lastByteOffsetInBlock: 434615
17/03/19 10:56:48 DEBUG DFSClient: DFSClient seqno: 85 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:======================>                                  (4 + 4) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/19 10:56:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=86, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=434176
17/03/19 10:56:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=445006 lastFlushOffset=434615 createNewBlock=false
17/03/19 10:56:50 DEBUG DFSClient: Queued packet 86
17/03/19 10:56:50 DEBUG DFSClient: Waiting for ack for: 86
17/03/19 10:56:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 86 offsetInBlock: 434176 lastPacketInBlock: false lastByteOffsetInBlock: 445006
17/03/19 10:56:50 DEBUG DFSClient: DFSClient seqno: 86 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:>                                                        (0 + 0) / 10][Stage 80:=======================================>                 (7 + 3) / 10]17/03/19 10:56:50 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=87, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=444928
17/03/19 10:56:50 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=450401 lastFlushOffset=445006 createNewBlock=false
17/03/19 10:56:50 DEBUG DFSClient: Queued packet 87
17/03/19 10:56:50 DEBUG DFSClient: Waiting for ack for: 87
17/03/19 10:56:50 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 87 offsetInBlock: 444928 lastPacketInBlock: false lastByteOffsetInBlock: 450401
17/03/19 10:56:50 DEBUG DFSClient: DFSClient seqno: 87 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/19 10:56:53 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=88, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=450048
17/03/19 10:56:53 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=462062 lastFlushOffset=450401 createNewBlock=false
17/03/19 10:56:53 DEBUG DFSClient: Queued packet 88
17/03/19 10:56:53 DEBUG DFSClient: Waiting for ack for: 88
17/03/19 10:56:53 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 88 offsetInBlock: 450048 lastPacketInBlock: false lastByteOffsetInBlock: 462062
17/03/19 10:56:53 DEBUG DFSClient: DFSClient seqno: 88 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10]17/03/19 10:56:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:56:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:56:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:56:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #27
17/03/19 10:56:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #27
17/03/19 10:56:55 DEBUG ProtobufRpcEngine: Call: renewLease took 9ms
17/03/19 10:56:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:56:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 82:=============================================>           (8 + 2) / 10][Stage 82:===================================================>     (9 + 1) / 10]17/03/19 10:56:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=89, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=461824
17/03/19 10:56:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=467532 lastFlushOffset=462062 createNewBlock=false
17/03/19 10:56:56 DEBUG DFSClient: Queued packet 89
17/03/19 10:56:56 DEBUG DFSClient: Waiting for ack for: 89
17/03/19 10:56:56 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 89 offsetInBlock: 461824 lastPacketInBlock: false lastByteOffsetInBlock: 467532
17/03/19 10:56:56 DEBUG DFSClient: DFSClient seqno: 89 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/03/19 10:57:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:57:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:57:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:57:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:57:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:57:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #28
17/03/19 10:57:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #28
17/03/19 10:57:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:57:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:57:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:57:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:57:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:57:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:57:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:57:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:57:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #29
17/03/19 10:57:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #29
17/03/19 10:57:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:57:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:57:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 83:>                                                        (0 + 4) / 10]17/03/19 10:58:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:58:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===========>                                             (2 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/03/19 10:58:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:58:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:58:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:58:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #30
17/03/19 10:58:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #30
17/03/19 10:58:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:58:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:58:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:58:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:58:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:58:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:58:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:58:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:58:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #31
17/03/19 10:58:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #31
17/03/19 10:58:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:58:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:58:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:59:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:59:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:======================>                                  (4 + 4) / 10]17/03/19 10:59:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:59:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:59:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:59:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #32
17/03/19 10:59:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #32
17/03/19 10:59:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 10:59:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:59:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 10:59:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: -1 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 0
17/03/19 10:59:26 DEBUG DFSClient: DFSClient seqno: -1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:=============================================>           (8 + 2) / 10]17/03/19 10:59:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 10:59:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 10:59:35 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=90, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=467456
17/03/19 10:59:35 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=478616 lastFlushOffset=467532 createNewBlock=false
17/03/19 10:59:35 DEBUG DFSClient: Queued packet 90
17/03/19 10:59:35 DEBUG DFSClient: Waiting for ack for: 90
17/03/19 10:59:35 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 90 offsetInBlock: 467456 lastPacketInBlock: false lastByteOffsetInBlock: 478616
17/03/19 10:59:35 DEBUG DFSClient: DFSClient seqno: 90 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 84:>                                                        (0 + 4) / 10][Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:===========>                                             (2 + 4) / 10][Stage 84:=================>                                       (3 + 4) / 10][Stage 84:======================>                                  (4 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10][Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10][Stage 84:===================================================>     (9 + 1) / 10]17/03/19 10:59:49 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=91, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=478208
17/03/19 10:59:49 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=484234 lastFlushOffset=478616 createNewBlock=false
17/03/19 10:59:49 DEBUG DFSClient: Queued packet 91
17/03/19 10:59:49 DEBUG DFSClient: Waiting for ack for: 91
17/03/19 10:59:49 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 91 offsetInBlock: 478208 lastPacketInBlock: false lastByteOffsetInBlock: 484234
17/03/19 10:59:50 DEBUG DFSClient: DFSClient seqno: 91 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10][Stage 85:=====>                                                   (1 + 4) / 10][Stage 85:===========>                                             (2 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10]17/03/19 10:59:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 10:59:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 10:59:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 10:59:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #33
17/03/19 10:59:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #33
17/03/19 10:59:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 10:59:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 10:59:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10][Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10]17/03/19 10:59:58 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=92, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=483840
17/03/19 10:59:58 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=495176 lastFlushOffset=484234 createNewBlock=false
17/03/19 10:59:58 DEBUG DFSClient: Queued packet 92
17/03/19 10:59:58 DEBUG DFSClient: Waiting for ack for: 92
17/03/19 10:59:58 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 92 offsetInBlock: 483840 lastPacketInBlock: false lastByteOffsetInBlock: 495176
17/03/19 10:59:58 DEBUG DFSClient: DFSClient seqno: 92 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10][Stage 86:===========>                                             (2 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10]17/03/19 11:00:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:00:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=============================================>           (8 + 2) / 10]17/03/19 11:00:13 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=93, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=495104
17/03/19 11:00:13 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=504812 lastFlushOffset=495176 createNewBlock=false
17/03/19 11:00:13 DEBUG DFSClient: Queued packet 93
17/03/19 11:00:13 DEBUG DFSClient: Waiting for ack for: 93
17/03/19 11:00:13 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 93 offsetInBlock: 495104 lastPacketInBlock: false lastByteOffsetInBlock: 504812
17/03/19 11:00:14 DEBUG DFSClient: DFSClient seqno: 93 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/19 11:00:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:00:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:00:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:00:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #34
17/03/19 11:00:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #34
17/03/19 11:00:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 11:00:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:00:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 11:00:25 WARN TaskSetManager: Lost task 3.0 in stage 87.2 (TID 478, 172.21.15.173, executor 2): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

17/03/19 11:00:26 WARN TaskSetManager: Lost task 4.0 in stage 87.2 (TID 479, 172.21.15.173, executor 2): FetchFailed(BlockManagerId(2, 172.21.15.173, 51581, None), shuffleId=3, mapId=6, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/23/shuffle_3_6_0.data, offset=322226, length=80593}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/23/shuffle_3_6_0.data, offset=322226, length=80593}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 38 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/23/shuffle_3_6_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 39 more

)
17/03/19 11:00:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=94, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=504320
17/03/19 11:00:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=515625 lastFlushOffset=504812 createNewBlock=false
17/03/19 11:00:26 DEBUG DFSClient: Queued packet 94
17/03/19 11:00:26 DEBUG DFSClient: Waiting for ack for: 94
17/03/19 11:00:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 94 offsetInBlock: 504320 lastPacketInBlock: false lastByteOffsetInBlock: 515625
17/03/19 11:00:26 DEBUG DFSClient: DFSClient seqno: 94 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:00:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=95, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=515584
17/03/19 11:00:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=515625 lastFlushOffset=515625 createNewBlock=false
17/03/19 11:00:26 DEBUG DFSClient: Waiting for ack for: 94
17/03/19 11:00:26 WARN TaskSetManager: Lost task 1.0 in stage 87.2 (TID 476, 172.21.15.173, executor 2): FetchFailed(BlockManagerId(2, 172.21.15.173, 51581, None), shuffleId=9, mapId=8, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/25/shuffle_9_8_0.data, offset=7442322, length=7442084}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/25/shuffle_9_8_0.data, offset=7442322, length=7442084}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/25/shuffle_9_8_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/19 11:00:26 WARN TaskSetManager: Lost task 0.1 in stage 87.2 (TID 481, 172.21.15.173, executor 2): FetchFailed(BlockManagerId(2, 172.21.15.173, 51581, None), shuffleId=7, mapId=9, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/3c/shuffle_7_9_0.data, offset=0, length=7479762}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/3c/shuffle_7_9_0.data, offset=0, length=7479762}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 36 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/3c/shuffle_7_9_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 37 more

)
17/03/19 11:00:26 WARN TaskSetManager: Lost task 2.1 in stage 87.2 (TID 482, 172.21.15.173, executor 2): FetchFailed(BlockManagerId(2, 172.21.15.173, 51581, None), shuffleId=2, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more

)
17/03/19 11:00:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=96, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=515584
17/03/19 11:00:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=520730 lastFlushOffset=515625 createNewBlock=false
17/03/19 11:00:26 DEBUG DFSClient: Queued packet 96
17/03/19 11:00:26 DEBUG DFSClient: Waiting for ack for: 96
17/03/19 11:00:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 96 offsetInBlock: 515584 lastPacketInBlock: false lastByteOffsetInBlock: 520730
17/03/19 11:00:26 DEBUG DFSClient: DFSClient seqno: 96 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:00:26 WARN TaskSetManager: Lost task 3.1 in stage 87.2 (TID 480, 172.21.15.173, executor 2): FetchFailed(BlockManagerId(2, 172.21.15.173, 51581, None), shuffleId=7, mapId=6, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/1f/shuffle_7_6_0.data, offset=22438785, length=7479749}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/1f/shuffle_7_6_0.data, offset=22438785, length=7479749}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 36 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/1f/shuffle_7_6_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 37 more

)
17/03/19 11:00:26 WARN TaskSetManager: Lost task 2.0 in stage 76.2 (TID 485, 172.21.15.173, executor 2): java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/23/temp_shuffle_9a39ec40-cff3-4183-85f7-da5f8043cb17 ()
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:229)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/19 11:00:26 WARN TaskSetManager: Lost task 1.0 in stage 76.2 (TID 484, 172.21.15.173, executor 2): java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-6ef0410b-d28c-4e79-9d7c-28d51a762fe8/34/temp_shuffle_879d5bfc-0604-4b7e-a0bb-82a4ba3468a6 ()
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:229)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

[Stage 76:>                                                        (0 + 4) / 10]17/03/19 11:00:27 WARN TransportChannelHandler: Exception in connection from /172.21.15.173:54339
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/19 11:00:27 ERROR TaskSchedulerImpl: Lost executor 2 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 11:00:27 WARN TaskSetManager: Lost task 4.0 in stage 76.2 (TID 487, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 11:00:27 WARN TaskSetManager: Lost task 0.0 in stage 76.2 (TID 483, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 11:00:27 WARN TaskSetManager: Lost task 3.0 in stage 76.2 (TID 486, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 11:00:27 WARN TaskSetManager: Lost task 2.1 in stage 76.2 (TID 488, 172.21.15.173, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 11:00:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=97, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=520704
17/03/19 11:00:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=520730 lastFlushOffset=520730 createNewBlock=false
17/03/19 11:00:27 DEBUG DFSClient: Waiting for ack for: 96
17/03/19 11:00:27 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=98, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=520704
17/03/19 11:00:27 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=520730 lastFlushOffset=520730 createNewBlock=false
17/03/19 11:00:27 DEBUG DFSClient: Waiting for ack for: 96
[Stage 76:>                                                        (0 + 0) / 10]17/03/19 11:00:32 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=99, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=520704
17/03/19 11:00:32 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=520730 lastFlushOffset=520730 createNewBlock=false
17/03/19 11:00:32 DEBUG DFSClient: Waiting for ack for: 96
17/03/19 11:00:32 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=100, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=520704
17/03/19 11:00:32 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=520730 lastFlushOffset=520730 createNewBlock=false
17/03/19 11:00:32 DEBUG DFSClient: Waiting for ack for: 96
[Stage 76:>                                                        (0 + 4) / 10]17/03/19 11:00:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:00:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 76:=================>                                       (3 + 4) / 10][Stage 76:======================>                                  (4 + 4) / 10][Stage 76:============================>                            (5 + 4) / 10][Stage 76:==================================>                      (6 + 4) / 10][Stage 76:=============================================>           (8 + 2) / 10][Stage 76:===================================================>     (9 + 1) / 10]17/03/19 11:00:44 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=101, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=520704
17/03/19 11:00:44 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=530233 lastFlushOffset=520730 createNewBlock=false
17/03/19 11:00:44 DEBUG DFSClient: Queued packet 101
17/03/19 11:00:44 DEBUG DFSClient: Waiting for ack for: 101
17/03/19 11:00:44 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 101 offsetInBlock: 520704 lastPacketInBlock: false lastByteOffsetInBlock: 530233
17/03/19 11:00:44 DEBUG DFSClient: DFSClient seqno: 101 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 77:>                                                        (0 + 4) / 10][Stage 77:======================>                                  (4 + 4) / 10][Stage 77:=============================================>           (8 + 2) / 10]17/03/19 11:00:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:00:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:00:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:00:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #35
17/03/19 11:00:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #35
17/03/19 11:00:55 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 11:00:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:00:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 11:00:56 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=102, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=529920
17/03/19 11:00:56 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=538842 lastFlushOffset=530233 createNewBlock=false
17/03/19 11:00:56 DEBUG DFSClient: Queued packet 102
17/03/19 11:00:56 DEBUG DFSClient: Waiting for ack for: 102
17/03/19 11:00:56 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 102 offsetInBlock: 529920 lastPacketInBlock: false lastByteOffsetInBlock: 538842
17/03/19 11:00:56 DEBUG DFSClient: DFSClient seqno: 102 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:00:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=103, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=538624
17/03/19 11:00:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=548076 lastFlushOffset=538842 createNewBlock=false
17/03/19 11:00:57 DEBUG DFSClient: Queued packet 103
17/03/19 11:00:57 DEBUG DFSClient: Waiting for ack for: 103
17/03/19 11:00:57 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 103 offsetInBlock: 538624 lastPacketInBlock: false lastByteOffsetInBlock: 548076
17/03/19 11:00:57 DEBUG DFSClient: DFSClient seqno: 103 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 79:>                                                        (0 + 0) / 10][Stage 79:>                                                        (0 + 4) / 10][Stage 79:======================>                                  (4 + 4) / 10][Stage 79:=============================================>           (8 + 2) / 10]17/03/19 11:00:58 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=104, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=547840
17/03/19 11:00:58 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=553423 lastFlushOffset=548076 createNewBlock=false
17/03/19 11:00:58 DEBUG DFSClient: Queued packet 104
17/03/19 11:00:58 DEBUG DFSClient: Waiting for ack for: 104
17/03/19 11:00:58 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 104 offsetInBlock: 547840 lastPacketInBlock: false lastByteOffsetInBlock: 553423
17/03/19 11:00:58 DEBUG DFSClient: DFSClient seqno: 104 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 80:==================================>                      (6 + 4) / 10]17/03/19 11:00:59 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=105, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=552960
17/03/19 11:00:59 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=559242 lastFlushOffset=553423 createNewBlock=false
17/03/19 11:00:59 DEBUG DFSClient: Queued packet 105
17/03/19 11:00:59 DEBUG DFSClient: Waiting for ack for: 105
17/03/19 11:00:59 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 105 offsetInBlock: 552960 lastPacketInBlock: false lastByteOffsetInBlock: 559242
17/03/19 11:00:59 DEBUG DFSClient: DFSClient seqno: 105 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 81:>                                                        (0 + 4) / 10][Stage 81:======================>                                  (4 + 4) / 10][Stage 81:=============================================>           (8 + 2) / 10]17/03/19 11:01:02 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=106, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=559104
17/03/19 11:01:02 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=569852 lastFlushOffset=559242 createNewBlock=false
17/03/19 11:01:02 DEBUG DFSClient: Queued packet 106
17/03/19 11:01:02 DEBUG DFSClient: Waiting for ack for: 106
17/03/19 11:01:02 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 106 offsetInBlock: 559104 lastPacketInBlock: false lastByteOffsetInBlock: 569852
17/03/19 11:01:02 DEBUG DFSClient: DFSClient seqno: 106 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 82:>                                                        (0 + 4) / 10][Stage 82:======================>                                  (4 + 4) / 10][Stage 82:=======================================>                 (7 + 3) / 10][Stage 82:=============================================>           (8 + 2) / 10]17/03/19 11:01:04 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=107, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=569344
17/03/19 11:01:04 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=581033 lastFlushOffset=569852 createNewBlock=false
17/03/19 11:01:04 DEBUG DFSClient: Queued packet 107
17/03/19 11:01:04 DEBUG DFSClient: Waiting for ack for: 107
17/03/19 11:01:04 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 107 offsetInBlock: 569344 lastPacketInBlock: false lastByteOffsetInBlock: 581033
17/03/19 11:01:04 DEBUG DFSClient: DFSClient seqno: 107 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 83:>                                                        (0 + 4) / 10]17/03/19 11:01:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:01:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 11:01:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:01:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:01:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:01:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #36
17/03/19 11:01:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #36
17/03/19 11:01:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 11:01:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:01:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 11:01:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:01:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 11:01:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:01:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:01:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:01:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #37
17/03/19 11:01:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #37
17/03/19 11:01:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 11:01:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:01:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 83:>                                                        (0 + 4) / 10]17/03/19 11:02:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:02:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:===========>                                             (2 + 4) / 10][Stage 83:======================>                                  (4 + 4) / 10]17/03/19 11:02:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:02:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:02:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:02:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #38
17/03/19 11:02:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #38
17/03/19 11:02:25 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 11:02:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:02:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 11:02:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:02:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
17/03/19 11:02:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:02:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:02:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:02:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #39
17/03/19 11:02:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #39
17/03/19 11:02:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 11:02:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:02:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 11:03:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:03:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 83:======================>                                  (4 + 4) / 10]17/03/19 11:03:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:03:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:03:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:03:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #40
17/03/19 11:03:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #40
17/03/19 11:03:25 DEBUG ProtobufRpcEngine: Call: renewLease took 7ms
17/03/19 11:03:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:03:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 83:=======================================>                 (7 + 3) / 10][Stage 83:=============================================>           (8 + 2) / 10]17/03/19 11:03:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: -1 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 0
17/03/19 11:03:34 DEBUG DFSClient: DFSClient seqno: -1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:03:34 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=108, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=580608
17/03/19 11:03:34 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=586465 lastFlushOffset=581033 createNewBlock=false
17/03/19 11:03:34 DEBUG DFSClient: Queued packet 108
17/03/19 11:03:34 DEBUG DFSClient: Waiting for ack for: 108
17/03/19 11:03:34 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 108 offsetInBlock: 580608 lastPacketInBlock: false lastByteOffsetInBlock: 586465
17/03/19 11:03:34 DEBUG DFSClient: DFSClient seqno: 108 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 84:>                                                        (0 + 4) / 10]17/03/19 11:03:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:03:35 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 84:=====>                                                   (1 + 4) / 10][Stage 84:======================>                                  (4 + 4) / 10][Stage 84:============================>                            (5 + 4) / 10][Stage 84:==================================>                      (6 + 4) / 10][Stage 84:=======================================>                 (7 + 3) / 10][Stage 84:=============================================>           (8 + 2) / 10][Stage 84:===================================================>     (9 + 1) / 10]17/03/19 11:03:46 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=109, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=586240
17/03/19 11:03:46 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=597587 lastFlushOffset=586465 createNewBlock=false
17/03/19 11:03:46 DEBUG DFSClient: Queued packet 109
17/03/19 11:03:46 DEBUG DFSClient: Waiting for ack for: 109
17/03/19 11:03:46 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 109 offsetInBlock: 586240 lastPacketInBlock: false lastByteOffsetInBlock: 597587
17/03/19 11:03:46 DEBUG DFSClient: DFSClient seqno: 109 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 85:>                                                        (0 + 4) / 10][Stage 85:===========>                                             (2 + 4) / 10][Stage 85:======================>                                  (4 + 4) / 10][Stage 85:============================>                            (5 + 4) / 10][Stage 85:==================================>                      (6 + 4) / 10]17/03/19 11:03:55 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:03:55 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:03:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:03:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #41
17/03/19 11:03:55 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #41
17/03/19 11:03:55 DEBUG ProtobufRpcEngine: Call: renewLease took 6ms
17/03/19 11:03:55 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:03:55 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
[Stage 85:=======================================>                 (7 + 3) / 10][Stage 85:=============================================>           (8 + 2) / 10][Stage 85:===================================================>     (9 + 1) / 10]17/03/19 11:03:57 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=110, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=597504
17/03/19 11:03:57 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=603308 lastFlushOffset=597587 createNewBlock=false
17/03/19 11:03:57 DEBUG DFSClient: Queued packet 110
17/03/19 11:03:57 DEBUG DFSClient: Waiting for ack for: 110
17/03/19 11:03:57 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 110 offsetInBlock: 597504 lastPacketInBlock: false lastByteOffsetInBlock: 603308
17/03/19 11:03:57 DEBUG DFSClient: DFSClient seqno: 110 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 86:>                                                        (0 + 4) / 10][Stage 86:=====>                                                   (1 + 4) / 10][Stage 86:=================>                                       (3 + 4) / 10][Stage 86:======================>                                  (4 + 4) / 10][Stage 86:============================>                            (5 + 4) / 10]17/03/19 11:04:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:04:05 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
[Stage 86:==================================>                      (6 + 4) / 10][Stage 86:=============================================>           (8 + 2) / 10][Stage 86:===================================================>     (9 + 1) / 10]17/03/19 11:04:11 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=111, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=603136
17/03/19 11:04:11 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=613178 lastFlushOffset=603308 createNewBlock=false
17/03/19 11:04:11 DEBUG DFSClient: Queued packet 111
17/03/19 11:04:11 DEBUG DFSClient: Waiting for ack for: 111
17/03/19 11:04:11 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 111 offsetInBlock: 603136 lastPacketInBlock: false lastByteOffsetInBlock: 613178
17/03/19 11:04:11 DEBUG DFSClient: DFSClient seqno: 111 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
[Stage 87:>                                                        (0 + 4) / 10]17/03/19 11:04:25 WARN TaskSetManager: Lost task 0.0 in stage 87.3 (TID 599, 172.21.15.173, executor 3): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:331)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4.apply(ShuffleBlockFetcherIterator.scala:364)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:356)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:322)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:362)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:369)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)

17/03/19 11:04:25 DEBUG Client: The ping interval is 60000 ms.
17/03/19 11:04:25 DEBUG Client: Connecting to spark1/172.21.15.90:9000
17/03/19 11:04:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: starting, having connections 1
17/03/19 11:04:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #42
17/03/19 11:04:25 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #42
17/03/19 11:04:25 DEBUG ProtobufRpcEngine: Call: renewLease took 8ms
17/03/19 11:04:25 DEBUG LeaseRenewer: Lease renewed for client DFSClient_NONMAPREDUCE_-752673868_1
17/03/19 11:04:25 DEBUG LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-752673868_1] with renew id 1 executed
17/03/19 11:04:26 WARN TaskSetManager: Lost task 3.0 in stage 87.3 (TID 602, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 46139, None), shuffleId=9, mapId=9, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/3a/shuffle_9_9_0.data, offset=22326954, length=7442460}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/3a/shuffle_9_9_0.data, offset=22326954, length=7442460}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/3a/shuffle_9_9_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/19 11:04:26 WARN TaskSetManager: Lost task 1.0 in stage 87.3 (TID 600, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 46139, None), shuffleId=9, mapId=6, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/1d/shuffle_9_6_0.data, offset=7442043, length=7442005}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/1d/shuffle_9_6_0.data, offset=7442043, length=7442005}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 35 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/1d/shuffle_9_6_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 36 more

)
17/03/19 11:04:26 WARN TaskSetManager: Lost task 4.0 in stage 87.3 (TID 603, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 46139, None), shuffleId=2, mapId=1, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/29/shuffle_2_1_0.data, offset=109036, length=27259}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/29/shuffle_2_1_0.data, offset=109036, length=27259}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349)
	... 39 more
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/29/shuffle_2_1_0.data ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 40 more

)
17/03/19 11:04:26 WARN TaskSetManager: Lost task 2.0 in stage 87.3 (TID 601, 172.21.15.173, executor 3): java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/18/broadcast_50_piece0 ()
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:171)
	at org.apache.spark.storage.DiskStore.put(DiskStore.scala:54)
	at org.apache.spark.storage.DiskStore.putBytes(DiskStore.scala:76)
	at org.apache.spark.storage.BlockManager.dropFromMemory(BlockManager.scala:1268)
	at org.apache.spark.storage.memory.MemoryStore.org$apache$spark$storage$memory$MemoryStore$$dropBlock$1(MemoryStore.scala:526)
	at org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$2.apply(MemoryStore.scala:547)
	at org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$2.apply(MemoryStore.scala:541)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.storage.memory.MemoryStore.evictBlocksToFreeSpace(MemoryStore.scala:541)
	at org.apache.spark.memory.StorageMemoryPool.acquireMemory(StorageMemoryPool.scala:92)
	at org.apache.spark.memory.StorageMemoryPool.acquireMemory(StorageMemoryPool.scala:73)
	at org.apache.spark.memory.UnifiedMemoryManager.acquireStorageMemory(UnifiedMemoryManager.scala:178)
	at org.apache.spark.memory.UnifiedMemoryManager.acquireUnrollMemory(UnifiedMemoryManager.scala:185)
	at org.apache.spark.storage.memory.MemoryStore.reserveUnrollMemoryForThisTask(MemoryStore.scala:584)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:223)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/03/19 11:04:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=112, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=612864
17/03/19 11:04:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=623745 lastFlushOffset=613178 createNewBlock=false
17/03/19 11:04:26 DEBUG DFSClient: Queued packet 112
17/03/19 11:04:26 DEBUG DFSClient: Waiting for ack for: 112
17/03/19 11:04:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 112 offsetInBlock: 612864 lastPacketInBlock: false lastByteOffsetInBlock: 623745
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 87 (mapPartitions at VertexRDD.scala:356) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/3a/shuffle_9_9_0.data, offset=22326954, length=7442460} 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:356) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58) 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39) 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439) 	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89) 	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:115) 	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$4$$anonfun$apply$5.apply(ReplicatedVertexView.scala:113) 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409) 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285) 	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54) 	at org.apache.spark.scheduler.Task.run(Task.scala:114) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) 	at java.lang.Thread.run(Thread.java:745) Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/3a/shuffle_9_9_0.data, offset=22326954, length=7442460} 	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:349) 	... 35 more Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/3a/shuffle_9_9_0.data () 	at java.io.FileInputStream.open(Native Method) 	at java.io.FileInputStream.<init>(FileInputStream.java:146) 	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98) 	... 36 more 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1456)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1443)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1443)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1273)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1626)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1615)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2016)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2037)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2056)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1159)
	at src.main.scala.SVDPlusPlusApp$.main(SVDPlusPlusApp.scala:105)
	at src.main.scala.SVDPlusPlusApp.main(SVDPlusPlusApp.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_90_0,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 WARN TaskSetManager: Lost task 0.1 in stage 87.3 (TID 604, 172.21.15.173, executor 3): FetchFailed(BlockManagerId(3, 172.21.15.173, 46139, None), shuffleId=2, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more

)
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerTaskEnd(87,3,ShuffleMapTask,FetchFailed(BlockManagerId(3, 172.21.15.173, 46139, None),2,1,0,org.apache.spark.shuffle.FetchFailedException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/0d/shuffle_2_1_0.index ()
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:416)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:392)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:58)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:89)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
	at org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:71)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:216)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:958)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:889)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:949)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:695)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:336)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.graphx.EdgeRDD.compute(EdgeRDD.scala:50)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.scheduler.Task.run(Task.scala:114)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /tmp/spark-bc77a469-0f5d-4afd-8635-712388d84d86/executor-5cb634b7-59f8-441e-9eb4-1b5d0667cf14/blockmgr-496bea63-c40c-46aa-8d19-d585eac2a69d/0d/shuffle_2_1_0.index ()
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:302)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:303)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:132)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:338)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	... 23 more
),org.apache.spark.scheduler.TaskInfo@5e4ecf09,null)
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerAdded(1489892666569,BlockManagerId(3, 172.21.15.173, 46139, None),527224012)
17/03/19 11:04:26 DEBUG DFSClient: DFSClient seqno: 112 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:04:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=113, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=623616
17/03/19 11:04:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=623745 lastFlushOffset=623745 createNewBlock=false
17/03/19 11:04:26 DEBUG DFSClient: Waiting for ack for: 112
17/03/19 11:04:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=114, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=623616
17/03/19 11:04:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=623745 lastFlushOffset=623745 createNewBlock=false
17/03/19 11:04:26 DEBUG DFSClient: Waiting for ack for: 112
17/03/19 11:04:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=115, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=623616
17/03/19 11:04:26 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=629722 lastFlushOffset=623745 createNewBlock=false
17/03/19 11:04:26 DEBUG DFSClient: Queued packet 115
17/03/19 11:04:26 DEBUG DFSClient: Waiting for ack for: 115
17/03/19 11:04:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 115 offsetInBlock: 623616 lastPacketInBlock: false lastByteOffsetInBlock: 629722
17/03/19 11:04:26 DEBUG DFSClient: DFSClient seqno: 115 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:04:26 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=116, src=/eventLogs/app-20170319104654-0012.lz4.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=629248
17/03/19 11:04:26 DEBUG DFSClient: Queued packet 116
17/03/19 11:04:26 DEBUG DFSClient: Queued packet 117
17/03/19 11:04:26 DEBUG DFSClient: Waiting for ack for: 117
17/03/19 11:04:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 116 offsetInBlock: 629248 lastPacketInBlock: false lastByteOffsetInBlock: 630973
17/03/19 11:04:26 DEBUG DFSClient: DFSClient seqno: 116 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:04:26 DEBUG DFSClient: DataStreamer block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930 sending packet packet seqno: 117 offsetInBlock: 630973 lastPacketInBlock: true lastByteOffsetInBlock: 630973
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_9,StorageLevel(memory, deserialized, 1 replicas),23550512,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_52_piece0,StorageLevel(memory, 1 replicas),3106,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_0,StorageLevel(memory, deserialized, 1 replicas),23519608,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_84_8,StorageLevel(memory, deserialized, 1 replicas),7053104,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_0_piece0,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_60_piece0,StorageLevel(memory, 1 replicas),3388,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_56_piece0,StorageLevel(memory, 1 replicas),3752,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_3,StorageLevel(memory, deserialized, 1 replicas),23536472,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_6,StorageLevel(memory, 1 replicas),9634792,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_3_4,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_0,StorageLevel(memory, 1 replicas),9634943,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_9,StorageLevel(memory, 1 replicas),9647283,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_84_7,StorageLevel(memory, deserialized, 1 replicas),8377328,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_51_piece0,StorageLevel(memory, 1 replicas),3478,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_3,StorageLevel(memory, 1 replicas),9638927,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_84_1,StorageLevel(memory, deserialized, 1 replicas),8380064,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_2,StorageLevel(memory, deserialized, 1 replicas),23511576,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_55_piece0,StorageLevel(memory, 1 replicas),4296,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_84_4,StorageLevel(memory, deserialized, 1 replicas),8821472,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_3_6,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_5,StorageLevel(memory, deserialized, 1 replicas),23517720,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_59_piece0,StorageLevel(memory, 1 replicas),4717,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_8,StorageLevel(memory, deserialized, 1 replicas),23489136,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_3_9,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_3_0,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_5,StorageLevel(memory, 1 replicas),9635951,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_3_3,StorageLevel(1 replicas),0,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_8,StorageLevel(memory, 1 replicas),9619273,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),broadcast_50_piece0,StorageLevel(memory, 1 replicas),2619,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_84_6,StorageLevel(memory, deserialized, 1 replicas),10162112,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_14_2,StorageLevel(memory, 1 replicas),9623916,0))
17/03/19 11:04:26 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(3, 172.21.15.173, 46139, None),rdd_23_7,StorageLevel(memory, deserialized, 1 replicas),23508176,0))
17/03/19 11:04:27 DEBUG DFSClient: DFSClient seqno: 117 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/19 11:04:27 DEBUG DFSClient: Closing old block BP-519507147-172.21.15.90-1479901973323:blk_1073809753_68930
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #43
17/03/19 11:04:27 WARN TransportChannelHandler: Exception in connection from /172.21.15.173:54355
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #43
17/03/19 11:04:27 DEBUG ProtobufRpcEngine: Call: complete took 83ms
17/03/19 11:04:27 ERROR TaskSchedulerImpl: Lost executor 3 on 172.21.15.173: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/03/19 11:04:27 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorRemoved(1489892667138,3,Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.)
17/03/19 11:04:27 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerRemoved(1489892667138,BlockManagerId(3, 172.21.15.173, 46139, None))
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #44
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #44
17/03/19 11:04:27 DEBUG ProtobufRpcEngine: Call: getFileInfo took 0ms
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #45
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #45
17/03/19 11:04:27 DEBUG ProtobufRpcEngine: Call: rename took 11ms
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop sending #46
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop got value #46
17/03/19 11:04:27 DEBUG ProtobufRpcEngine: Call: setTimes took 4ms
17/03/19 11:04:27 DEBUG PoolThreadCache: Freed 17 thread-local buffer(s) from thread: shuffle-server-6-3
17/03/19 11:04:27 DEBUG PoolThreadCache: Freed 32 thread-local buffer(s) from thread: shuffle-server-6-2
17/03/19 11:04:27 DEBUG PoolThreadCache: Freed 16 thread-local buffer(s) from thread: shuffle-server-6-4
17/03/19 11:04:27 DEBUG PoolThreadCache: Freed 30 thread-local buffer(s) from thread: rpc-server-3-2
17/03/19 11:04:27 DEBUG PoolThreadCache: Freed 36 thread-local buffer(s) from thread: rpc-server-3-3
17/03/19 11:04:27 DEBUG Client: stopping client from cache: org.apache.hadoop.ipc.Client@3c71d5a
17/03/19 11:04:27 DEBUG Client: removing client from cache: org.apache.hadoop.ipc.Client@3c71d5a
17/03/19 11:04:27 DEBUG Client: stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3c71d5a
17/03/19 11:04:27 DEBUG Client: Stopping client
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: closed
17/03/19 11:04:27 DEBUG Client: IPC Client (1665038823) connection to spark1/172.21.15.90:9000 from hadoop: stopped, remaining connections 0
